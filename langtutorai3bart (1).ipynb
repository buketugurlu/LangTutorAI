{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37e261c861ea409c859ff654c1a2f045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56e5219649294985924c7dfb4650aa03",
              "IPY_MODEL_f2192da62ddd4a91a44ea873643904f0",
              "IPY_MODEL_f7d109ddf9b14f18a2fcb3f34d91bee5"
            ],
            "layout": "IPY_MODEL_8a6bf0cf2a0a4ba9a22b993b50acf551"
          }
        },
        "56e5219649294985924c7dfb4650aa03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dccc65c84d0c4f7a88ef2e9b9d17ed82",
            "placeholder": "​",
            "style": "IPY_MODEL_45c5f96a768d4c2b881145bcf159c7fe",
            "value": "vocab.json: 100%"
          }
        },
        "f2192da62ddd4a91a44ea873643904f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9952bb37b5243fda90a24bea823b48d",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bdb7c7ab1bd943998f5b8417a726d563",
            "value": 898823
          }
        },
        "f7d109ddf9b14f18a2fcb3f34d91bee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b4ed0331d2d40e8b7d13dac2508de25",
            "placeholder": "​",
            "style": "IPY_MODEL_52f6e17c177a43c5a7a7e80358268c5c",
            "value": " 899k/899k [00:00&lt;00:00, 1.40MB/s]"
          }
        },
        "8a6bf0cf2a0a4ba9a22b993b50acf551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dccc65c84d0c4f7a88ef2e9b9d17ed82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45c5f96a768d4c2b881145bcf159c7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9952bb37b5243fda90a24bea823b48d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdb7c7ab1bd943998f5b8417a726d563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b4ed0331d2d40e8b7d13dac2508de25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52f6e17c177a43c5a7a7e80358268c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0ed5ece16944b3f87926d5624ad166a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4898cd2415a401bbf8d4c5a224bfed5",
              "IPY_MODEL_2fcf7efb08d14107a741f03dec4ca57c",
              "IPY_MODEL_643ec4a45bbc49999064dd96d13726fe"
            ],
            "layout": "IPY_MODEL_4c97ce09bc3f43879073da1af947d302"
          }
        },
        "a4898cd2415a401bbf8d4c5a224bfed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc8a6242679944bf9cdfffd6c360a49f",
            "placeholder": "​",
            "style": "IPY_MODEL_7c61692963fa4220bd3f00a7b87f2a28",
            "value": "merges.txt: 100%"
          }
        },
        "2fcf7efb08d14107a741f03dec4ca57c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0fd7459a6c047df822594467d4fe6a5",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0fbc09f752f4924980331d7267521f1",
            "value": 456318
          }
        },
        "643ec4a45bbc49999064dd96d13726fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d30ec347df84565a47a7af6e76a9305",
            "placeholder": "​",
            "style": "IPY_MODEL_1eccd297288141ff8fd4357e095100dc",
            "value": " 456k/456k [00:00&lt;00:00, 1.07MB/s]"
          }
        },
        "4c97ce09bc3f43879073da1af947d302": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc8a6242679944bf9cdfffd6c360a49f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c61692963fa4220bd3f00a7b87f2a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0fd7459a6c047df822594467d4fe6a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0fbc09f752f4924980331d7267521f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d30ec347df84565a47a7af6e76a9305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eccd297288141ff8fd4357e095100dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79a9b7d2608340eca298e97c356d6124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7655e01ce44c4d8f921a07f14aa686e9",
              "IPY_MODEL_947318624ad84280baca28ccc48ce6a9",
              "IPY_MODEL_98b814f91b234307bd7ab39fa4289445"
            ],
            "layout": "IPY_MODEL_a062a14ac7b54602bb8672dc0cd6f2e3"
          }
        },
        "7655e01ce44c4d8f921a07f14aa686e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0925f2da2a5c4d9397d1bf67a39a8081",
            "placeholder": "​",
            "style": "IPY_MODEL_f06a476d40c440b5b4c67d398616bcca",
            "value": "tokenizer.json: 100%"
          }
        },
        "947318624ad84280baca28ccc48ce6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48de07390d954e4fba21c09005f40608",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0f5bf24954a43f38270674e82960ddc",
            "value": 1355863
          }
        },
        "98b814f91b234307bd7ab39fa4289445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_220f1871f49742a79b475962f08a06da",
            "placeholder": "​",
            "style": "IPY_MODEL_b0f6ede1cc7f4573889a532cb29c4cf0",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 3.09MB/s]"
          }
        },
        "a062a14ac7b54602bb8672dc0cd6f2e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0925f2da2a5c4d9397d1bf67a39a8081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f06a476d40c440b5b4c67d398616bcca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48de07390d954e4fba21c09005f40608": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f5bf24954a43f38270674e82960ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "220f1871f49742a79b475962f08a06da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f6ede1cc7f4573889a532cb29c4cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "742fa46b14344507a822f90683f03615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83206a0156e644dfa122e89b8144cce9",
              "IPY_MODEL_09fc38ac2ca24b8bb20a2235bba1c20a",
              "IPY_MODEL_6b01fcf8c6544f52ab061578dc592590"
            ],
            "layout": "IPY_MODEL_aa55e025062747d0afd71cac9ed5d814"
          }
        },
        "83206a0156e644dfa122e89b8144cce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3c384d2f32f4103a48313ad79790f9c",
            "placeholder": "​",
            "style": "IPY_MODEL_58f5d242aea34e7ea85755c2d23023ca",
            "value": "config.json: 100%"
          }
        },
        "09fc38ac2ca24b8bb20a2235bba1c20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd1d06a0a11447bcaa0e277cc479497a",
            "max": 1716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2195420db4224a4496da7c5265fae1bf",
            "value": 1716
          }
        },
        "6b01fcf8c6544f52ab061578dc592590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0bdb5f1198a441cbb07412433b5ba61",
            "placeholder": "​",
            "style": "IPY_MODEL_ef4fab89b9e046c48aba70764f956569",
            "value": " 1.72k/1.72k [00:00&lt;00:00, 150kB/s]"
          }
        },
        "aa55e025062747d0afd71cac9ed5d814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3c384d2f32f4103a48313ad79790f9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58f5d242aea34e7ea85755c2d23023ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd1d06a0a11447bcaa0e277cc479497a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2195420db4224a4496da7c5265fae1bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0bdb5f1198a441cbb07412433b5ba61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef4fab89b9e046c48aba70764f956569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b351033c1cbd403b89b9b9666c38f207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99e73679fad7429c87d488c7848ffcc8",
              "IPY_MODEL_b9cffc859a814575aeac48d5d373d812",
              "IPY_MODEL_9cc16df469274e1b8d2e3f864b2d3069"
            ],
            "layout": "IPY_MODEL_68d8994806cb425bbc19dd12864eb26a"
          }
        },
        "99e73679fad7429c87d488c7848ffcc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c66a003a7914e0cb1914d2ad165ab15",
            "placeholder": "​",
            "style": "IPY_MODEL_1ac13c98a99a4114a11e23ac3659e7ab",
            "value": "model.safetensors: 100%"
          }
        },
        "b9cffc859a814575aeac48d5d373d812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86961d087a9249f08366f9ca834922e0",
            "max": 557709915,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_103edbc5df894099b39f34ed56309e88",
            "value": 557709915
          }
        },
        "9cc16df469274e1b8d2e3f864b2d3069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbbe183a767b48469cb6f1b021004a09",
            "placeholder": "​",
            "style": "IPY_MODEL_a611f3ed31984d65b4dc72a01235da0e",
            "value": " 558M/558M [00:02&lt;00:00, 226MB/s]"
          }
        },
        "68d8994806cb425bbc19dd12864eb26a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c66a003a7914e0cb1914d2ad165ab15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ac13c98a99a4114a11e23ac3659e7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86961d087a9249f08366f9ca834922e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "103edbc5df894099b39f34ed56309e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbbe183a767b48469cb6f1b021004a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a611f3ed31984d65b4dc72a01235da0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e208dc3760854afd9d9ade6fc14c4dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb22d0c1b33647d2af64c3a30e7b3938",
              "IPY_MODEL_bf83cb25b80e415a86d750552c2e7cd8",
              "IPY_MODEL_65b171820bb149efa950c8d13cf91a7e"
            ],
            "layout": "IPY_MODEL_65ed960fd5564fa1a7edfad5958f14f9"
          }
        },
        "fb22d0c1b33647d2af64c3a30e7b3938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4daf51c881f94a83b7f26f59f955b683",
            "placeholder": "​",
            "style": "IPY_MODEL_0bdb7da716a0496bbe3286d6e2235c55",
            "value": "Downloading builder script: 100%"
          }
        },
        "bf83cb25b80e415a86d750552c2e7cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe292e5182f24c9d9a0d47822982dff2",
            "max": 7021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d03fecbf09764c15a12f03cf4b2ee597",
            "value": 7021
          }
        },
        "65b171820bb149efa950c8d13cf91a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb8ca82b90e845e1b7d809a2fdc90976",
            "placeholder": "​",
            "style": "IPY_MODEL_5770370c0ded4a9c8401dc217c7468ef",
            "value": " 7.02k/7.02k [00:00&lt;00:00, 583kB/s]"
          }
        },
        "65ed960fd5564fa1a7edfad5958f14f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4daf51c881f94a83b7f26f59f955b683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bdb7da716a0496bbe3286d6e2235c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe292e5182f24c9d9a0d47822982dff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d03fecbf09764c15a12f03cf4b2ee597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb8ca82b90e845e1b7d809a2fdc90976": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5770370c0ded4a9c8401dc217c7468ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDpHu-DXIWbK"
      },
      "outputs": [],
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Veri Yükleme ve İşleme\n",
        "file_path = \"/content/drive/My Drive/entries.train\"\n",
        "inputs = []  # Hatalı cümleler\n",
        "targets = []  # Düzeltilmiş cümleler\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split(\"\\t\")  # Satırları tab (\\t) ile ayır\n",
        "        if len(parts) > 5:  # En az 5 sütun varsa\n",
        "            corrected_label = parts[0]  # Düzeltme etiketi (ilk sütun)\n",
        "            original_text = parts[4]  # Hatalı cümle (5. sütun)\n",
        "            if corrected_label == \"1\":  # Düzeltme varsa\n",
        "                inputs.append(original_text)\n",
        "                targets.append(parts[5])  # Düzeltilmiş cümle (6. sütun)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLnhmKgYIbBk",
        "outputId": "443a64e0-1185-4b1b-af3a-ddfa0d115271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model ve Tokenizer Yükleme\n",
        "model_name = \"facebook/bart-base\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "37e261c861ea409c859ff654c1a2f045",
            "56e5219649294985924c7dfb4650aa03",
            "f2192da62ddd4a91a44ea873643904f0",
            "f7d109ddf9b14f18a2fcb3f34d91bee5",
            "8a6bf0cf2a0a4ba9a22b993b50acf551",
            "dccc65c84d0c4f7a88ef2e9b9d17ed82",
            "45c5f96a768d4c2b881145bcf159c7fe",
            "a9952bb37b5243fda90a24bea823b48d",
            "bdb7c7ab1bd943998f5b8417a726d563",
            "6b4ed0331d2d40e8b7d13dac2508de25",
            "52f6e17c177a43c5a7a7e80358268c5c",
            "c0ed5ece16944b3f87926d5624ad166a",
            "a4898cd2415a401bbf8d4c5a224bfed5",
            "2fcf7efb08d14107a741f03dec4ca57c",
            "643ec4a45bbc49999064dd96d13726fe",
            "4c97ce09bc3f43879073da1af947d302",
            "bc8a6242679944bf9cdfffd6c360a49f",
            "7c61692963fa4220bd3f00a7b87f2a28",
            "a0fd7459a6c047df822594467d4fe6a5",
            "e0fbc09f752f4924980331d7267521f1",
            "5d30ec347df84565a47a7af6e76a9305",
            "1eccd297288141ff8fd4357e095100dc",
            "79a9b7d2608340eca298e97c356d6124",
            "7655e01ce44c4d8f921a07f14aa686e9",
            "947318624ad84280baca28ccc48ce6a9",
            "98b814f91b234307bd7ab39fa4289445",
            "a062a14ac7b54602bb8672dc0cd6f2e3",
            "0925f2da2a5c4d9397d1bf67a39a8081",
            "f06a476d40c440b5b4c67d398616bcca",
            "48de07390d954e4fba21c09005f40608",
            "b0f5bf24954a43f38270674e82960ddc",
            "220f1871f49742a79b475962f08a06da",
            "b0f6ede1cc7f4573889a532cb29c4cf0",
            "742fa46b14344507a822f90683f03615",
            "83206a0156e644dfa122e89b8144cce9",
            "09fc38ac2ca24b8bb20a2235bba1c20a",
            "6b01fcf8c6544f52ab061578dc592590",
            "aa55e025062747d0afd71cac9ed5d814",
            "a3c384d2f32f4103a48313ad79790f9c",
            "58f5d242aea34e7ea85755c2d23023ca",
            "bd1d06a0a11447bcaa0e277cc479497a",
            "2195420db4224a4496da7c5265fae1bf",
            "a0bdb5f1198a441cbb07412433b5ba61",
            "ef4fab89b9e046c48aba70764f956569",
            "b351033c1cbd403b89b9b9666c38f207",
            "99e73679fad7429c87d488c7848ffcc8",
            "b9cffc859a814575aeac48d5d373d812",
            "9cc16df469274e1b8d2e3f864b2d3069",
            "68d8994806cb425bbc19dd12864eb26a",
            "5c66a003a7914e0cb1914d2ad165ab15",
            "1ac13c98a99a4114a11e23ac3659e7ab",
            "86961d087a9249f08366f9ca834922e0",
            "103edbc5df894099b39f34ed56309e88",
            "fbbe183a767b48469cb6f1b021004a09",
            "a611f3ed31984d65b4dc72a01235da0e"
          ]
        },
        "id": "GJfXB3_cImro",
        "outputId": "77a712c9-d9e8-4597-9429-908a8d302e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37e261c861ea409c859ff654c1a2f045"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0ed5ece16944b3f87926d5624ad166a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79a9b7d2608340eca298e97c356d6124"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "742fa46b14344507a822f90683f03615"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b351033c1cbd403b89b9b9666c38f207"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartEncoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartDecoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer Tanımlama\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "1JEUD-owJEzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim Parametreleri\n",
        "num_epochs = 3\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "630rEZ9NJIBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim Döngüsü\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i in range(0, len(inputs), batch_size):\n",
        "        input_batch = inputs[i:i+batch_size]\n",
        "        target_batch = targets[i:i+batch_size]\n",
        "\n",
        "        # Veriyi Tokenizer İle Kodlama\n",
        "        inputs_enc = tokenizer(input_batch, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "        targets_enc = tokenizer(target_batch, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # Model Çıktıları ve Kaybı Hesaplama\n",
        "        outputs = model(input_ids=inputs_enc[\"input_ids\"], labels=targets_enc[\"input_ids\"])\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Step {i // batch_size + 1}: Loss = {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdBJoBpMJJ3y",
        "outputId": "c9f10d44-c9c9-40be-dafa-16a46bcd2574"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mGörüntülenen çıkış son 5000 satıra kısaltıldı.\u001b[0m\n",
            "Epoch 3, Step 22576: Loss = 0.29517441987991333\n",
            "Epoch 3, Step 22577: Loss = 0.35770317912101746\n",
            "Epoch 3, Step 22578: Loss = 0.488254189491272\n",
            "Epoch 3, Step 22579: Loss = 0.2725049555301666\n",
            "Epoch 3, Step 22580: Loss = 0.2716313600540161\n",
            "Epoch 3, Step 22581: Loss = 0.3568219840526581\n",
            "Epoch 3, Step 22582: Loss = 0.23758617043495178\n",
            "Epoch 3, Step 22583: Loss = 0.2561863362789154\n",
            "Epoch 3, Step 22584: Loss = 0.3353123664855957\n",
            "Epoch 3, Step 22585: Loss = 0.23424723744392395\n",
            "Epoch 3, Step 22586: Loss = 0.2850981652736664\n",
            "Epoch 3, Step 22587: Loss = 0.2788282036781311\n",
            "Epoch 3, Step 22588: Loss = 0.35510966181755066\n",
            "Epoch 3, Step 22589: Loss = 0.4893946349620819\n",
            "Epoch 3, Step 22590: Loss = 0.2460593581199646\n",
            "Epoch 3, Step 22591: Loss = 0.4718018174171448\n",
            "Epoch 3, Step 22592: Loss = 0.27200910449028015\n",
            "Epoch 3, Step 22593: Loss = 0.18436001241207123\n",
            "Epoch 3, Step 22594: Loss = 0.2858182191848755\n",
            "Epoch 3, Step 22595: Loss = 0.5199289917945862\n",
            "Epoch 3, Step 22596: Loss = 0.21316437423229218\n",
            "Epoch 3, Step 22597: Loss = 0.2365938276052475\n",
            "Epoch 3, Step 22598: Loss = 0.3568975031375885\n",
            "Epoch 3, Step 22599: Loss = 0.7156199812889099\n",
            "Epoch 3, Step 22600: Loss = 0.3348722755908966\n",
            "Epoch 3, Step 22601: Loss = 0.2767455577850342\n",
            "Epoch 3, Step 22602: Loss = 0.2510639727115631\n",
            "Epoch 3, Step 22603: Loss = 0.4157838523387909\n",
            "Epoch 3, Step 22604: Loss = 0.48272037506103516\n",
            "Epoch 3, Step 22605: Loss = 0.4014650583267212\n",
            "Epoch 3, Step 22606: Loss = 0.18390315771102905\n",
            "Epoch 3, Step 22607: Loss = 0.19853368401527405\n",
            "Epoch 3, Step 22608: Loss = 0.5466053485870361\n",
            "Epoch 3, Step 22609: Loss = 0.15324591100215912\n",
            "Epoch 3, Step 22610: Loss = 0.5063234567642212\n",
            "Epoch 3, Step 22611: Loss = 0.2750172019004822\n",
            "Epoch 3, Step 22612: Loss = 0.24787355959415436\n",
            "Epoch 3, Step 22613: Loss = 0.38373661041259766\n",
            "Epoch 3, Step 22614: Loss = 0.1562868058681488\n",
            "Epoch 3, Step 22615: Loss = 0.2414873093366623\n",
            "Epoch 3, Step 22616: Loss = 0.4770260751247406\n",
            "Epoch 3, Step 22617: Loss = 0.3259567618370056\n",
            "Epoch 3, Step 22618: Loss = 0.2921365201473236\n",
            "Epoch 3, Step 22619: Loss = 0.7189006805419922\n",
            "Epoch 3, Step 22620: Loss = 0.47984758019447327\n",
            "Epoch 3, Step 22621: Loss = 0.29938915371894836\n",
            "Epoch 3, Step 22622: Loss = 0.1569918543100357\n",
            "Epoch 3, Step 22623: Loss = 0.40195587277412415\n",
            "Epoch 3, Step 22624: Loss = 0.4153849482536316\n",
            "Epoch 3, Step 22625: Loss = 0.42269062995910645\n",
            "Epoch 3, Step 22626: Loss = 0.41742298007011414\n",
            "Epoch 3, Step 22627: Loss = 0.48912104964256287\n",
            "Epoch 3, Step 22628: Loss = 0.16241148114204407\n",
            "Epoch 3, Step 22629: Loss = 0.35758882761001587\n",
            "Epoch 3, Step 22630: Loss = 0.3438816964626312\n",
            "Epoch 3, Step 22631: Loss = 0.1607089787721634\n",
            "Epoch 3, Step 22632: Loss = 0.23538343608379364\n",
            "Epoch 3, Step 22633: Loss = 0.3340899646282196\n",
            "Epoch 3, Step 22634: Loss = 0.3188400864601135\n",
            "Epoch 3, Step 22635: Loss = 0.1933552622795105\n",
            "Epoch 3, Step 22636: Loss = 0.35015544295310974\n",
            "Epoch 3, Step 22637: Loss = 0.3724806606769562\n",
            "Epoch 3, Step 22638: Loss = 0.393627792596817\n",
            "Epoch 3, Step 22639: Loss = 0.3638908863067627\n",
            "Epoch 3, Step 22640: Loss = 0.3079621195793152\n",
            "Epoch 3, Step 22641: Loss = 0.503134548664093\n",
            "Epoch 3, Step 22642: Loss = 0.33692091703414917\n",
            "Epoch 3, Step 22643: Loss = 0.4718950092792511\n",
            "Epoch 3, Step 22644: Loss = 0.2409200668334961\n",
            "Epoch 3, Step 22645: Loss = 0.655814528465271\n",
            "Epoch 3, Step 22646: Loss = 0.6160998940467834\n",
            "Epoch 3, Step 22647: Loss = 0.33579567074775696\n",
            "Epoch 3, Step 22648: Loss = 0.369612455368042\n",
            "Epoch 3, Step 22649: Loss = 0.32378068566322327\n",
            "Epoch 3, Step 22650: Loss = 0.35552099347114563\n",
            "Epoch 3, Step 22651: Loss = 0.27285587787628174\n",
            "Epoch 3, Step 22652: Loss = 0.2036711424589157\n",
            "Epoch 3, Step 22653: Loss = 0.46587780117988586\n",
            "Epoch 3, Step 22654: Loss = 0.5922005772590637\n",
            "Epoch 3, Step 22655: Loss = 0.32204216718673706\n",
            "Epoch 3, Step 22656: Loss = 0.455606073141098\n",
            "Epoch 3, Step 22657: Loss = 0.24332837760448456\n",
            "Epoch 3, Step 22658: Loss = 0.5864218473434448\n",
            "Epoch 3, Step 22659: Loss = 0.49746203422546387\n",
            "Epoch 3, Step 22660: Loss = 0.3769983649253845\n",
            "Epoch 3, Step 22661: Loss = 0.3661960959434509\n",
            "Epoch 3, Step 22662: Loss = 0.21933431923389435\n",
            "Epoch 3, Step 22663: Loss = 0.38329362869262695\n",
            "Epoch 3, Step 22664: Loss = 0.30948567390441895\n",
            "Epoch 3, Step 22665: Loss = 0.22203703224658966\n",
            "Epoch 3, Step 22666: Loss = 0.3763558268547058\n",
            "Epoch 3, Step 22667: Loss = 0.24807828664779663\n",
            "Epoch 3, Step 22668: Loss = 0.22149474918842316\n",
            "Epoch 3, Step 22669: Loss = 0.44771257042884827\n",
            "Epoch 3, Step 22670: Loss = 0.2965549826622009\n",
            "Epoch 3, Step 22671: Loss = 0.662432074546814\n",
            "Epoch 3, Step 22672: Loss = 0.23946812748908997\n",
            "Epoch 3, Step 22673: Loss = 0.4522312879562378\n",
            "Epoch 3, Step 22674: Loss = 0.37278780341148376\n",
            "Epoch 3, Step 22675: Loss = 0.20183627307415009\n",
            "Epoch 3, Step 22676: Loss = 0.2558923065662384\n",
            "Epoch 3, Step 22677: Loss = 0.3799269199371338\n",
            "Epoch 3, Step 22678: Loss = 0.323529988527298\n",
            "Epoch 3, Step 22679: Loss = 0.41132405400276184\n",
            "Epoch 3, Step 22680: Loss = 0.253058522939682\n",
            "Epoch 3, Step 22681: Loss = 0.3193058371543884\n",
            "Epoch 3, Step 22682: Loss = 0.4436003565788269\n",
            "Epoch 3, Step 22683: Loss = 0.3958335816860199\n",
            "Epoch 3, Step 22684: Loss = 0.35059550404548645\n",
            "Epoch 3, Step 22685: Loss = 0.25799694657325745\n",
            "Epoch 3, Step 22686: Loss = 0.32310786843299866\n",
            "Epoch 3, Step 22687: Loss = 0.2555253207683563\n",
            "Epoch 3, Step 22688: Loss = 0.1419869065284729\n",
            "Epoch 3, Step 22689: Loss = 0.44824519753456116\n",
            "Epoch 3, Step 22690: Loss = 0.389433890581131\n",
            "Epoch 3, Step 22691: Loss = 0.36729568243026733\n",
            "Epoch 3, Step 22692: Loss = 0.40751832723617554\n",
            "Epoch 3, Step 22693: Loss = 0.3094589114189148\n",
            "Epoch 3, Step 22694: Loss = 0.3660293519496918\n",
            "Epoch 3, Step 22695: Loss = 0.33682793378829956\n",
            "Epoch 3, Step 22696: Loss = 0.23839473724365234\n",
            "Epoch 3, Step 22697: Loss = 0.31289440393447876\n",
            "Epoch 3, Step 22698: Loss = 0.29025188088417053\n",
            "Epoch 3, Step 22699: Loss = 0.3630800247192383\n",
            "Epoch 3, Step 22700: Loss = 0.4180867373943329\n",
            "Epoch 3, Step 22701: Loss = 0.2092660367488861\n",
            "Epoch 3, Step 22702: Loss = 0.5298446416854858\n",
            "Epoch 3, Step 22703: Loss = 0.22697165608406067\n",
            "Epoch 3, Step 22704: Loss = 0.29913634061813354\n",
            "Epoch 3, Step 22705: Loss = 0.23463238775730133\n",
            "Epoch 3, Step 22706: Loss = 0.47182050347328186\n",
            "Epoch 3, Step 22707: Loss = 0.2628841698169708\n",
            "Epoch 3, Step 22708: Loss = 0.5343558192253113\n",
            "Epoch 3, Step 22709: Loss = 0.2389027625322342\n",
            "Epoch 3, Step 22710: Loss = 0.308901309967041\n",
            "Epoch 3, Step 22711: Loss = 0.7606163620948792\n",
            "Epoch 3, Step 22712: Loss = 0.3450067937374115\n",
            "Epoch 3, Step 22713: Loss = 0.2511671781539917\n",
            "Epoch 3, Step 22714: Loss = 0.5357027053833008\n",
            "Epoch 3, Step 22715: Loss = 0.39339396357536316\n",
            "Epoch 3, Step 22716: Loss = 0.3164618909358978\n",
            "Epoch 3, Step 22717: Loss = 0.3326078951358795\n",
            "Epoch 3, Step 22718: Loss = 0.5068711042404175\n",
            "Epoch 3, Step 22719: Loss = 0.28930431604385376\n",
            "Epoch 3, Step 22720: Loss = 0.35274162888526917\n",
            "Epoch 3, Step 22721: Loss = 0.28597375750541687\n",
            "Epoch 3, Step 22722: Loss = 0.23733901977539062\n",
            "Epoch 3, Step 22723: Loss = 0.18860584497451782\n",
            "Epoch 3, Step 22724: Loss = 0.4042789340019226\n",
            "Epoch 3, Step 22725: Loss = 0.18949462473392487\n",
            "Epoch 3, Step 22726: Loss = 0.5196818709373474\n",
            "Epoch 3, Step 22727: Loss = 0.3226979672908783\n",
            "Epoch 3, Step 22728: Loss = 0.25494185090065\n",
            "Epoch 3, Step 22729: Loss = 0.29432347416877747\n",
            "Epoch 3, Step 22730: Loss = 0.2520906329154968\n",
            "Epoch 3, Step 22731: Loss = 0.24350257217884064\n",
            "Epoch 3, Step 22732: Loss = 0.2216813862323761\n",
            "Epoch 3, Step 22733: Loss = 0.27521347999572754\n",
            "Epoch 3, Step 22734: Loss = 0.2395874410867691\n",
            "Epoch 3, Step 22735: Loss = 0.14395743608474731\n",
            "Epoch 3, Step 22736: Loss = 0.3770489990711212\n",
            "Epoch 3, Step 22737: Loss = 0.3880109190940857\n",
            "Epoch 3, Step 22738: Loss = 0.23942293226718903\n",
            "Epoch 3, Step 22739: Loss = 0.30741217732429504\n",
            "Epoch 3, Step 22740: Loss = 0.1392090916633606\n",
            "Epoch 3, Step 22741: Loss = 0.3115580677986145\n",
            "Epoch 3, Step 22742: Loss = 0.47630929946899414\n",
            "Epoch 3, Step 22743: Loss = 0.1585773229598999\n",
            "Epoch 3, Step 22744: Loss = 0.2318819761276245\n",
            "Epoch 3, Step 22745: Loss = 0.19248740375041962\n",
            "Epoch 3, Step 22746: Loss = 0.2025517076253891\n",
            "Epoch 3, Step 22747: Loss = 0.2872092127799988\n",
            "Epoch 3, Step 22748: Loss = 0.415692538022995\n",
            "Epoch 3, Step 22749: Loss = 0.40923944115638733\n",
            "Epoch 3, Step 22750: Loss = 0.3584423065185547\n",
            "Epoch 3, Step 22751: Loss = 0.45273396372795105\n",
            "Epoch 3, Step 22752: Loss = 0.5646383762359619\n",
            "Epoch 3, Step 22753: Loss = 0.3477603793144226\n",
            "Epoch 3, Step 22754: Loss = 0.15528585016727448\n",
            "Epoch 3, Step 22755: Loss = 0.3412461280822754\n",
            "Epoch 3, Step 22756: Loss = 0.3112952411174774\n",
            "Epoch 3, Step 22757: Loss = 0.49074411392211914\n",
            "Epoch 3, Step 22758: Loss = 0.194529727101326\n",
            "Epoch 3, Step 22759: Loss = 0.33992043137550354\n",
            "Epoch 3, Step 22760: Loss = 0.6359539031982422\n",
            "Epoch 3, Step 22761: Loss = 0.2088732123374939\n",
            "Epoch 3, Step 22762: Loss = 0.2247125506401062\n",
            "Epoch 3, Step 22763: Loss = 0.31284600496292114\n",
            "Epoch 3, Step 22764: Loss = 0.6108877062797546\n",
            "Epoch 3, Step 22765: Loss = 0.2949405908584595\n",
            "Epoch 3, Step 22766: Loss = 0.33242619037628174\n",
            "Epoch 3, Step 22767: Loss = 0.4281104803085327\n",
            "Epoch 3, Step 22768: Loss = 0.3014073073863983\n",
            "Epoch 3, Step 22769: Loss = 0.5548937916755676\n",
            "Epoch 3, Step 22770: Loss = 0.24365076422691345\n",
            "Epoch 3, Step 22771: Loss = 0.46203598380088806\n",
            "Epoch 3, Step 22772: Loss = 0.4198523759841919\n",
            "Epoch 3, Step 22773: Loss = 0.43344905972480774\n",
            "Epoch 3, Step 22774: Loss = 0.2343263030052185\n",
            "Epoch 3, Step 22775: Loss = 0.5271521806716919\n",
            "Epoch 3, Step 22776: Loss = 0.272887647151947\n",
            "Epoch 3, Step 22777: Loss = 0.38293635845184326\n",
            "Epoch 3, Step 22778: Loss = 0.2706148624420166\n",
            "Epoch 3, Step 22779: Loss = 0.2891749441623688\n",
            "Epoch 3, Step 22780: Loss = 0.3891298770904541\n",
            "Epoch 3, Step 22781: Loss = 0.40916547179222107\n",
            "Epoch 3, Step 22782: Loss = 0.3016012907028198\n",
            "Epoch 3, Step 22783: Loss = 0.2674834430217743\n",
            "Epoch 3, Step 22784: Loss = 0.5208978652954102\n",
            "Epoch 3, Step 22785: Loss = 0.4613463878631592\n",
            "Epoch 3, Step 22786: Loss = 0.35418736934661865\n",
            "Epoch 3, Step 22787: Loss = 0.4046681821346283\n",
            "Epoch 3, Step 22788: Loss = 0.38685449957847595\n",
            "Epoch 3, Step 22789: Loss = 0.6753567457199097\n",
            "Epoch 3, Step 22790: Loss = 0.31073975563049316\n",
            "Epoch 3, Step 22791: Loss = 0.3139861524105072\n",
            "Epoch 3, Step 22792: Loss = 0.24178862571716309\n",
            "Epoch 3, Step 22793: Loss = 0.2725844979286194\n",
            "Epoch 3, Step 22794: Loss = 0.32581818103790283\n",
            "Epoch 3, Step 22795: Loss = 0.3826510012149811\n",
            "Epoch 3, Step 22796: Loss = 0.30067670345306396\n",
            "Epoch 3, Step 22797: Loss = 0.28848984837532043\n",
            "Epoch 3, Step 22798: Loss = 0.2835758924484253\n",
            "Epoch 3, Step 22799: Loss = 0.4352758228778839\n",
            "Epoch 3, Step 22800: Loss = 0.268126904964447\n",
            "Epoch 3, Step 22801: Loss = 0.29548949003219604\n",
            "Epoch 3, Step 22802: Loss = 0.40009576082229614\n",
            "Epoch 3, Step 22803: Loss = 0.2998931407928467\n",
            "Epoch 3, Step 22804: Loss = 0.21961082518100739\n",
            "Epoch 3, Step 22805: Loss = 0.5481783151626587\n",
            "Epoch 3, Step 22806: Loss = 0.16890154778957367\n",
            "Epoch 3, Step 22807: Loss = 0.2785850167274475\n",
            "Epoch 3, Step 22808: Loss = 0.49833792448043823\n",
            "Epoch 3, Step 22809: Loss = 0.20473386347293854\n",
            "Epoch 3, Step 22810: Loss = 0.19119690358638763\n",
            "Epoch 3, Step 22811: Loss = 0.26754021644592285\n",
            "Epoch 3, Step 22812: Loss = 0.2807624638080597\n",
            "Epoch 3, Step 22813: Loss = 0.35501158237457275\n",
            "Epoch 3, Step 22814: Loss = 0.3228827714920044\n",
            "Epoch 3, Step 22815: Loss = 0.18132460117340088\n",
            "Epoch 3, Step 22816: Loss = 0.37272587418556213\n",
            "Epoch 3, Step 22817: Loss = 0.43531477451324463\n",
            "Epoch 3, Step 22818: Loss = 0.5528929829597473\n",
            "Epoch 3, Step 22819: Loss = 0.5928298830986023\n",
            "Epoch 3, Step 22820: Loss = 0.3273543119430542\n",
            "Epoch 3, Step 22821: Loss = 0.6226022839546204\n",
            "Epoch 3, Step 22822: Loss = 0.4080504775047302\n",
            "Epoch 3, Step 22823: Loss = 0.4314381182193756\n",
            "Epoch 3, Step 22824: Loss = 0.41286933422088623\n",
            "Epoch 3, Step 22825: Loss = 0.21517546474933624\n",
            "Epoch 3, Step 22826: Loss = 0.21138855814933777\n",
            "Epoch 3, Step 22827: Loss = 0.25826114416122437\n",
            "Epoch 3, Step 22828: Loss = 0.300971120595932\n",
            "Epoch 3, Step 22829: Loss = 0.32327908277511597\n",
            "Epoch 3, Step 22830: Loss = 0.6728674173355103\n",
            "Epoch 3, Step 22831: Loss = 0.2090320587158203\n",
            "Epoch 3, Step 22832: Loss = 0.23675981163978577\n",
            "Epoch 3, Step 22833: Loss = 0.3709123134613037\n",
            "Epoch 3, Step 22834: Loss = 0.39775627851486206\n",
            "Epoch 3, Step 22835: Loss = 0.3656681776046753\n",
            "Epoch 3, Step 22836: Loss = 0.5075317621231079\n",
            "Epoch 3, Step 22837: Loss = 0.34204205870628357\n",
            "Epoch 3, Step 22838: Loss = 0.31663358211517334\n",
            "Epoch 3, Step 22839: Loss = 0.18781238794326782\n",
            "Epoch 3, Step 22840: Loss = 0.29436755180358887\n",
            "Epoch 3, Step 22841: Loss = 0.3112275302410126\n",
            "Epoch 3, Step 22842: Loss = 0.24149926006793976\n",
            "Epoch 3, Step 22843: Loss = 0.2751027047634125\n",
            "Epoch 3, Step 22844: Loss = 0.24598205089569092\n",
            "Epoch 3, Step 22845: Loss = 0.28311672806739807\n",
            "Epoch 3, Step 22846: Loss = 0.452687531709671\n",
            "Epoch 3, Step 22847: Loss = 0.41500261425971985\n",
            "Epoch 3, Step 22848: Loss = 0.29105621576309204\n",
            "Epoch 3, Step 22849: Loss = 0.43737101554870605\n",
            "Epoch 3, Step 22850: Loss = 0.25251635909080505\n",
            "Epoch 3, Step 22851: Loss = 0.3576342463493347\n",
            "Epoch 3, Step 22852: Loss = 0.1979108452796936\n",
            "Epoch 3, Step 22853: Loss = 0.13594989478588104\n",
            "Epoch 3, Step 22854: Loss = 0.4321463406085968\n",
            "Epoch 3, Step 22855: Loss = 0.27666252851486206\n",
            "Epoch 3, Step 22856: Loss = 0.30927610397338867\n",
            "Epoch 3, Step 22857: Loss = 0.32456713914871216\n",
            "Epoch 3, Step 22858: Loss = 0.2881488502025604\n",
            "Epoch 3, Step 22859: Loss = 0.4112756848335266\n",
            "Epoch 3, Step 22860: Loss = 0.4271393120288849\n",
            "Epoch 3, Step 22861: Loss = 0.40439164638519287\n",
            "Epoch 3, Step 22862: Loss = 0.40623098611831665\n",
            "Epoch 3, Step 22863: Loss = 0.19288478791713715\n",
            "Epoch 3, Step 22864: Loss = 0.5259650945663452\n",
            "Epoch 3, Step 22865: Loss = 0.23673945665359497\n",
            "Epoch 3, Step 22866: Loss = 0.17049844563007355\n",
            "Epoch 3, Step 22867: Loss = 0.3597639799118042\n",
            "Epoch 3, Step 22868: Loss = 0.1970464438199997\n",
            "Epoch 3, Step 22869: Loss = 0.35892316699028015\n",
            "Epoch 3, Step 22870: Loss = 0.17575863003730774\n",
            "Epoch 3, Step 22871: Loss = 0.31322985887527466\n",
            "Epoch 3, Step 22872: Loss = 0.21758390963077545\n",
            "Epoch 3, Step 22873: Loss = 0.5297965407371521\n",
            "Epoch 3, Step 22874: Loss = 0.4021928608417511\n",
            "Epoch 3, Step 22875: Loss = 0.2100655883550644\n",
            "Epoch 3, Step 22876: Loss = 0.8897741436958313\n",
            "Epoch 3, Step 22877: Loss = 0.3191792964935303\n",
            "Epoch 3, Step 22878: Loss = 0.29459381103515625\n",
            "Epoch 3, Step 22879: Loss = 0.31070759892463684\n",
            "Epoch 3, Step 22880: Loss = 0.2928757965564728\n",
            "Epoch 3, Step 22881: Loss = 0.2691272497177124\n",
            "Epoch 3, Step 22882: Loss = 0.18757373094558716\n",
            "Epoch 3, Step 22883: Loss = 0.42337581515312195\n",
            "Epoch 3, Step 22884: Loss = 0.3248107433319092\n",
            "Epoch 3, Step 22885: Loss = 0.34212926030158997\n",
            "Epoch 3, Step 22886: Loss = 0.23941479623317719\n",
            "Epoch 3, Step 22887: Loss = 0.2379651814699173\n",
            "Epoch 3, Step 22888: Loss = 0.32396915555000305\n",
            "Epoch 3, Step 22889: Loss = 0.15481339395046234\n",
            "Epoch 3, Step 22890: Loss = 0.44558456540107727\n",
            "Epoch 3, Step 22891: Loss = 0.48511186242103577\n",
            "Epoch 3, Step 22892: Loss = 0.4221327304840088\n",
            "Epoch 3, Step 22893: Loss = 0.22667311131954193\n",
            "Epoch 3, Step 22894: Loss = 0.27561840415000916\n",
            "Epoch 3, Step 22895: Loss = 0.23797540366649628\n",
            "Epoch 3, Step 22896: Loss = 0.6307565569877625\n",
            "Epoch 3, Step 22897: Loss = 0.39672234654426575\n",
            "Epoch 3, Step 22898: Loss = 0.3777141273021698\n",
            "Epoch 3, Step 22899: Loss = 0.3982905149459839\n",
            "Epoch 3, Step 22900: Loss = 0.29638898372650146\n",
            "Epoch 3, Step 22901: Loss = 0.26914072036743164\n",
            "Epoch 3, Step 22902: Loss = 0.2470938116312027\n",
            "Epoch 3, Step 22903: Loss = 0.6258315443992615\n",
            "Epoch 3, Step 22904: Loss = 0.34838181734085083\n",
            "Epoch 3, Step 22905: Loss = 0.36398839950561523\n",
            "Epoch 3, Step 22906: Loss = 0.3991558849811554\n",
            "Epoch 3, Step 22907: Loss = 0.29300421476364136\n",
            "Epoch 3, Step 22908: Loss = 0.24672271311283112\n",
            "Epoch 3, Step 22909: Loss = 0.4113064408302307\n",
            "Epoch 3, Step 22910: Loss = 0.27576106786727905\n",
            "Epoch 3, Step 22911: Loss = 0.2115090936422348\n",
            "Epoch 3, Step 22912: Loss = 0.5052186250686646\n",
            "Epoch 3, Step 22913: Loss = 0.32682517170906067\n",
            "Epoch 3, Step 22914: Loss = 0.3412565588951111\n",
            "Epoch 3, Step 22915: Loss = 0.24715621769428253\n",
            "Epoch 3, Step 22916: Loss = 0.4755963683128357\n",
            "Epoch 3, Step 22917: Loss = 0.45486319065093994\n",
            "Epoch 3, Step 22918: Loss = 0.38140663504600525\n",
            "Epoch 3, Step 22919: Loss = 0.33322426676750183\n",
            "Epoch 3, Step 22920: Loss = 0.3364793062210083\n",
            "Epoch 3, Step 22921: Loss = 0.34828925132751465\n",
            "Epoch 3, Step 22922: Loss = 0.3081406354904175\n",
            "Epoch 3, Step 22923: Loss = 0.373654842376709\n",
            "Epoch 3, Step 22924: Loss = 0.30016201734542847\n",
            "Epoch 3, Step 22925: Loss = 0.28915935754776\n",
            "Epoch 3, Step 22926: Loss = 0.1824382245540619\n",
            "Epoch 3, Step 22927: Loss = 0.30702704191207886\n",
            "Epoch 3, Step 22928: Loss = 0.21909812092781067\n",
            "Epoch 3, Step 22929: Loss = 0.4519096910953522\n",
            "Epoch 3, Step 22930: Loss = 0.326566219329834\n",
            "Epoch 3, Step 22931: Loss = 0.5426601767539978\n",
            "Epoch 3, Step 22932: Loss = 0.6913107633590698\n",
            "Epoch 3, Step 22933: Loss = 0.403790682554245\n",
            "Epoch 3, Step 22934: Loss = 0.18805065751075745\n",
            "Epoch 3, Step 22935: Loss = 0.22118999063968658\n",
            "Epoch 3, Step 22936: Loss = 0.2729197144508362\n",
            "Epoch 3, Step 22937: Loss = 0.3002062737941742\n",
            "Epoch 3, Step 22938: Loss = 0.35291048884391785\n",
            "Epoch 3, Step 22939: Loss = 0.6139549612998962\n",
            "Epoch 3, Step 22940: Loss = 0.2198151797056198\n",
            "Epoch 3, Step 22941: Loss = 0.21189028024673462\n",
            "Epoch 3, Step 22942: Loss = 0.2243511974811554\n",
            "Epoch 3, Step 22943: Loss = 0.2826234996318817\n",
            "Epoch 3, Step 22944: Loss = 0.19008605182170868\n",
            "Epoch 3, Step 22945: Loss = 0.3637993335723877\n",
            "Epoch 3, Step 22946: Loss = 0.5259929299354553\n",
            "Epoch 3, Step 22947: Loss = 0.2879883646965027\n",
            "Epoch 3, Step 22948: Loss = 0.34750378131866455\n",
            "Epoch 3, Step 22949: Loss = 0.4185599386692047\n",
            "Epoch 3, Step 22950: Loss = 0.3949834406375885\n",
            "Epoch 3, Step 22951: Loss = 0.22786845266819\n",
            "Epoch 3, Step 22952: Loss = 0.19572290778160095\n",
            "Epoch 3, Step 22953: Loss = 0.3284986913204193\n",
            "Epoch 3, Step 22954: Loss = 0.12110815942287445\n",
            "Epoch 3, Step 22955: Loss = 0.15936516225337982\n",
            "Epoch 3, Step 22956: Loss = 0.5030838251113892\n",
            "Epoch 3, Step 22957: Loss = 0.1312224268913269\n",
            "Epoch 3, Step 22958: Loss = 0.2512831687927246\n",
            "Epoch 3, Step 22959: Loss = 0.35912877321243286\n",
            "Epoch 3, Step 22960: Loss = 0.23273004591464996\n",
            "Epoch 3, Step 22961: Loss = 0.33302050828933716\n",
            "Epoch 3, Step 22962: Loss = 0.25183364748954773\n",
            "Epoch 3, Step 22963: Loss = 0.22428739070892334\n",
            "Epoch 3, Step 22964: Loss = 0.21353884041309357\n",
            "Epoch 3, Step 22965: Loss = 0.2979504466056824\n",
            "Epoch 3, Step 22966: Loss = 0.39899566769599915\n",
            "Epoch 3, Step 22967: Loss = 0.2678764760494232\n",
            "Epoch 3, Step 22968: Loss = 0.3555760979652405\n",
            "Epoch 3, Step 22969: Loss = 0.34408995509147644\n",
            "Epoch 3, Step 22970: Loss = 0.5146163702011108\n",
            "Epoch 3, Step 22971: Loss = 0.41654258966445923\n",
            "Epoch 3, Step 22972: Loss = 0.34516096115112305\n",
            "Epoch 3, Step 22973: Loss = 0.29296600818634033\n",
            "Epoch 3, Step 22974: Loss = 0.35651910305023193\n",
            "Epoch 3, Step 22975: Loss = 0.344094842672348\n",
            "Epoch 3, Step 22976: Loss = 0.265919953584671\n",
            "Epoch 3, Step 22977: Loss = 0.2038307785987854\n",
            "Epoch 3, Step 22978: Loss = 0.20591875910758972\n",
            "Epoch 3, Step 22979: Loss = 0.40862345695495605\n",
            "Epoch 3, Step 22980: Loss = 0.23427481949329376\n",
            "Epoch 3, Step 22981: Loss = 0.29402798414230347\n",
            "Epoch 3, Step 22982: Loss = 0.3155519962310791\n",
            "Epoch 3, Step 22983: Loss = 0.4657939076423645\n",
            "Epoch 3, Step 22984: Loss = 0.26578187942504883\n",
            "Epoch 3, Step 22985: Loss = 0.4129416346549988\n",
            "Epoch 3, Step 22986: Loss = 0.2938710153102875\n",
            "Epoch 3, Step 22987: Loss = 0.13492298126220703\n",
            "Epoch 3, Step 22988: Loss = 0.2764703631401062\n",
            "Epoch 3, Step 22989: Loss = 0.24447186291217804\n",
            "Epoch 3, Step 22990: Loss = 0.3525785505771637\n",
            "Epoch 3, Step 22991: Loss = 0.2565842866897583\n",
            "Epoch 3, Step 22992: Loss = 0.46428629755973816\n",
            "Epoch 3, Step 22993: Loss = 0.3580002188682556\n",
            "Epoch 3, Step 22994: Loss = 0.22102336585521698\n",
            "Epoch 3, Step 22995: Loss = 0.3754223883152008\n",
            "Epoch 3, Step 22996: Loss = 0.3949960768222809\n",
            "Epoch 3, Step 22997: Loss = 0.300812304019928\n",
            "Epoch 3, Step 22998: Loss = 0.15603488683700562\n",
            "Epoch 3, Step 22999: Loss = 0.36745211482048035\n",
            "Epoch 3, Step 23000: Loss = 0.2661339044570923\n",
            "Epoch 3, Step 23001: Loss = 0.6140502691268921\n",
            "Epoch 3, Step 23002: Loss = 0.345628559589386\n",
            "Epoch 3, Step 23003: Loss = 0.3863634467124939\n",
            "Epoch 3, Step 23004: Loss = 0.6853415369987488\n",
            "Epoch 3, Step 23005: Loss = 0.21400845050811768\n",
            "Epoch 3, Step 23006: Loss = 0.40926238894462585\n",
            "Epoch 3, Step 23007: Loss = 0.2516457736492157\n",
            "Epoch 3, Step 23008: Loss = 0.4008517861366272\n",
            "Epoch 3, Step 23009: Loss = 0.4679863452911377\n",
            "Epoch 3, Step 23010: Loss = 0.20698842406272888\n",
            "Epoch 3, Step 23011: Loss = 0.3662593364715576\n",
            "Epoch 3, Step 23012: Loss = 0.1766616851091385\n",
            "Epoch 3, Step 23013: Loss = 0.38262227177619934\n",
            "Epoch 3, Step 23014: Loss = 0.2568735182285309\n",
            "Epoch 3, Step 23015: Loss = 0.38392916321754456\n",
            "Epoch 3, Step 23016: Loss = 0.28631970286369324\n",
            "Epoch 3, Step 23017: Loss = 0.3858480751514435\n",
            "Epoch 3, Step 23018: Loss = 0.2524128258228302\n",
            "Epoch 3, Step 23019: Loss = 0.24251389503479004\n",
            "Epoch 3, Step 23020: Loss = 0.3252476453781128\n",
            "Epoch 3, Step 23021: Loss = 0.22338660061359406\n",
            "Epoch 3, Step 23022: Loss = 0.27859723567962646\n",
            "Epoch 3, Step 23023: Loss = 0.1702796071767807\n",
            "Epoch 3, Step 23024: Loss = 0.2451033741235733\n",
            "Epoch 3, Step 23025: Loss = 0.416145920753479\n",
            "Epoch 3, Step 23026: Loss = 0.5605818033218384\n",
            "Epoch 3, Step 23027: Loss = 0.4385717809200287\n",
            "Epoch 3, Step 23028: Loss = 0.25423577427864075\n",
            "Epoch 3, Step 23029: Loss = 0.34411120414733887\n",
            "Epoch 3, Step 23030: Loss = 0.2730667293071747\n",
            "Epoch 3, Step 23031: Loss = 0.30061447620391846\n",
            "Epoch 3, Step 23032: Loss = 0.2641980051994324\n",
            "Epoch 3, Step 23033: Loss = 0.24508555233478546\n",
            "Epoch 3, Step 23034: Loss = 0.15924134850502014\n",
            "Epoch 3, Step 23035: Loss = 0.7922004461288452\n",
            "Epoch 3, Step 23036: Loss = 0.16361671686172485\n",
            "Epoch 3, Step 23037: Loss = 0.2308371663093567\n",
            "Epoch 3, Step 23038: Loss = 0.49338239431381226\n",
            "Epoch 3, Step 23039: Loss = 0.36496663093566895\n",
            "Epoch 3, Step 23040: Loss = 0.4032963812351227\n",
            "Epoch 3, Step 23041: Loss = 0.46665120124816895\n",
            "Epoch 3, Step 23042: Loss = 0.34103065729141235\n",
            "Epoch 3, Step 23043: Loss = 0.3116038143634796\n",
            "Epoch 3, Step 23044: Loss = 0.5878272652626038\n",
            "Epoch 3, Step 23045: Loss = 0.5903885960578918\n",
            "Epoch 3, Step 23046: Loss = 0.3325789272785187\n",
            "Epoch 3, Step 23047: Loss = 0.15875114500522614\n",
            "Epoch 3, Step 23048: Loss = 0.2523401975631714\n",
            "Epoch 3, Step 23049: Loss = 0.33434271812438965\n",
            "Epoch 3, Step 23050: Loss = 0.342592716217041\n",
            "Epoch 3, Step 23051: Loss = 0.4263969361782074\n",
            "Epoch 3, Step 23052: Loss = 0.2556835412979126\n",
            "Epoch 3, Step 23053: Loss = 0.5117871165275574\n",
            "Epoch 3, Step 23054: Loss = 0.18259121477603912\n",
            "Epoch 3, Step 23055: Loss = 0.4282474219799042\n",
            "Epoch 3, Step 23056: Loss = 0.2843577563762665\n",
            "Epoch 3, Step 23057: Loss = 0.2225276678800583\n",
            "Epoch 3, Step 23058: Loss = 0.4547106921672821\n",
            "Epoch 3, Step 23059: Loss = 0.39228278398513794\n",
            "Epoch 3, Step 23060: Loss = 0.31398582458496094\n",
            "Epoch 3, Step 23061: Loss = 0.15846729278564453\n",
            "Epoch 3, Step 23062: Loss = 0.28427600860595703\n",
            "Epoch 3, Step 23063: Loss = 0.37830451130867004\n",
            "Epoch 3, Step 23064: Loss = 0.6098466515541077\n",
            "Epoch 3, Step 23065: Loss = 0.32582220435142517\n",
            "Epoch 3, Step 23066: Loss = 0.2894821763038635\n",
            "Epoch 3, Step 23067: Loss = 0.24958856403827667\n",
            "Epoch 3, Step 23068: Loss = 0.44959351420402527\n",
            "Epoch 3, Step 23069: Loss = 0.39105671644210815\n",
            "Epoch 3, Step 23070: Loss = 0.32024866342544556\n",
            "Epoch 3, Step 23071: Loss = 0.334844172000885\n",
            "Epoch 3, Step 23072: Loss = 0.31946974992752075\n",
            "Epoch 3, Step 23073: Loss = 0.4298950135707855\n",
            "Epoch 3, Step 23074: Loss = 0.4634567201137543\n",
            "Epoch 3, Step 23075: Loss = 0.2663755416870117\n",
            "Epoch 3, Step 23076: Loss = 0.13147152960300446\n",
            "Epoch 3, Step 23077: Loss = 0.4109001159667969\n",
            "Epoch 3, Step 23078: Loss = 0.6219480633735657\n",
            "Epoch 3, Step 23079: Loss = 0.30074456334114075\n",
            "Epoch 3, Step 23080: Loss = 0.20615866780281067\n",
            "Epoch 3, Step 23081: Loss = 0.2664687931537628\n",
            "Epoch 3, Step 23082: Loss = 0.24593721330165863\n",
            "Epoch 3, Step 23083: Loss = 0.2606724500656128\n",
            "Epoch 3, Step 23084: Loss = 0.3027339577674866\n",
            "Epoch 3, Step 23085: Loss = 0.39432042837142944\n",
            "Epoch 3, Step 23086: Loss = 0.47653403878211975\n",
            "Epoch 3, Step 23087: Loss = 0.45912718772888184\n",
            "Epoch 3, Step 23088: Loss = 0.23248283565044403\n",
            "Epoch 3, Step 23089: Loss = 0.3517058789730072\n",
            "Epoch 3, Step 23090: Loss = 0.37584054470062256\n",
            "Epoch 3, Step 23091: Loss = 0.4953027665615082\n",
            "Epoch 3, Step 23092: Loss = 0.3638478219509125\n",
            "Epoch 3, Step 23093: Loss = 0.18582770228385925\n",
            "Epoch 3, Step 23094: Loss = 0.43697959184646606\n",
            "Epoch 3, Step 23095: Loss = 0.4296985864639282\n",
            "Epoch 3, Step 23096: Loss = 0.19990506768226624\n",
            "Epoch 3, Step 23097: Loss = 0.3632599413394928\n",
            "Epoch 3, Step 23098: Loss = 0.5854690670967102\n",
            "Epoch 3, Step 23099: Loss = 0.27537423372268677\n",
            "Epoch 3, Step 23100: Loss = 0.26074716448783875\n",
            "Epoch 3, Step 23101: Loss = 0.39764922857284546\n",
            "Epoch 3, Step 23102: Loss = 0.35852304100990295\n",
            "Epoch 3, Step 23103: Loss = 0.22894178330898285\n",
            "Epoch 3, Step 23104: Loss = 0.3988786041736603\n",
            "Epoch 3, Step 23105: Loss = 0.4587734043598175\n",
            "Epoch 3, Step 23106: Loss = 0.3574292063713074\n",
            "Epoch 3, Step 23107: Loss = 0.24395152926445007\n",
            "Epoch 3, Step 23108: Loss = 0.2784841060638428\n",
            "Epoch 3, Step 23109: Loss = 0.4700923264026642\n",
            "Epoch 3, Step 23110: Loss = 0.3202979266643524\n",
            "Epoch 3, Step 23111: Loss = 0.5711367130279541\n",
            "Epoch 3, Step 23112: Loss = 0.39358964562416077\n",
            "Epoch 3, Step 23113: Loss = 0.3787766695022583\n",
            "Epoch 3, Step 23114: Loss = 0.19202503561973572\n",
            "Epoch 3, Step 23115: Loss = 0.38556957244873047\n",
            "Epoch 3, Step 23116: Loss = 0.4785654544830322\n",
            "Epoch 3, Step 23117: Loss = 0.46603888273239136\n",
            "Epoch 3, Step 23118: Loss = 0.3366404175758362\n",
            "Epoch 3, Step 23119: Loss = 0.23008763790130615\n",
            "Epoch 3, Step 23120: Loss = 0.23016586899757385\n",
            "Epoch 3, Step 23121: Loss = 0.5862671732902527\n",
            "Epoch 3, Step 23122: Loss = 0.47805264592170715\n",
            "Epoch 3, Step 23123: Loss = 0.3000662326812744\n",
            "Epoch 3, Step 23124: Loss = 0.3431060314178467\n",
            "Epoch 3, Step 23125: Loss = 0.3623523414134979\n",
            "Epoch 3, Step 23126: Loss = 0.4075952172279358\n",
            "Epoch 3, Step 23127: Loss = 0.2705838680267334\n",
            "Epoch 3, Step 23128: Loss = 0.2610395550727844\n",
            "Epoch 3, Step 23129: Loss = 0.33132490515708923\n",
            "Epoch 3, Step 23130: Loss = 0.21571530401706696\n",
            "Epoch 3, Step 23131: Loss = 0.3318679928779602\n",
            "Epoch 3, Step 23132: Loss = 0.1557960957288742\n",
            "Epoch 3, Step 23133: Loss = 0.3130468428134918\n",
            "Epoch 3, Step 23134: Loss = 0.4137025773525238\n",
            "Epoch 3, Step 23135: Loss = 0.39102718234062195\n",
            "Epoch 3, Step 23136: Loss = 0.16578274965286255\n",
            "Epoch 3, Step 23137: Loss = 0.4042353332042694\n",
            "Epoch 3, Step 23138: Loss = 0.3656647503376007\n",
            "Epoch 3, Step 23139: Loss = 0.41237518191337585\n",
            "Epoch 3, Step 23140: Loss = 0.17424531280994415\n",
            "Epoch 3, Step 23141: Loss = 0.22509253025054932\n",
            "Epoch 3, Step 23142: Loss = 0.19470186531543732\n",
            "Epoch 3, Step 23143: Loss = 0.7958753705024719\n",
            "Epoch 3, Step 23144: Loss = 0.15221482515335083\n",
            "Epoch 3, Step 23145: Loss = 0.3049931228160858\n",
            "Epoch 3, Step 23146: Loss = 0.2941550612449646\n",
            "Epoch 3, Step 23147: Loss = 0.19854451715946198\n",
            "Epoch 3, Step 23148: Loss = 0.270646870136261\n",
            "Epoch 3, Step 23149: Loss = 0.4535689055919647\n",
            "Epoch 3, Step 23150: Loss = 0.39253926277160645\n",
            "Epoch 3, Step 23151: Loss = 0.3613041043281555\n",
            "Epoch 3, Step 23152: Loss = 0.4608560800552368\n",
            "Epoch 3, Step 23153: Loss = 0.2797784209251404\n",
            "Epoch 3, Step 23154: Loss = 0.3596455454826355\n",
            "Epoch 3, Step 23155: Loss = 0.3931262195110321\n",
            "Epoch 3, Step 23156: Loss = 0.2886233627796173\n",
            "Epoch 3, Step 23157: Loss = 0.5162304043769836\n",
            "Epoch 3, Step 23158: Loss = 0.4748068153858185\n",
            "Epoch 3, Step 23159: Loss = 0.41851386427879333\n",
            "Epoch 3, Step 23160: Loss = 0.4154483675956726\n",
            "Epoch 3, Step 23161: Loss = 0.4919544458389282\n",
            "Epoch 3, Step 23162: Loss = 0.351382315158844\n",
            "Epoch 3, Step 23163: Loss = 0.350871205329895\n",
            "Epoch 3, Step 23164: Loss = 0.2493266463279724\n",
            "Epoch 3, Step 23165: Loss = 0.29000145196914673\n",
            "Epoch 3, Step 23166: Loss = 0.42817771434783936\n",
            "Epoch 3, Step 23167: Loss = 0.2999286651611328\n",
            "Epoch 3, Step 23168: Loss = 0.33800190687179565\n",
            "Epoch 3, Step 23169: Loss = 0.41376930475234985\n",
            "Epoch 3, Step 23170: Loss = 0.3732706308364868\n",
            "Epoch 3, Step 23171: Loss = 0.35077372193336487\n",
            "Epoch 3, Step 23172: Loss = 0.34751516580581665\n",
            "Epoch 3, Step 23173: Loss = 0.27662360668182373\n",
            "Epoch 3, Step 23174: Loss = 0.3234535753726959\n",
            "Epoch 3, Step 23175: Loss = 0.21207976341247559\n",
            "Epoch 3, Step 23176: Loss = 0.4237726330757141\n",
            "Epoch 3, Step 23177: Loss = 0.2538813352584839\n",
            "Epoch 3, Step 23178: Loss = 0.17712007462978363\n",
            "Epoch 3, Step 23179: Loss = 0.19014139473438263\n",
            "Epoch 3, Step 23180: Loss = 0.26048973202705383\n",
            "Epoch 3, Step 23181: Loss = 0.5271610617637634\n",
            "Epoch 3, Step 23182: Loss = 0.24892346560955048\n",
            "Epoch 3, Step 23183: Loss = 0.38307464122772217\n",
            "Epoch 3, Step 23184: Loss = 0.6539901494979858\n",
            "Epoch 3, Step 23185: Loss = 0.21229341626167297\n",
            "Epoch 3, Step 23186: Loss = 0.4964887201786041\n",
            "Epoch 3, Step 23187: Loss = 0.4872681200504303\n",
            "Epoch 3, Step 23188: Loss = 0.38848677277565\n",
            "Epoch 3, Step 23189: Loss = 0.35359400510787964\n",
            "Epoch 3, Step 23190: Loss = 0.248219832777977\n",
            "Epoch 3, Step 23191: Loss = 0.27278757095336914\n",
            "Epoch 3, Step 23192: Loss = 0.2881726622581482\n",
            "Epoch 3, Step 23193: Loss = 0.3708750307559967\n",
            "Epoch 3, Step 23194: Loss = 0.2234755903482437\n",
            "Epoch 3, Step 23195: Loss = 0.2658071219921112\n",
            "Epoch 3, Step 23196: Loss = 0.2908448278903961\n",
            "Epoch 3, Step 23197: Loss = 0.37883636355400085\n",
            "Epoch 3, Step 23198: Loss = 0.3107641637325287\n",
            "Epoch 3, Step 23199: Loss = 0.30220991373062134\n",
            "Epoch 3, Step 23200: Loss = 0.33242475986480713\n",
            "Epoch 3, Step 23201: Loss = 0.2791801691055298\n",
            "Epoch 3, Step 23202: Loss = 0.38498374819755554\n",
            "Epoch 3, Step 23203: Loss = 0.20346969366073608\n",
            "Epoch 3, Step 23204: Loss = 0.5613041520118713\n",
            "Epoch 3, Step 23205: Loss = 0.21468667685985565\n",
            "Epoch 3, Step 23206: Loss = 0.16196411848068237\n",
            "Epoch 3, Step 23207: Loss = 0.2506977915763855\n",
            "Epoch 3, Step 23208: Loss = 0.4113353490829468\n",
            "Epoch 3, Step 23209: Loss = 0.24698689579963684\n",
            "Epoch 3, Step 23210: Loss = 0.2600036561489105\n",
            "Epoch 3, Step 23211: Loss = 0.4880904257297516\n",
            "Epoch 3, Step 23212: Loss = 0.38640296459198\n",
            "Epoch 3, Step 23213: Loss = 0.44309353828430176\n",
            "Epoch 3, Step 23214: Loss = 0.338398814201355\n",
            "Epoch 3, Step 23215: Loss = 0.36790624260902405\n",
            "Epoch 3, Step 23216: Loss = 0.3990134596824646\n",
            "Epoch 3, Step 23217: Loss = 0.21915461122989655\n",
            "Epoch 3, Step 23218: Loss = 0.36467134952545166\n",
            "Epoch 3, Step 23219: Loss = 0.2754468321800232\n",
            "Epoch 3, Step 23220: Loss = 0.22143451869487762\n",
            "Epoch 3, Step 23221: Loss = 0.4509073495864868\n",
            "Epoch 3, Step 23222: Loss = 0.4944131374359131\n",
            "Epoch 3, Step 23223: Loss = 0.5833489894866943\n",
            "Epoch 3, Step 23224: Loss = 0.27828243374824524\n",
            "Epoch 3, Step 23225: Loss = 0.43482550978660583\n",
            "Epoch 3, Step 23226: Loss = 0.3129526674747467\n",
            "Epoch 3, Step 23227: Loss = 0.4772367477416992\n",
            "Epoch 3, Step 23228: Loss = 0.2676081359386444\n",
            "Epoch 3, Step 23229: Loss = 0.21259227395057678\n",
            "Epoch 3, Step 23230: Loss = 0.2775854766368866\n",
            "Epoch 3, Step 23231: Loss = 0.25761955976486206\n",
            "Epoch 3, Step 23232: Loss = 0.2982802093029022\n",
            "Epoch 3, Step 23233: Loss = 0.3360336124897003\n",
            "Epoch 3, Step 23234: Loss = 0.3254129886627197\n",
            "Epoch 3, Step 23235: Loss = 0.3278529644012451\n",
            "Epoch 3, Step 23236: Loss = 0.28997713327407837\n",
            "Epoch 3, Step 23237: Loss = 0.4255255460739136\n",
            "Epoch 3, Step 23238: Loss = 0.43178194761276245\n",
            "Epoch 3, Step 23239: Loss = 0.5979007482528687\n",
            "Epoch 3, Step 23240: Loss = 0.3140600621700287\n",
            "Epoch 3, Step 23241: Loss = 0.28906145691871643\n",
            "Epoch 3, Step 23242: Loss = 0.23035018146038055\n",
            "Epoch 3, Step 23243: Loss = 0.31865450739860535\n",
            "Epoch 3, Step 23244: Loss = 0.20979253947734833\n",
            "Epoch 3, Step 23245: Loss = 0.24792791903018951\n",
            "Epoch 3, Step 23246: Loss = 0.37882035970687866\n",
            "Epoch 3, Step 23247: Loss = 0.4059714078903198\n",
            "Epoch 3, Step 23248: Loss = 0.5351040363311768\n",
            "Epoch 3, Step 23249: Loss = 0.3558349311351776\n",
            "Epoch 3, Step 23250: Loss = 0.6036440134048462\n",
            "Epoch 3, Step 23251: Loss = 0.18842773139476776\n",
            "Epoch 3, Step 23252: Loss = 0.6134087443351746\n",
            "Epoch 3, Step 23253: Loss = 0.204920694231987\n",
            "Epoch 3, Step 23254: Loss = 0.207542285323143\n",
            "Epoch 3, Step 23255: Loss = 0.22022096812725067\n",
            "Epoch 3, Step 23256: Loss = 0.3189743161201477\n",
            "Epoch 3, Step 23257: Loss = 0.5046932101249695\n",
            "Epoch 3, Step 23258: Loss = 0.40838101506233215\n",
            "Epoch 3, Step 23259: Loss = 0.5633959770202637\n",
            "Epoch 3, Step 23260: Loss = 0.3216326832771301\n",
            "Epoch 3, Step 23261: Loss = 0.3116549253463745\n",
            "Epoch 3, Step 23262: Loss = 0.2616007328033447\n",
            "Epoch 3, Step 23263: Loss = 0.35301750898361206\n",
            "Epoch 3, Step 23264: Loss = 0.4494900405406952\n",
            "Epoch 3, Step 23265: Loss = 0.3132396340370178\n",
            "Epoch 3, Step 23266: Loss = 0.2938258647918701\n",
            "Epoch 3, Step 23267: Loss = 0.29136398434638977\n",
            "Epoch 3, Step 23268: Loss = 0.19621917605400085\n",
            "Epoch 3, Step 23269: Loss = 0.44826850295066833\n",
            "Epoch 3, Step 23270: Loss = 0.24006137251853943\n",
            "Epoch 3, Step 23271: Loss = 0.26688385009765625\n",
            "Epoch 3, Step 23272: Loss = 0.3795425295829773\n",
            "Epoch 3, Step 23273: Loss = 0.20521968603134155\n",
            "Epoch 3, Step 23274: Loss = 0.14894302189350128\n",
            "Epoch 3, Step 23275: Loss = 0.39499881863594055\n",
            "Epoch 3, Step 23276: Loss = 0.38700351119041443\n",
            "Epoch 3, Step 23277: Loss = 0.29830703139305115\n",
            "Epoch 3, Step 23278: Loss = 0.4560236930847168\n",
            "Epoch 3, Step 23279: Loss = 0.4775938391685486\n",
            "Epoch 3, Step 23280: Loss = 0.29078078269958496\n",
            "Epoch 3, Step 23281: Loss = 0.26758962869644165\n",
            "Epoch 3, Step 23282: Loss = 0.2708306312561035\n",
            "Epoch 3, Step 23283: Loss = 0.27351605892181396\n",
            "Epoch 3, Step 23284: Loss = 0.22747166454792023\n",
            "Epoch 3, Step 23285: Loss = 0.27362844347953796\n",
            "Epoch 3, Step 23286: Loss = 0.29407742619514465\n",
            "Epoch 3, Step 23287: Loss = 0.43706879019737244\n",
            "Epoch 3, Step 23288: Loss = 0.24272018671035767\n",
            "Epoch 3, Step 23289: Loss = 0.330558717250824\n",
            "Epoch 3, Step 23290: Loss = 0.26260122656822205\n",
            "Epoch 3, Step 23291: Loss = 0.30878451466560364\n",
            "Epoch 3, Step 23292: Loss = 0.3894302546977997\n",
            "Epoch 3, Step 23293: Loss = 0.20186685025691986\n",
            "Epoch 3, Step 23294: Loss = 0.19187907874584198\n",
            "Epoch 3, Step 23295: Loss = 0.27127641439437866\n",
            "Epoch 3, Step 23296: Loss = 0.357120543718338\n",
            "Epoch 3, Step 23297: Loss = 0.2278110682964325\n",
            "Epoch 3, Step 23298: Loss = 0.2873934507369995\n",
            "Epoch 3, Step 23299: Loss = 0.2931528389453888\n",
            "Epoch 3, Step 23300: Loss = 0.2950645089149475\n",
            "Epoch 3, Step 23301: Loss = 0.4743838906288147\n",
            "Epoch 3, Step 23302: Loss = 0.2845474183559418\n",
            "Epoch 3, Step 23303: Loss = 0.33601778745651245\n",
            "Epoch 3, Step 23304: Loss = 0.5455142855644226\n",
            "Epoch 3, Step 23305: Loss = 0.7591279745101929\n",
            "Epoch 3, Step 23306: Loss = 0.29196980595588684\n",
            "Epoch 3, Step 23307: Loss = 0.15380412340164185\n",
            "Epoch 3, Step 23308: Loss = 0.3623352348804474\n",
            "Epoch 3, Step 23309: Loss = 0.2582401931285858\n",
            "Epoch 3, Step 23310: Loss = 0.3155952990055084\n",
            "Epoch 3, Step 23311: Loss = 0.20387698709964752\n",
            "Epoch 3, Step 23312: Loss = 0.2422640174627304\n",
            "Epoch 3, Step 23313: Loss = 0.5272358655929565\n",
            "Epoch 3, Step 23314: Loss = 0.25760799646377563\n",
            "Epoch 3, Step 23315: Loss = 0.3540131449699402\n",
            "Epoch 3, Step 23316: Loss = 0.34768813848495483\n",
            "Epoch 3, Step 23317: Loss = 0.2808205485343933\n",
            "Epoch 3, Step 23318: Loss = 0.34398436546325684\n",
            "Epoch 3, Step 23319: Loss = 0.37136417627334595\n",
            "Epoch 3, Step 23320: Loss = 0.17923954129219055\n",
            "Epoch 3, Step 23321: Loss = 0.29016244411468506\n",
            "Epoch 3, Step 23322: Loss = 0.29238808155059814\n",
            "Epoch 3, Step 23323: Loss = 0.1774379312992096\n",
            "Epoch 3, Step 23324: Loss = 0.17196930944919586\n",
            "Epoch 3, Step 23325: Loss = 0.38580143451690674\n",
            "Epoch 3, Step 23326: Loss = 0.34939292073249817\n",
            "Epoch 3, Step 23327: Loss = 0.29070621728897095\n",
            "Epoch 3, Step 23328: Loss = 0.17598854005336761\n",
            "Epoch 3, Step 23329: Loss = 0.22939495742321014\n",
            "Epoch 3, Step 23330: Loss = 0.30673709511756897\n",
            "Epoch 3, Step 23331: Loss = 0.26857274770736694\n",
            "Epoch 3, Step 23332: Loss = 0.45415717363357544\n",
            "Epoch 3, Step 23333: Loss = 0.3275538980960846\n",
            "Epoch 3, Step 23334: Loss = 0.4890720248222351\n",
            "Epoch 3, Step 23335: Loss = 0.3110570013523102\n",
            "Epoch 3, Step 23336: Loss = 0.24841000139713287\n",
            "Epoch 3, Step 23337: Loss = 0.4974325895309448\n",
            "Epoch 3, Step 23338: Loss = 0.353746622800827\n",
            "Epoch 3, Step 23339: Loss = 0.3306195139884949\n",
            "Epoch 3, Step 23340: Loss = 0.2591512203216553\n",
            "Epoch 3, Step 23341: Loss = 0.3849344849586487\n",
            "Epoch 3, Step 23342: Loss = 0.39212894439697266\n",
            "Epoch 3, Step 23343: Loss = 0.5895159244537354\n",
            "Epoch 3, Step 23344: Loss = 0.20987673103809357\n",
            "Epoch 3, Step 23345: Loss = 0.46442508697509766\n",
            "Epoch 3, Step 23346: Loss = 0.32461032271385193\n",
            "Epoch 3, Step 23347: Loss = 0.20807309448719025\n",
            "Epoch 3, Step 23348: Loss = 0.31266823410987854\n",
            "Epoch 3, Step 23349: Loss = 0.22532474994659424\n",
            "Epoch 3, Step 23350: Loss = 0.1568317860364914\n",
            "Epoch 3, Step 23351: Loss = 0.31778639554977417\n",
            "Epoch 3, Step 23352: Loss = 0.21644176542758942\n",
            "Epoch 3, Step 23353: Loss = 0.3117741346359253\n",
            "Epoch 3, Step 23354: Loss = 0.1721753627061844\n",
            "Epoch 3, Step 23355: Loss = 0.2296735644340515\n",
            "Epoch 3, Step 23356: Loss = 0.2871961295604706\n",
            "Epoch 3, Step 23357: Loss = 0.3534432649612427\n",
            "Epoch 3, Step 23358: Loss = 0.48689571022987366\n",
            "Epoch 3, Step 23359: Loss = 0.23696300387382507\n",
            "Epoch 3, Step 23360: Loss = 0.2494254857301712\n",
            "Epoch 3, Step 23361: Loss = 0.5878070592880249\n",
            "Epoch 3, Step 23362: Loss = 0.5367405414581299\n",
            "Epoch 3, Step 23363: Loss = 0.33467593789100647\n",
            "Epoch 3, Step 23364: Loss = 0.4066476821899414\n",
            "Epoch 3, Step 23365: Loss = 0.39210814237594604\n",
            "Epoch 3, Step 23366: Loss = 0.38097894191741943\n",
            "Epoch 3, Step 23367: Loss = 0.25546586513519287\n",
            "Epoch 3, Step 23368: Loss = 0.2770492434501648\n",
            "Epoch 3, Step 23369: Loss = 0.3218837082386017\n",
            "Epoch 3, Step 23370: Loss = 0.3098737299442291\n",
            "Epoch 3, Step 23371: Loss = 0.34677761793136597\n",
            "Epoch 3, Step 23372: Loss = 0.24963602423667908\n",
            "Epoch 3, Step 23373: Loss = 0.2072867453098297\n",
            "Epoch 3, Step 23374: Loss = 0.3302622437477112\n",
            "Epoch 3, Step 23375: Loss = 0.2880948483943939\n",
            "Epoch 3, Step 23376: Loss = 0.7270896434783936\n",
            "Epoch 3, Step 23377: Loss = 0.553863525390625\n",
            "Epoch 3, Step 23378: Loss = 0.3905599117279053\n",
            "Epoch 3, Step 23379: Loss = 0.30973103642463684\n",
            "Epoch 3, Step 23380: Loss = 0.4453180134296417\n",
            "Epoch 3, Step 23381: Loss = 0.2638229727745056\n",
            "Epoch 3, Step 23382: Loss = 0.4532827138900757\n",
            "Epoch 3, Step 23383: Loss = 0.2927171289920807\n",
            "Epoch 3, Step 23384: Loss = 0.6472766399383545\n",
            "Epoch 3, Step 23385: Loss = 0.31914496421813965\n",
            "Epoch 3, Step 23386: Loss = 0.23254919052124023\n",
            "Epoch 3, Step 23387: Loss = 0.40695443749427795\n",
            "Epoch 3, Step 23388: Loss = 0.30882102251052856\n",
            "Epoch 3, Step 23389: Loss = 0.26365262269973755\n",
            "Epoch 3, Step 23390: Loss = 0.25975269079208374\n",
            "Epoch 3, Step 23391: Loss = 0.23291164636611938\n",
            "Epoch 3, Step 23392: Loss = 0.6936153769493103\n",
            "Epoch 3, Step 23393: Loss = 0.34553012251853943\n",
            "Epoch 3, Step 23394: Loss = 0.3044029772281647\n",
            "Epoch 3, Step 23395: Loss = 0.14563649892807007\n",
            "Epoch 3, Step 23396: Loss = 0.3207397758960724\n",
            "Epoch 3, Step 23397: Loss = 0.3889225125312805\n",
            "Epoch 3, Step 23398: Loss = 0.4128240644931793\n",
            "Epoch 3, Step 23399: Loss = 0.41173237562179565\n",
            "Epoch 3, Step 23400: Loss = 0.3601524829864502\n",
            "Epoch 3, Step 23401: Loss = 0.3601796329021454\n",
            "Epoch 3, Step 23402: Loss = 0.5625214576721191\n",
            "Epoch 3, Step 23403: Loss = 0.4461313486099243\n",
            "Epoch 3, Step 23404: Loss = 0.23258166015148163\n",
            "Epoch 3, Step 23405: Loss = 0.4109874367713928\n",
            "Epoch 3, Step 23406: Loss = 0.2752964496612549\n",
            "Epoch 3, Step 23407: Loss = 0.2419402003288269\n",
            "Epoch 3, Step 23408: Loss = 0.2627764046192169\n",
            "Epoch 3, Step 23409: Loss = 0.20947803556919098\n",
            "Epoch 3, Step 23410: Loss = 0.19108307361602783\n",
            "Epoch 3, Step 23411: Loss = 0.33291855454444885\n",
            "Epoch 3, Step 23412: Loss = 0.2479151338338852\n",
            "Epoch 3, Step 23413: Loss = 0.5246404409408569\n",
            "Epoch 3, Step 23414: Loss = 0.2701807916164398\n",
            "Epoch 3, Step 23415: Loss = 0.6357161998748779\n",
            "Epoch 3, Step 23416: Loss = 0.26447683572769165\n",
            "Epoch 3, Step 23417: Loss = 0.3716025650501251\n",
            "Epoch 3, Step 23418: Loss = 0.2541245222091675\n",
            "Epoch 3, Step 23419: Loss = 0.3167372941970825\n",
            "Epoch 3, Step 23420: Loss = 0.28886473178863525\n",
            "Epoch 3, Step 23421: Loss = 0.354987233877182\n",
            "Epoch 3, Step 23422: Loss = 0.2415926456451416\n",
            "Epoch 3, Step 23423: Loss = 0.14155936241149902\n",
            "Epoch 3, Step 23424: Loss = 0.4341641366481781\n",
            "Epoch 3, Step 23425: Loss = 0.4133724272251129\n",
            "Epoch 3, Step 23426: Loss = 0.2726005017757416\n",
            "Epoch 3, Step 23427: Loss = 0.31414392590522766\n",
            "Epoch 3, Step 23428: Loss = 0.35089871287345886\n",
            "Epoch 3, Step 23429: Loss = 0.5392941236495972\n",
            "Epoch 3, Step 23430: Loss = 0.33177706599235535\n",
            "Epoch 3, Step 23431: Loss = 0.2871863842010498\n",
            "Epoch 3, Step 23432: Loss = 0.2536861002445221\n",
            "Epoch 3, Step 23433: Loss = 0.3285771310329437\n",
            "Epoch 3, Step 23434: Loss = 0.2727886438369751\n",
            "Epoch 3, Step 23435: Loss = 0.2157178521156311\n",
            "Epoch 3, Step 23436: Loss = 0.2582854628562927\n",
            "Epoch 3, Step 23437: Loss = 0.432258665561676\n",
            "Epoch 3, Step 23438: Loss = 0.21928702294826508\n",
            "Epoch 3, Step 23439: Loss = 0.23694032430648804\n",
            "Epoch 3, Step 23440: Loss = 0.5017613172531128\n",
            "Epoch 3, Step 23441: Loss = 0.3516632914543152\n",
            "Epoch 3, Step 23442: Loss = 0.3131091296672821\n",
            "Epoch 3, Step 23443: Loss = 0.36669960618019104\n",
            "Epoch 3, Step 23444: Loss = 0.35348498821258545\n",
            "Epoch 3, Step 23445: Loss = 0.391338586807251\n",
            "Epoch 3, Step 23446: Loss = 0.4932772219181061\n",
            "Epoch 3, Step 23447: Loss = 0.18015961349010468\n",
            "Epoch 3, Step 23448: Loss = 0.3326053321361542\n",
            "Epoch 3, Step 23449: Loss = 0.35014787316322327\n",
            "Epoch 3, Step 23450: Loss = 0.25477033853530884\n",
            "Epoch 3, Step 23451: Loss = 0.3675778806209564\n",
            "Epoch 3, Step 23452: Loss = 0.27584975957870483\n",
            "Epoch 3, Step 23453: Loss = 0.20372991263866425\n",
            "Epoch 3, Step 23454: Loss = 0.46460604667663574\n",
            "Epoch 3, Step 23455: Loss = 0.23308567702770233\n",
            "Epoch 3, Step 23456: Loss = 0.33385828137397766\n",
            "Epoch 3, Step 23457: Loss = 0.20201964676380157\n",
            "Epoch 3, Step 23458: Loss = 0.5194070339202881\n",
            "Epoch 3, Step 23459: Loss = 0.26477766036987305\n",
            "Epoch 3, Step 23460: Loss = 0.23843219876289368\n",
            "Epoch 3, Step 23461: Loss = 0.38154569268226624\n",
            "Epoch 3, Step 23462: Loss = 0.3487664461135864\n",
            "Epoch 3, Step 23463: Loss = 0.2271432727575302\n",
            "Epoch 3, Step 23464: Loss = 0.2290176898241043\n",
            "Epoch 3, Step 23465: Loss = 0.25228047370910645\n",
            "Epoch 3, Step 23466: Loss = 0.19364044070243835\n",
            "Epoch 3, Step 23467: Loss = 0.3094610273838043\n",
            "Epoch 3, Step 23468: Loss = 0.4102886915206909\n",
            "Epoch 3, Step 23469: Loss = 0.6184386014938354\n",
            "Epoch 3, Step 23470: Loss = 0.224081352353096\n",
            "Epoch 3, Step 23471: Loss = 0.2337592989206314\n",
            "Epoch 3, Step 23472: Loss = 0.20356985926628113\n",
            "Epoch 3, Step 23473: Loss = 0.2920631468296051\n",
            "Epoch 3, Step 23474: Loss = 0.3786369562149048\n",
            "Epoch 3, Step 23475: Loss = 0.3274119794368744\n",
            "Epoch 3, Step 23476: Loss = 0.49641215801239014\n",
            "Epoch 3, Step 23477: Loss = 0.2891082465648651\n",
            "Epoch 3, Step 23478: Loss = 0.3106430470943451\n",
            "Epoch 3, Step 23479: Loss = 0.23520682752132416\n",
            "Epoch 3, Step 23480: Loss = 0.43609267473220825\n",
            "Epoch 3, Step 23481: Loss = 0.1927311271429062\n",
            "Epoch 3, Step 23482: Loss = 0.2295529842376709\n",
            "Epoch 3, Step 23483: Loss = 0.4301537871360779\n",
            "Epoch 3, Step 23484: Loss = 0.4326399564743042\n",
            "Epoch 3, Step 23485: Loss = 0.5034186244010925\n",
            "Epoch 3, Step 23486: Loss = 0.4460267424583435\n",
            "Epoch 3, Step 23487: Loss = 0.3732185959815979\n",
            "Epoch 3, Step 23488: Loss = 0.2966558337211609\n",
            "Epoch 3, Step 23489: Loss = 0.2687256336212158\n",
            "Epoch 3, Step 23490: Loss = 0.25422653555870056\n",
            "Epoch 3, Step 23491: Loss = 0.24601225554943085\n",
            "Epoch 3, Step 23492: Loss = 0.22634802758693695\n",
            "Epoch 3, Step 23493: Loss = 0.5779498815536499\n",
            "Epoch 3, Step 23494: Loss = 0.3756132125854492\n",
            "Epoch 3, Step 23495: Loss = 0.4255904257297516\n",
            "Epoch 3, Step 23496: Loss = 0.3343539834022522\n",
            "Epoch 3, Step 23497: Loss = 0.32229083776474\n",
            "Epoch 3, Step 23498: Loss = 0.3565680980682373\n",
            "Epoch 3, Step 23499: Loss = 0.2231384962797165\n",
            "Epoch 3, Step 23500: Loss = 0.26988455653190613\n",
            "Epoch 3, Step 23501: Loss = 0.39744287729263306\n",
            "Epoch 3, Step 23502: Loss = 0.2011677473783493\n",
            "Epoch 3, Step 23503: Loss = 0.2152397483587265\n",
            "Epoch 3, Step 23504: Loss = 0.152888223528862\n",
            "Epoch 3, Step 23505: Loss = 0.4493313431739807\n",
            "Epoch 3, Step 23506: Loss = 0.3012761175632477\n",
            "Epoch 3, Step 23507: Loss = 0.15787306427955627\n",
            "Epoch 3, Step 23508: Loss = 0.542436957359314\n",
            "Epoch 3, Step 23509: Loss = 0.2985067069530487\n",
            "Epoch 3, Step 23510: Loss = 0.3040417730808258\n",
            "Epoch 3, Step 23511: Loss = 0.28031685948371887\n",
            "Epoch 3, Step 23512: Loss = 0.15767021477222443\n",
            "Epoch 3, Step 23513: Loss = 0.27262380719184875\n",
            "Epoch 3, Step 23514: Loss = 0.28141072392463684\n",
            "Epoch 3, Step 23515: Loss = 0.41998979449272156\n",
            "Epoch 3, Step 23516: Loss = 0.3424132168292999\n",
            "Epoch 3, Step 23517: Loss = 0.24252234399318695\n",
            "Epoch 3, Step 23518: Loss = 0.49314093589782715\n",
            "Epoch 3, Step 23519: Loss = 0.5045867562294006\n",
            "Epoch 3, Step 23520: Loss = 0.37036046385765076\n",
            "Epoch 3, Step 23521: Loss = 0.30010560154914856\n",
            "Epoch 3, Step 23522: Loss = 0.3989289104938507\n",
            "Epoch 3, Step 23523: Loss = 0.23699411749839783\n",
            "Epoch 3, Step 23524: Loss = 0.28014373779296875\n",
            "Epoch 3, Step 23525: Loss = 0.28529030084609985\n",
            "Epoch 3, Step 23526: Loss = 0.39798492193222046\n",
            "Epoch 3, Step 23527: Loss = 0.2979781925678253\n",
            "Epoch 3, Step 23528: Loss = 0.4424365162849426\n",
            "Epoch 3, Step 23529: Loss = 0.617983877658844\n",
            "Epoch 3, Step 23530: Loss = 0.14831489324569702\n",
            "Epoch 3, Step 23531: Loss = 0.23555901646614075\n",
            "Epoch 3, Step 23532: Loss = 0.358812540769577\n",
            "Epoch 3, Step 23533: Loss = 0.2561893165111542\n",
            "Epoch 3, Step 23534: Loss = 0.7236441969871521\n",
            "Epoch 3, Step 23535: Loss = 0.31725791096687317\n",
            "Epoch 3, Step 23536: Loss = 0.21225300431251526\n",
            "Epoch 3, Step 23537: Loss = 0.24832533299922943\n",
            "Epoch 3, Step 23538: Loss = 0.23344244062900543\n",
            "Epoch 3, Step 23539: Loss = 0.3919834494590759\n",
            "Epoch 3, Step 23540: Loss = 0.3877614736557007\n",
            "Epoch 3, Step 23541: Loss = 0.19348014891147614\n",
            "Epoch 3, Step 23542: Loss = 0.2985355257987976\n",
            "Epoch 3, Step 23543: Loss = 0.3390243947505951\n",
            "Epoch 3, Step 23544: Loss = 0.23291079699993134\n",
            "Epoch 3, Step 23545: Loss = 0.38135117292404175\n",
            "Epoch 3, Step 23546: Loss = 0.25780344009399414\n",
            "Epoch 3, Step 23547: Loss = 0.22325760126113892\n",
            "Epoch 3, Step 23548: Loss = 0.5478718876838684\n",
            "Epoch 3, Step 23549: Loss = 0.6017995476722717\n",
            "Epoch 3, Step 23550: Loss = 0.1953042894601822\n",
            "Epoch 3, Step 23551: Loss = 0.2586389183998108\n",
            "Epoch 3, Step 23552: Loss = 0.17567512392997742\n",
            "Epoch 3, Step 23553: Loss = 0.20140311121940613\n",
            "Epoch 3, Step 23554: Loss = 0.31767910718917847\n",
            "Epoch 3, Step 23555: Loss = 0.5140889286994934\n",
            "Epoch 3, Step 23556: Loss = 0.3460146486759186\n",
            "Epoch 3, Step 23557: Loss = 0.1967151165008545\n",
            "Epoch 3, Step 23558: Loss = 0.208197683095932\n",
            "Epoch 3, Step 23559: Loss = 0.40728139877319336\n",
            "Epoch 3, Step 23560: Loss = 0.4594075679779053\n",
            "Epoch 3, Step 23561: Loss = 0.3931766152381897\n",
            "Epoch 3, Step 23562: Loss = 0.33891385793685913\n",
            "Epoch 3, Step 23563: Loss = 0.3102174699306488\n",
            "Epoch 3, Step 23564: Loss = 0.3466469347476959\n",
            "Epoch 3, Step 23565: Loss = 0.3795679807662964\n",
            "Epoch 3, Step 23566: Loss = 0.4706993103027344\n",
            "Epoch 3, Step 23567: Loss = 0.2174546718597412\n",
            "Epoch 3, Step 23568: Loss = 0.2934136986732483\n",
            "Epoch 3, Step 23569: Loss = 0.27732184529304504\n",
            "Epoch 3, Step 23570: Loss = 0.4008081555366516\n",
            "Epoch 3, Step 23571: Loss = 0.4708895981311798\n",
            "Epoch 3, Step 23572: Loss = 0.20370624959468842\n",
            "Epoch 3, Step 23573: Loss = 0.28407585620880127\n",
            "Epoch 3, Step 23574: Loss = 0.4317604899406433\n",
            "Epoch 3, Step 23575: Loss = 0.3741929233074188\n",
            "Epoch 3, Step 23576: Loss = 0.3803445100784302\n",
            "Epoch 3, Step 23577: Loss = 0.20359109342098236\n",
            "Epoch 3, Step 23578: Loss = 0.2604297995567322\n",
            "Epoch 3, Step 23579: Loss = 0.30082884430885315\n",
            "Epoch 3, Step 23580: Loss = 0.7244948148727417\n",
            "Epoch 3, Step 23581: Loss = 0.3637021780014038\n",
            "Epoch 3, Step 23582: Loss = 0.2507433295249939\n",
            "Epoch 3, Step 23583: Loss = 0.274076372385025\n",
            "Epoch 3, Step 23584: Loss = 0.503875195980072\n",
            "Epoch 3, Step 23585: Loss = 0.28524720668792725\n",
            "Epoch 3, Step 23586: Loss = 0.20284348726272583\n",
            "Epoch 3, Step 23587: Loss = 0.36593371629714966\n",
            "Epoch 3, Step 23588: Loss = 0.25027674436569214\n",
            "Epoch 3, Step 23589: Loss = 0.24658848345279694\n",
            "Epoch 3, Step 23590: Loss = 0.21258696913719177\n",
            "Epoch 3, Step 23591: Loss = 0.383424311876297\n",
            "Epoch 3, Step 23592: Loss = 0.23866857588291168\n",
            "Epoch 3, Step 23593: Loss = 0.20601795613765717\n",
            "Epoch 3, Step 23594: Loss = 0.5207292437553406\n",
            "Epoch 3, Step 23595: Loss = 0.2827991545200348\n",
            "Epoch 3, Step 23596: Loss = 0.44866320490837097\n",
            "Epoch 3, Step 23597: Loss = 0.3325359523296356\n",
            "Epoch 3, Step 23598: Loss = 0.3401716351509094\n",
            "Epoch 3, Step 23599: Loss = 0.1613992303609848\n",
            "Epoch 3, Step 23600: Loss = 0.4385647475719452\n",
            "Epoch 3, Step 23601: Loss = 0.5203459858894348\n",
            "Epoch 3, Step 23602: Loss = 0.2170218974351883\n",
            "Epoch 3, Step 23603: Loss = 0.3143865168094635\n",
            "Epoch 3, Step 23604: Loss = 0.4044547975063324\n",
            "Epoch 3, Step 23605: Loss = 0.2903159260749817\n",
            "Epoch 3, Step 23606: Loss = 0.3290783166885376\n",
            "Epoch 3, Step 23607: Loss = 0.2925476133823395\n",
            "Epoch 3, Step 23608: Loss = 0.46407026052474976\n",
            "Epoch 3, Step 23609: Loss = 0.5472527146339417\n",
            "Epoch 3, Step 23610: Loss = 0.32783129811286926\n",
            "Epoch 3, Step 23611: Loss = 0.3650180697441101\n",
            "Epoch 3, Step 23612: Loss = 0.2756635546684265\n",
            "Epoch 3, Step 23613: Loss = 0.2841205894947052\n",
            "Epoch 3, Step 23614: Loss = 0.3568231463432312\n",
            "Epoch 3, Step 23615: Loss = 0.5339970588684082\n",
            "Epoch 3, Step 23616: Loss = 0.23465070128440857\n",
            "Epoch 3, Step 23617: Loss = 0.2989596128463745\n",
            "Epoch 3, Step 23618: Loss = 0.31092214584350586\n",
            "Epoch 3, Step 23619: Loss = 0.3001854419708252\n",
            "Epoch 3, Step 23620: Loss = 0.4393918514251709\n",
            "Epoch 3, Step 23621: Loss = 0.2245589792728424\n",
            "Epoch 3, Step 23622: Loss = 0.19966340065002441\n",
            "Epoch 3, Step 23623: Loss = 0.3594035804271698\n",
            "Epoch 3, Step 23624: Loss = 0.35069799423217773\n",
            "Epoch 3, Step 23625: Loss = 0.33783507347106934\n",
            "Epoch 3, Step 23626: Loss = 0.3869035542011261\n",
            "Epoch 3, Step 23627: Loss = 0.3771626651287079\n",
            "Epoch 3, Step 23628: Loss = 0.23665951192378998\n",
            "Epoch 3, Step 23629: Loss = 0.2630577087402344\n",
            "Epoch 3, Step 23630: Loss = 0.16239702701568604\n",
            "Epoch 3, Step 23631: Loss = 0.5928820967674255\n",
            "Epoch 3, Step 23632: Loss = 0.2679814100265503\n",
            "Epoch 3, Step 23633: Loss = 0.4226055443286896\n",
            "Epoch 3, Step 23634: Loss = 0.4251798093318939\n",
            "Epoch 3, Step 23635: Loss = 0.22781208157539368\n",
            "Epoch 3, Step 23636: Loss = 0.18847550451755524\n",
            "Epoch 3, Step 23637: Loss = 0.43627285957336426\n",
            "Epoch 3, Step 23638: Loss = 0.2670726776123047\n",
            "Epoch 3, Step 23639: Loss = 0.345076322555542\n",
            "Epoch 3, Step 23640: Loss = 0.27108335494995117\n",
            "Epoch 3, Step 23641: Loss = 0.3222261071205139\n",
            "Epoch 3, Step 23642: Loss = 0.3605755865573883\n",
            "Epoch 3, Step 23643: Loss = 0.3859756290912628\n",
            "Epoch 3, Step 23644: Loss = 0.33662837743759155\n",
            "Epoch 3, Step 23645: Loss = 0.22264891862869263\n",
            "Epoch 3, Step 23646: Loss = 0.2997818887233734\n",
            "Epoch 3, Step 23647: Loss = 0.3473376929759979\n",
            "Epoch 3, Step 23648: Loss = 0.3049543797969818\n",
            "Epoch 3, Step 23649: Loss = 0.3278094530105591\n",
            "Epoch 3, Step 23650: Loss = 0.5334985256195068\n",
            "Epoch 3, Step 23651: Loss = 0.3179592490196228\n",
            "Epoch 3, Step 23652: Loss = 0.5307215452194214\n",
            "Epoch 3, Step 23653: Loss = 0.529727041721344\n",
            "Epoch 3, Step 23654: Loss = 0.21869009733200073\n",
            "Epoch 3, Step 23655: Loss = 0.44959601759910583\n",
            "Epoch 3, Step 23656: Loss = 0.4058118462562561\n",
            "Epoch 3, Step 23657: Loss = 0.4266526699066162\n",
            "Epoch 3, Step 23658: Loss = 0.3880528509616852\n",
            "Epoch 3, Step 23659: Loss = 0.15844979882240295\n",
            "Epoch 3, Step 23660: Loss = 0.2709408700466156\n",
            "Epoch 3, Step 23661: Loss = 0.3351341187953949\n",
            "Epoch 3, Step 23662: Loss = 0.26951247453689575\n",
            "Epoch 3, Step 23663: Loss = 0.24044358730316162\n",
            "Epoch 3, Step 23664: Loss = 0.30063676834106445\n",
            "Epoch 3, Step 23665: Loss = 0.298957496881485\n",
            "Epoch 3, Step 23666: Loss = 0.3003957271575928\n",
            "Epoch 3, Step 23667: Loss = 0.42911264300346375\n",
            "Epoch 3, Step 23668: Loss = 0.21721336245536804\n",
            "Epoch 3, Step 23669: Loss = 0.4827287793159485\n",
            "Epoch 3, Step 23670: Loss = 0.392971009016037\n",
            "Epoch 3, Step 23671: Loss = 0.35454437136650085\n",
            "Epoch 3, Step 23672: Loss = 0.27399370074272156\n",
            "Epoch 3, Step 23673: Loss = 0.41962969303131104\n",
            "Epoch 3, Step 23674: Loss = 0.31340092420578003\n",
            "Epoch 3, Step 23675: Loss = 0.27461084723472595\n",
            "Epoch 3, Step 23676: Loss = 0.17781256139278412\n",
            "Epoch 3, Step 23677: Loss = 0.2187788039445877\n",
            "Epoch 3, Step 23678: Loss = 0.4435230493545532\n",
            "Epoch 3, Step 23679: Loss = 0.35234349966049194\n",
            "Epoch 3, Step 23680: Loss = 0.3256666660308838\n",
            "Epoch 3, Step 23681: Loss = 0.2777353525161743\n",
            "Epoch 3, Step 23682: Loss = 0.4547639489173889\n",
            "Epoch 3, Step 23683: Loss = 0.24694810807704926\n",
            "Epoch 3, Step 23684: Loss = 0.3081666827201843\n",
            "Epoch 3, Step 23685: Loss = 0.34441328048706055\n",
            "Epoch 3, Step 23686: Loss = 0.1602814495563507\n",
            "Epoch 3, Step 23687: Loss = 0.2373758852481842\n",
            "Epoch 3, Step 23688: Loss = 0.28236907720565796\n",
            "Epoch 3, Step 23689: Loss = 0.3815949261188507\n",
            "Epoch 3, Step 23690: Loss = 0.4980655610561371\n",
            "Epoch 3, Step 23691: Loss = 0.3936876952648163\n",
            "Epoch 3, Step 23692: Loss = 0.32592400908470154\n",
            "Epoch 3, Step 23693: Loss = 0.24552816152572632\n",
            "Epoch 3, Step 23694: Loss = 0.44308245182037354\n",
            "Epoch 3, Step 23695: Loss = 0.33504927158355713\n",
            "Epoch 3, Step 23696: Loss = 0.313125342130661\n",
            "Epoch 3, Step 23697: Loss = 0.4593636989593506\n",
            "Epoch 3, Step 23698: Loss = 0.3521600365638733\n",
            "Epoch 3, Step 23699: Loss = 0.2312384992837906\n",
            "Epoch 3, Step 23700: Loss = 0.3214622735977173\n",
            "Epoch 3, Step 23701: Loss = 0.36636874079704285\n",
            "Epoch 3, Step 23702: Loss = 0.3652486801147461\n",
            "Epoch 3, Step 23703: Loss = 0.3526567220687866\n",
            "Epoch 3, Step 23704: Loss = 0.32740724086761475\n",
            "Epoch 3, Step 23705: Loss = 0.36749809980392456\n",
            "Epoch 3, Step 23706: Loss = 0.29463568329811096\n",
            "Epoch 3, Step 23707: Loss = 0.5090510845184326\n",
            "Epoch 3, Step 23708: Loss = 0.1845749020576477\n",
            "Epoch 3, Step 23709: Loss = 0.4163903295993805\n",
            "Epoch 3, Step 23710: Loss = 0.26267722249031067\n",
            "Epoch 3, Step 23711: Loss = 0.40627768635749817\n",
            "Epoch 3, Step 23712: Loss = 0.26495060324668884\n",
            "Epoch 3, Step 23713: Loss = 0.3158799707889557\n",
            "Epoch 3, Step 23714: Loss = 0.5222399234771729\n",
            "Epoch 3, Step 23715: Loss = 0.35337120294570923\n",
            "Epoch 3, Step 23716: Loss = 0.4475351572036743\n",
            "Epoch 3, Step 23717: Loss = 0.3231337368488312\n",
            "Epoch 3, Step 23718: Loss = 0.21417741477489471\n",
            "Epoch 3, Step 23719: Loss = 0.2336084544658661\n",
            "Epoch 3, Step 23720: Loss = 0.39894789457321167\n",
            "Epoch 3, Step 23721: Loss = 0.32737261056900024\n",
            "Epoch 3, Step 23722: Loss = 0.44347214698791504\n",
            "Epoch 3, Step 23723: Loss = 0.48934406042099\n",
            "Epoch 3, Step 23724: Loss = 0.45671379566192627\n",
            "Epoch 3, Step 23725: Loss = 0.25771164894104004\n",
            "Epoch 3, Step 23726: Loss = 0.19268928468227386\n",
            "Epoch 3, Step 23727: Loss = 0.3344617486000061\n",
            "Epoch 3, Step 23728: Loss = 0.4249183237552643\n",
            "Epoch 3, Step 23729: Loss = 0.3155370354652405\n",
            "Epoch 3, Step 23730: Loss = 0.29011082649230957\n",
            "Epoch 3, Step 23731: Loss = 0.22619403898715973\n",
            "Epoch 3, Step 23732: Loss = 0.5764379501342773\n",
            "Epoch 3, Step 23733: Loss = 0.4924416244029999\n",
            "Epoch 3, Step 23734: Loss = 0.27663224935531616\n",
            "Epoch 3, Step 23735: Loss = 0.30334892868995667\n",
            "Epoch 3, Step 23736: Loss = 0.27543336153030396\n",
            "Epoch 3, Step 23737: Loss = 0.3509729504585266\n",
            "Epoch 3, Step 23738: Loss = 0.3624347448348999\n",
            "Epoch 3, Step 23739: Loss = 0.40008625388145447\n",
            "Epoch 3, Step 23740: Loss = 0.2032669633626938\n",
            "Epoch 3, Step 23741: Loss = 0.4256975054740906\n",
            "Epoch 3, Step 23742: Loss = 0.32792729139328003\n",
            "Epoch 3, Step 23743: Loss = 0.44023585319519043\n",
            "Epoch 3, Step 23744: Loss = 0.26257118582725525\n",
            "Epoch 3, Step 23745: Loss = 0.3377832770347595\n",
            "Epoch 3, Step 23746: Loss = 0.12949848175048828\n",
            "Epoch 3, Step 23747: Loss = 0.2625386118888855\n",
            "Epoch 3, Step 23748: Loss = 0.3129623830318451\n",
            "Epoch 3, Step 23749: Loss = 0.17558464407920837\n",
            "Epoch 3, Step 23750: Loss = 0.3921225965023041\n",
            "Epoch 3, Step 23751: Loss = 0.46726086735725403\n",
            "Epoch 3, Step 23752: Loss = 0.36690959334373474\n",
            "Epoch 3, Step 23753: Loss = 0.2325020581483841\n",
            "Epoch 3, Step 23754: Loss = 0.3286970853805542\n",
            "Epoch 3, Step 23755: Loss = 0.3123159110546112\n",
            "Epoch 3, Step 23756: Loss = 0.19843144714832306\n",
            "Epoch 3, Step 23757: Loss = 0.1343948394060135\n",
            "Epoch 3, Step 23758: Loss = 0.4251474142074585\n",
            "Epoch 3, Step 23759: Loss = 0.2178649753332138\n",
            "Epoch 3, Step 23760: Loss = 0.3680284321308136\n",
            "Epoch 3, Step 23761: Loss = 0.13902577757835388\n",
            "Epoch 3, Step 23762: Loss = 0.5877389311790466\n",
            "Epoch 3, Step 23763: Loss = 0.3272653818130493\n",
            "Epoch 3, Step 23764: Loss = 0.30142050981521606\n",
            "Epoch 3, Step 23765: Loss = 0.18348437547683716\n",
            "Epoch 3, Step 23766: Loss = 0.31952643394470215\n",
            "Epoch 3, Step 23767: Loss = 0.2275424301624298\n",
            "Epoch 3, Step 23768: Loss = 0.35696667432785034\n",
            "Epoch 3, Step 23769: Loss = 0.6261926889419556\n",
            "Epoch 3, Step 23770: Loss = 0.4751608371734619\n",
            "Epoch 3, Step 23771: Loss = 0.39824482798576355\n",
            "Epoch 3, Step 23772: Loss = 0.2773457467556\n",
            "Epoch 3, Step 23773: Loss = 0.22040458023548126\n",
            "Epoch 3, Step 23774: Loss = 0.21960975229740143\n",
            "Epoch 3, Step 23775: Loss = 0.327869176864624\n",
            "Epoch 3, Step 23776: Loss = 0.21547824144363403\n",
            "Epoch 3, Step 23777: Loss = 0.7028706073760986\n",
            "Epoch 3, Step 23778: Loss = 0.36652588844299316\n",
            "Epoch 3, Step 23779: Loss = 0.231750026345253\n",
            "Epoch 3, Step 23780: Loss = 0.43960532546043396\n",
            "Epoch 3, Step 23781: Loss = 0.24146796762943268\n",
            "Epoch 3, Step 23782: Loss = 0.2559993863105774\n",
            "Epoch 3, Step 23783: Loss = 0.2809227406978607\n",
            "Epoch 3, Step 23784: Loss = 0.33702588081359863\n",
            "Epoch 3, Step 23785: Loss = 0.23968800902366638\n",
            "Epoch 3, Step 23786: Loss = 0.21322014927864075\n",
            "Epoch 3, Step 23787: Loss = 0.25631335377693176\n",
            "Epoch 3, Step 23788: Loss = 0.2511278986930847\n",
            "Epoch 3, Step 23789: Loss = 0.17184871435165405\n",
            "Epoch 3, Step 23790: Loss = 0.4617172181606293\n",
            "Epoch 3, Step 23791: Loss = 0.4144551157951355\n",
            "Epoch 3, Step 23792: Loss = 0.33310115337371826\n",
            "Epoch 3, Step 23793: Loss = 0.35194501280784607\n",
            "Epoch 3, Step 23794: Loss = 0.24371835589408875\n",
            "Epoch 3, Step 23795: Loss = 0.2768019139766693\n",
            "Epoch 3, Step 23796: Loss = 0.5671573281288147\n",
            "Epoch 3, Step 23797: Loss = 0.28663021326065063\n",
            "Epoch 3, Step 23798: Loss = 0.3167298436164856\n",
            "Epoch 3, Step 23799: Loss = 0.24217325448989868\n",
            "Epoch 3, Step 23800: Loss = 0.498650461435318\n",
            "Epoch 3, Step 23801: Loss = 0.33828601241111755\n",
            "Epoch 3, Step 23802: Loss = 0.27761417627334595\n",
            "Epoch 3, Step 23803: Loss = 0.21700219810009003\n",
            "Epoch 3, Step 23804: Loss = 0.3097933828830719\n",
            "Epoch 3, Step 23805: Loss = 0.36530718207359314\n",
            "Epoch 3, Step 23806: Loss = 0.38243141770362854\n",
            "Epoch 3, Step 23807: Loss = 0.35379642248153687\n",
            "Epoch 3, Step 23808: Loss = 0.28996631503105164\n",
            "Epoch 3, Step 23809: Loss = 0.23308277130126953\n",
            "Epoch 3, Step 23810: Loss = 0.340896874666214\n",
            "Epoch 3, Step 23811: Loss = 0.3958881199359894\n",
            "Epoch 3, Step 23812: Loss = 0.3578220307826996\n",
            "Epoch 3, Step 23813: Loss = 0.28171664476394653\n",
            "Epoch 3, Step 23814: Loss = 0.297075092792511\n",
            "Epoch 3, Step 23815: Loss = 0.5084332227706909\n",
            "Epoch 3, Step 23816: Loss = 0.2868936061859131\n",
            "Epoch 3, Step 23817: Loss = 0.23338745534420013\n",
            "Epoch 3, Step 23818: Loss = 0.1900644451379776\n",
            "Epoch 3, Step 23819: Loss = 0.3180350065231323\n",
            "Epoch 3, Step 23820: Loss = 0.2591364085674286\n",
            "Epoch 3, Step 23821: Loss = 0.5295009613037109\n",
            "Epoch 3, Step 23822: Loss = 0.20008690655231476\n",
            "Epoch 3, Step 23823: Loss = 0.5066930651664734\n",
            "Epoch 3, Step 23824: Loss = 0.26285794377326965\n",
            "Epoch 3, Step 23825: Loss = 0.4150215983390808\n",
            "Epoch 3, Step 23826: Loss = 0.30675387382507324\n",
            "Epoch 3, Step 23827: Loss = 0.20392398536205292\n",
            "Epoch 3, Step 23828: Loss = 0.3939703404903412\n",
            "Epoch 3, Step 23829: Loss = 0.2798726260662079\n",
            "Epoch 3, Step 23830: Loss = 0.2244652956724167\n",
            "Epoch 3, Step 23831: Loss = 0.3374045789241791\n",
            "Epoch 3, Step 23832: Loss = 0.24184748530387878\n",
            "Epoch 3, Step 23833: Loss = 0.24260492622852325\n",
            "Epoch 3, Step 23834: Loss = 0.2887272238731384\n",
            "Epoch 3, Step 23835: Loss = 0.4578312039375305\n",
            "Epoch 3, Step 23836: Loss = 0.2309274971485138\n",
            "Epoch 3, Step 23837: Loss = 0.3381304442882538\n",
            "Epoch 3, Step 23838: Loss = 0.4027099609375\n",
            "Epoch 3, Step 23839: Loss = 0.3222882151603699\n",
            "Epoch 3, Step 23840: Loss = 0.2612611651420593\n",
            "Epoch 3, Step 23841: Loss = 0.39555710554122925\n",
            "Epoch 3, Step 23842: Loss = 0.5124052166938782\n",
            "Epoch 3, Step 23843: Loss = 0.2234088033437729\n",
            "Epoch 3, Step 23844: Loss = 0.5020440816879272\n",
            "Epoch 3, Step 23845: Loss = 0.52301424741745\n",
            "Epoch 3, Step 23846: Loss = 0.2909482419490814\n",
            "Epoch 3, Step 23847: Loss = 0.3369419574737549\n",
            "Epoch 3, Step 23848: Loss = 0.35675114393234253\n",
            "Epoch 3, Step 23849: Loss = 0.44602110981941223\n",
            "Epoch 3, Step 23850: Loss = 0.3046777844429016\n",
            "Epoch 3, Step 23851: Loss = 0.5392955541610718\n",
            "Epoch 3, Step 23852: Loss = 0.3254777193069458\n",
            "Epoch 3, Step 23853: Loss = 0.29028430581092834\n",
            "Epoch 3, Step 23854: Loss = 0.24648380279541016\n",
            "Epoch 3, Step 23855: Loss = 0.1711864173412323\n",
            "Epoch 3, Step 23856: Loss = 0.5194176435470581\n",
            "Epoch 3, Step 23857: Loss = 0.2677444815635681\n",
            "Epoch 3, Step 23858: Loss = 0.3520393967628479\n",
            "Epoch 3, Step 23859: Loss = 0.32031846046447754\n",
            "Epoch 3, Step 23860: Loss = 0.31435611844062805\n",
            "Epoch 3, Step 23861: Loss = 0.27669116854667664\n",
            "Epoch 3, Step 23862: Loss = 0.18359525501728058\n",
            "Epoch 3, Step 23863: Loss = 0.2318539172410965\n",
            "Epoch 3, Step 23864: Loss = 0.221604123711586\n",
            "Epoch 3, Step 23865: Loss = 0.34067004919052124\n",
            "Epoch 3, Step 23866: Loss = 0.45716118812561035\n",
            "Epoch 3, Step 23867: Loss = 0.23162658512592316\n",
            "Epoch 3, Step 23868: Loss = 0.3268093168735504\n",
            "Epoch 3, Step 23869: Loss = 0.31350600719451904\n",
            "Epoch 3, Step 23870: Loss = 0.38135629892349243\n",
            "Epoch 3, Step 23871: Loss = 0.4387381672859192\n",
            "Epoch 3, Step 23872: Loss = 0.2818813621997833\n",
            "Epoch 3, Step 23873: Loss = 0.2728831470012665\n",
            "Epoch 3, Step 23874: Loss = 0.2755238115787506\n",
            "Epoch 3, Step 23875: Loss = 0.22006848454475403\n",
            "Epoch 3, Step 23876: Loss = 0.2164044976234436\n",
            "Epoch 3, Step 23877: Loss = 0.6101884841918945\n",
            "Epoch 3, Step 23878: Loss = 0.2649763226509094\n",
            "Epoch 3, Step 23879: Loss = 0.298916220664978\n",
            "Epoch 3, Step 23880: Loss = 0.43537241220474243\n",
            "Epoch 3, Step 23881: Loss = 0.5469462871551514\n",
            "Epoch 3, Step 23882: Loss = 0.3783525228500366\n",
            "Epoch 3, Step 23883: Loss = 0.15671910345554352\n",
            "Epoch 3, Step 23884: Loss = 0.2375570386648178\n",
            "Epoch 3, Step 23885: Loss = 0.29416078329086304\n",
            "Epoch 3, Step 23886: Loss = 0.17385566234588623\n",
            "Epoch 3, Step 23887: Loss = 0.22549766302108765\n",
            "Epoch 3, Step 23888: Loss = 0.3313632607460022\n",
            "Epoch 3, Step 23889: Loss = 0.3529232442378998\n",
            "Epoch 3, Step 23890: Loss = 0.47640395164489746\n",
            "Epoch 3, Step 23891: Loss = 0.31637391448020935\n",
            "Epoch 3, Step 23892: Loss = 0.23807024955749512\n",
            "Epoch 3, Step 23893: Loss = 0.416657954454422\n",
            "Epoch 3, Step 23894: Loss = 0.31133899092674255\n",
            "Epoch 3, Step 23895: Loss = 0.5235671997070312\n",
            "Epoch 3, Step 23896: Loss = 0.22384539246559143\n",
            "Epoch 3, Step 23897: Loss = 0.21837303042411804\n",
            "Epoch 3, Step 23898: Loss = 0.3449292480945587\n",
            "Epoch 3, Step 23899: Loss = 0.2934055030345917\n",
            "Epoch 3, Step 23900: Loss = 0.2117014229297638\n",
            "Epoch 3, Step 23901: Loss = 0.32405897974967957\n",
            "Epoch 3, Step 23902: Loss = 0.3195149898529053\n",
            "Epoch 3, Step 23903: Loss = 0.28154951333999634\n",
            "Epoch 3, Step 23904: Loss = 0.2815150320529938\n",
            "Epoch 3, Step 23905: Loss = 0.3074228763580322\n",
            "Epoch 3, Step 23906: Loss = 0.40156927704811096\n",
            "Epoch 3, Step 23907: Loss = 0.22842319309711456\n",
            "Epoch 3, Step 23908: Loss = 0.31075024604797363\n",
            "Epoch 3, Step 23909: Loss = 0.7885144948959351\n",
            "Epoch 3, Step 23910: Loss = 0.1321309208869934\n",
            "Epoch 3, Step 23911: Loss = 0.18550585210323334\n",
            "Epoch 3, Step 23912: Loss = 0.2395232766866684\n",
            "Epoch 3, Step 23913: Loss = 0.2751113772392273\n",
            "Epoch 3, Step 23914: Loss = 0.24037772417068481\n",
            "Epoch 3, Step 23915: Loss = 0.3819024860858917\n",
            "Epoch 3, Step 23916: Loss = 0.37368494272232056\n",
            "Epoch 3, Step 23917: Loss = 0.22396986186504364\n",
            "Epoch 3, Step 23918: Loss = 0.368731826543808\n",
            "Epoch 3, Step 23919: Loss = 0.34822824597358704\n",
            "Epoch 3, Step 23920: Loss = 0.42655816674232483\n",
            "Epoch 3, Step 23921: Loss = 0.38826003670692444\n",
            "Epoch 3, Step 23922: Loss = 0.14622312784194946\n",
            "Epoch 3, Step 23923: Loss = 0.3238201439380646\n",
            "Epoch 3, Step 23924: Loss = 0.3136846721172333\n",
            "Epoch 3, Step 23925: Loss = 0.4910125434398651\n",
            "Epoch 3, Step 23926: Loss = 0.6282870173454285\n",
            "Epoch 3, Step 23927: Loss = 0.3233529329299927\n",
            "Epoch 3, Step 23928: Loss = 0.49987122416496277\n",
            "Epoch 3, Step 23929: Loss = 0.1871604174375534\n",
            "Epoch 3, Step 23930: Loss = 0.34982502460479736\n",
            "Epoch 3, Step 23931: Loss = 0.3049061894416809\n",
            "Epoch 3, Step 23932: Loss = 0.5909228324890137\n",
            "Epoch 3, Step 23933: Loss = 0.3442075848579407\n",
            "Epoch 3, Step 23934: Loss = 0.3031725287437439\n",
            "Epoch 3, Step 23935: Loss = 0.202666237950325\n",
            "Epoch 3, Step 23936: Loss = 0.4892774522304535\n",
            "Epoch 3, Step 23937: Loss = 0.2803537845611572\n",
            "Epoch 3, Step 23938: Loss = 0.3760541081428528\n",
            "Epoch 3, Step 23939: Loss = 0.3496023714542389\n",
            "Epoch 3, Step 23940: Loss = 0.413040429353714\n",
            "Epoch 3, Step 23941: Loss = 0.2899444103240967\n",
            "Epoch 3, Step 23942: Loss = 0.4260022044181824\n",
            "Epoch 3, Step 23943: Loss = 0.348103404045105\n",
            "Epoch 3, Step 23944: Loss = 0.3588605225086212\n",
            "Epoch 3, Step 23945: Loss = 0.6501334309577942\n",
            "Epoch 3, Step 23946: Loss = 0.5907323360443115\n",
            "Epoch 3, Step 23947: Loss = 0.28117361664772034\n",
            "Epoch 3, Step 23948: Loss = 0.41594845056533813\n",
            "Epoch 3, Step 23949: Loss = 0.5205336809158325\n",
            "Epoch 3, Step 23950: Loss = 0.2427239865064621\n",
            "Epoch 3, Step 23951: Loss = 0.2675975561141968\n",
            "Epoch 3, Step 23952: Loss = 0.2233799248933792\n",
            "Epoch 3, Step 23953: Loss = 0.30472925305366516\n",
            "Epoch 3, Step 23954: Loss = 0.23344780504703522\n",
            "Epoch 3, Step 23955: Loss = 0.38723066449165344\n",
            "Epoch 3, Step 23956: Loss = 0.35156241059303284\n",
            "Epoch 3, Step 23957: Loss = 0.23829048871994019\n",
            "Epoch 3, Step 23958: Loss = 0.19861933588981628\n",
            "Epoch 3, Step 23959: Loss = 0.3637336790561676\n",
            "Epoch 3, Step 23960: Loss = 0.29387059807777405\n",
            "Epoch 3, Step 23961: Loss = 0.5497015118598938\n",
            "Epoch 3, Step 23962: Loss = 0.4347616136074066\n",
            "Epoch 3, Step 23963: Loss = 0.23975656926631927\n",
            "Epoch 3, Step 23964: Loss = 0.23191364109516144\n",
            "Epoch 3, Step 23965: Loss = 0.3186478912830353\n",
            "Epoch 3, Step 23966: Loss = 0.27937987446784973\n",
            "Epoch 3, Step 23967: Loss = 0.11279403418302536\n",
            "Epoch 3, Step 23968: Loss = 0.35716915130615234\n",
            "Epoch 3, Step 23969: Loss = 0.2902592122554779\n",
            "Epoch 3, Step 23970: Loss = 0.3706634044647217\n",
            "Epoch 3, Step 23971: Loss = 0.36933770775794983\n",
            "Epoch 3, Step 23972: Loss = 0.3895051181316376\n",
            "Epoch 3, Step 23973: Loss = 0.359602153301239\n",
            "Epoch 3, Step 23974: Loss = 0.534391462802887\n",
            "Epoch 3, Step 23975: Loss = 0.5274147987365723\n",
            "Epoch 3, Step 23976: Loss = 0.19120262563228607\n",
            "Epoch 3, Step 23977: Loss = 0.26697835326194763\n",
            "Epoch 3, Step 23978: Loss = 0.37321603298187256\n",
            "Epoch 3, Step 23979: Loss = 0.2925475537776947\n",
            "Epoch 3, Step 23980: Loss = 0.4297574758529663\n",
            "Epoch 3, Step 23981: Loss = 0.30887216329574585\n",
            "Epoch 3, Step 23982: Loss = 0.2889840006828308\n",
            "Epoch 3, Step 23983: Loss = 0.3208630681037903\n",
            "Epoch 3, Step 23984: Loss = 0.2635965645313263\n",
            "Epoch 3, Step 23985: Loss = 0.45153695344924927\n",
            "Epoch 3, Step 23986: Loss = 0.16154393553733826\n",
            "Epoch 3, Step 23987: Loss = 0.29111477732658386\n",
            "Epoch 3, Step 23988: Loss = 0.3891521394252777\n",
            "Epoch 3, Step 23989: Loss = 0.27309131622314453\n",
            "Epoch 3, Step 23990: Loss = 0.22724123299121857\n",
            "Epoch 3, Step 23991: Loss = 0.1945039927959442\n",
            "Epoch 3, Step 23992: Loss = 0.42272698879241943\n",
            "Epoch 3, Step 23993: Loss = 0.3662235736846924\n",
            "Epoch 3, Step 23994: Loss = 0.42046311497688293\n",
            "Epoch 3, Step 23995: Loss = 0.16907700896263123\n",
            "Epoch 3, Step 23996: Loss = 0.22085390985012054\n",
            "Epoch 3, Step 23997: Loss = 0.5133556723594666\n",
            "Epoch 3, Step 23998: Loss = 0.21113772690296173\n",
            "Epoch 3, Step 23999: Loss = 0.23315852880477905\n",
            "Epoch 3, Step 24000: Loss = 0.5883100032806396\n",
            "Epoch 3, Step 24001: Loss = 0.29981574416160583\n",
            "Epoch 3, Step 24002: Loss = 0.21783773601055145\n",
            "Epoch 3, Step 24003: Loss = 0.34773945808410645\n",
            "Epoch 3, Step 24004: Loss = 0.1914563626050949\n",
            "Epoch 3, Step 24005: Loss = 0.3685908317565918\n",
            "Epoch 3, Step 24006: Loss = 0.6762858033180237\n",
            "Epoch 3, Step 24007: Loss = 0.3404117226600647\n",
            "Epoch 3, Step 24008: Loss = 0.3968799114227295\n",
            "Epoch 3, Step 24009: Loss = 0.147894486784935\n",
            "Epoch 3, Step 24010: Loss = 0.31854453682899475\n",
            "Epoch 3, Step 24011: Loss = 0.4426323473453522\n",
            "Epoch 3, Step 24012: Loss = 0.2730043828487396\n",
            "Epoch 3, Step 24013: Loss = 0.32265710830688477\n",
            "Epoch 3, Step 24014: Loss = 0.40988463163375854\n",
            "Epoch 3, Step 24015: Loss = 0.3459322452545166\n",
            "Epoch 3, Step 24016: Loss = 0.32468554377555847\n",
            "Epoch 3, Step 24017: Loss = 0.4891684949398041\n",
            "Epoch 3, Step 24018: Loss = 0.36363843083381653\n",
            "Epoch 3, Step 24019: Loss = 0.2491416037082672\n",
            "Epoch 3, Step 24020: Loss = 0.22532348334789276\n",
            "Epoch 3, Step 24021: Loss = 0.27879390120506287\n",
            "Epoch 3, Step 24022: Loss = 0.3670386075973511\n",
            "Epoch 3, Step 24023: Loss = 0.29674047231674194\n",
            "Epoch 3, Step 24024: Loss = 0.32261553406715393\n",
            "Epoch 3, Step 24025: Loss = 0.28354331851005554\n",
            "Epoch 3, Step 24026: Loss = 0.4341798722743988\n",
            "Epoch 3, Step 24027: Loss = 0.5876137018203735\n",
            "Epoch 3, Step 24028: Loss = 0.32430166006088257\n",
            "Epoch 3, Step 24029: Loss = 0.24022561311721802\n",
            "Epoch 3, Step 24030: Loss = 0.23409292101860046\n",
            "Epoch 3, Step 24031: Loss = 0.5388567447662354\n",
            "Epoch 3, Step 24032: Loss = 0.3462997376918793\n",
            "Epoch 3, Step 24033: Loss = 0.2825913727283478\n",
            "Epoch 3, Step 24034: Loss = 0.4305057227611542\n",
            "Epoch 3, Step 24035: Loss = 0.1547156274318695\n",
            "Epoch 3, Step 24036: Loss = 0.18469445407390594\n",
            "Epoch 3, Step 24037: Loss = 0.15402325987815857\n",
            "Epoch 3, Step 24038: Loss = 0.5006994605064392\n",
            "Epoch 3, Step 24039: Loss = 0.3033318817615509\n",
            "Epoch 3, Step 24040: Loss = 0.2249336987733841\n",
            "Epoch 3, Step 24041: Loss = 0.37224555015563965\n",
            "Epoch 3, Step 24042: Loss = 0.5838459730148315\n",
            "Epoch 3, Step 24043: Loss = 0.33440473675727844\n",
            "Epoch 3, Step 24044: Loss = 0.4114342927932739\n",
            "Epoch 3, Step 24045: Loss = 0.39703813195228577\n",
            "Epoch 3, Step 24046: Loss = 0.5304042100906372\n",
            "Epoch 3, Step 24047: Loss = 0.3241352438926697\n",
            "Epoch 3, Step 24048: Loss = 0.3792484998703003\n",
            "Epoch 3, Step 24049: Loss = 0.4326554238796234\n",
            "Epoch 3, Step 24050: Loss = 0.36693352460861206\n",
            "Epoch 3, Step 24051: Loss = 0.4604004919528961\n",
            "Epoch 3, Step 24052: Loss = 0.36639130115509033\n",
            "Epoch 3, Step 24053: Loss = 0.543855607509613\n",
            "Epoch 3, Step 24054: Loss = 0.3700462579727173\n",
            "Epoch 3, Step 24055: Loss = 0.3995612561702728\n",
            "Epoch 3, Step 24056: Loss = 0.36594444513320923\n",
            "Epoch 3, Step 24057: Loss = 0.3417201638221741\n",
            "Epoch 3, Step 24058: Loss = 0.48665812611579895\n",
            "Epoch 3, Step 24059: Loss = 0.4501035809516907\n",
            "Epoch 3, Step 24060: Loss = 0.2712838649749756\n",
            "Epoch 3, Step 24061: Loss = 0.5377790927886963\n",
            "Epoch 3, Step 24062: Loss = 0.3417937755584717\n",
            "Epoch 3, Step 24063: Loss = 0.39664191007614136\n",
            "Epoch 3, Step 24064: Loss = 0.3026530146598816\n",
            "Epoch 3, Step 24065: Loss = 0.1362350434064865\n",
            "Epoch 3, Step 24066: Loss = 0.32828888297080994\n",
            "Epoch 3, Step 24067: Loss = 0.4288080930709839\n",
            "Epoch 3, Step 24068: Loss = 0.5392227172851562\n",
            "Epoch 3, Step 24069: Loss = 0.298513799905777\n",
            "Epoch 3, Step 24070: Loss = 0.34840530157089233\n",
            "Epoch 3, Step 24071: Loss = 0.17793238162994385\n",
            "Epoch 3, Step 24072: Loss = 0.4007991850376129\n",
            "Epoch 3, Step 24073: Loss = 0.38743042945861816\n",
            "Epoch 3, Step 24074: Loss = 0.22893154621124268\n",
            "Epoch 3, Step 24075: Loss = 0.18713852763175964\n",
            "Epoch 3, Step 24076: Loss = 0.30095577239990234\n",
            "Epoch 3, Step 24077: Loss = 0.36975571513175964\n",
            "Epoch 3, Step 24078: Loss = 0.16150198876857758\n",
            "Epoch 3, Step 24079: Loss = 0.433565229177475\n",
            "Epoch 3, Step 24080: Loss = 0.3355705142021179\n",
            "Epoch 3, Step 24081: Loss = 0.2875126302242279\n",
            "Epoch 3, Step 24082: Loss = 0.249692901968956\n",
            "Epoch 3, Step 24083: Loss = 0.21383222937583923\n",
            "Epoch 3, Step 24084: Loss = 0.24769029021263123\n",
            "Epoch 3, Step 24085: Loss = 0.144877091050148\n",
            "Epoch 3, Step 24086: Loss = 0.2710507810115814\n",
            "Epoch 3, Step 24087: Loss = 0.34356963634490967\n",
            "Epoch 3, Step 24088: Loss = 0.272337943315506\n",
            "Epoch 3, Step 24089: Loss = 0.17433252930641174\n",
            "Epoch 3, Step 24090: Loss = 0.22591905295848846\n",
            "Epoch 3, Step 24091: Loss = 0.26889103651046753\n",
            "Epoch 3, Step 24092: Loss = 0.2635451555252075\n",
            "Epoch 3, Step 24093: Loss = 0.5394559502601624\n",
            "Epoch 3, Step 24094: Loss = 0.27346327900886536\n",
            "Epoch 3, Step 24095: Loss = 0.22510571777820587\n",
            "Epoch 3, Step 24096: Loss = 0.230762779712677\n",
            "Epoch 3, Step 24097: Loss = 0.24181172251701355\n",
            "Epoch 3, Step 24098: Loss = 0.33284130692481995\n",
            "Epoch 3, Step 24099: Loss = 0.40490278601646423\n",
            "Epoch 3, Step 24100: Loss = 0.4735924005508423\n",
            "Epoch 3, Step 24101: Loss = 0.5435888767242432\n",
            "Epoch 3, Step 24102: Loss = 0.22213102877140045\n",
            "Epoch 3, Step 24103: Loss = 0.34960952401161194\n",
            "Epoch 3, Step 24104: Loss = 0.23574301600456238\n",
            "Epoch 3, Step 24105: Loss = 0.2530900835990906\n",
            "Epoch 3, Step 24106: Loss = 0.32012122869491577\n",
            "Epoch 3, Step 24107: Loss = 0.4018332064151764\n",
            "Epoch 3, Step 24108: Loss = 0.2836567163467407\n",
            "Epoch 3, Step 24109: Loss = 0.5198469758033752\n",
            "Epoch 3, Step 24110: Loss = 0.505033016204834\n",
            "Epoch 3, Step 24111: Loss = 0.2689470648765564\n",
            "Epoch 3, Step 24112: Loss = 0.25634002685546875\n",
            "Epoch 3, Step 24113: Loss = 0.3826568126678467\n",
            "Epoch 3, Step 24114: Loss = 0.24567414820194244\n",
            "Epoch 3, Step 24115: Loss = 0.27410322427749634\n",
            "Epoch 3, Step 24116: Loss = 0.4700198769569397\n",
            "Epoch 3, Step 24117: Loss = 0.4916681945323944\n",
            "Epoch 3, Step 24118: Loss = 0.21708185970783234\n",
            "Epoch 3, Step 24119: Loss = 0.31216585636138916\n",
            "Epoch 3, Step 24120: Loss = 0.14610019326210022\n",
            "Epoch 3, Step 24121: Loss = 0.450702965259552\n",
            "Epoch 3, Step 24122: Loss = 0.26930952072143555\n",
            "Epoch 3, Step 24123: Loss = 0.3739304542541504\n",
            "Epoch 3, Step 24124: Loss = 0.47201400995254517\n",
            "Epoch 3, Step 24125: Loss = 0.5457744598388672\n",
            "Epoch 3, Step 24126: Loss = 0.37883374094963074\n",
            "Epoch 3, Step 24127: Loss = 0.16950444877147675\n",
            "Epoch 3, Step 24128: Loss = 0.27490729093551636\n",
            "Epoch 3, Step 24129: Loss = 0.4996878504753113\n",
            "Epoch 3, Step 24130: Loss = 0.2923930287361145\n",
            "Epoch 3, Step 24131: Loss = 0.38996097445487976\n",
            "Epoch 3, Step 24132: Loss = 0.5359099507331848\n",
            "Epoch 3, Step 24133: Loss = 0.2571945786476135\n",
            "Epoch 3, Step 24134: Loss = 0.3538958728313446\n",
            "Epoch 3, Step 24135: Loss = 0.22489391267299652\n",
            "Epoch 3, Step 24136: Loss = 0.217396542429924\n",
            "Epoch 3, Step 24137: Loss = 0.4129555821418762\n",
            "Epoch 3, Step 24138: Loss = 0.4489525556564331\n",
            "Epoch 3, Step 24139: Loss = 0.14640580117702484\n",
            "Epoch 3, Step 24140: Loss = 0.22235776484012604\n",
            "Epoch 3, Step 24141: Loss = 0.2321157604455948\n",
            "Epoch 3, Step 24142: Loss = 0.6384634375572205\n",
            "Epoch 3, Step 24143: Loss = 0.2667495906352997\n",
            "Epoch 3, Step 24144: Loss = 0.3471433222293854\n",
            "Epoch 3, Step 24145: Loss = 0.19562818109989166\n",
            "Epoch 3, Step 24146: Loss = 0.3033733367919922\n",
            "Epoch 3, Step 24147: Loss = 0.35060468316078186\n",
            "Epoch 3, Step 24148: Loss = 0.39137083292007446\n",
            "Epoch 3, Step 24149: Loss = 0.43733668327331543\n",
            "Epoch 3, Step 24150: Loss = 0.5062969923019409\n",
            "Epoch 3, Step 24151: Loss = 0.3071736693382263\n",
            "Epoch 3, Step 24152: Loss = 0.3554270565509796\n",
            "Epoch 3, Step 24153: Loss = 0.20943842828273773\n",
            "Epoch 3, Step 24154: Loss = 0.3146248757839203\n",
            "Epoch 3, Step 24155: Loss = 0.3359159231185913\n",
            "Epoch 3, Step 24156: Loss = 0.2807123363018036\n",
            "Epoch 3, Step 24157: Loss = 0.1581254005432129\n",
            "Epoch 3, Step 24158: Loss = 0.44193732738494873\n",
            "Epoch 3, Step 24159: Loss = 0.48497751355171204\n",
            "Epoch 3, Step 24160: Loss = 0.21444092690944672\n",
            "Epoch 3, Step 24161: Loss = 0.2844141125679016\n",
            "Epoch 3, Step 24162: Loss = 0.25674229860305786\n",
            "Epoch 3, Step 24163: Loss = 0.3162485957145691\n",
            "Epoch 3, Step 24164: Loss = 0.20271004736423492\n",
            "Epoch 3, Step 24165: Loss = 0.28008008003234863\n",
            "Epoch 3, Step 24166: Loss = 0.5317747592926025\n",
            "Epoch 3, Step 24167: Loss = 0.35712963342666626\n",
            "Epoch 3, Step 24168: Loss = 0.325620174407959\n",
            "Epoch 3, Step 24169: Loss = 0.32630980014801025\n",
            "Epoch 3, Step 24170: Loss = 0.2561523914337158\n",
            "Epoch 3, Step 24171: Loss = 0.46756571531295776\n",
            "Epoch 3, Step 24172: Loss = 0.18354536592960358\n",
            "Epoch 3, Step 24173: Loss = 0.3480837047100067\n",
            "Epoch 3, Step 24174: Loss = 0.1996804177761078\n",
            "Epoch 3, Step 24175: Loss = 0.2390156090259552\n",
            "Epoch 3, Step 24176: Loss = 0.24131715297698975\n",
            "Epoch 3, Step 24177: Loss = 0.21933020651340485\n",
            "Epoch 3, Step 24178: Loss = 0.32015544176101685\n",
            "Epoch 3, Step 24179: Loss = 0.3015545606613159\n",
            "Epoch 3, Step 24180: Loss = 0.20200879871845245\n",
            "Epoch 3, Step 24181: Loss = 0.2883955240249634\n",
            "Epoch 3, Step 24182: Loss = 0.3801563084125519\n",
            "Epoch 3, Step 24183: Loss = 0.49296441674232483\n",
            "Epoch 3, Step 24184: Loss = 0.26167362928390503\n",
            "Epoch 3, Step 24185: Loss = 0.1653900444507599\n",
            "Epoch 3, Step 24186: Loss = 0.3183327913284302\n",
            "Epoch 3, Step 24187: Loss = 0.22507627308368683\n",
            "Epoch 3, Step 24188: Loss = 0.25520244240760803\n",
            "Epoch 3, Step 24189: Loss = 0.46546393632888794\n",
            "Epoch 3, Step 24190: Loss = 0.32228732109069824\n",
            "Epoch 3, Step 24191: Loss = 0.2072870135307312\n",
            "Epoch 3, Step 24192: Loss = 0.27398964762687683\n",
            "Epoch 3, Step 24193: Loss = 0.4126650393009186\n",
            "Epoch 3, Step 24194: Loss = 0.25099998712539673\n",
            "Epoch 3, Step 24195: Loss = 0.3210236132144928\n",
            "Epoch 3, Step 24196: Loss = 0.21171142160892487\n",
            "Epoch 3, Step 24197: Loss = 0.2663823664188385\n",
            "Epoch 3, Step 24198: Loss = 0.2719399333000183\n",
            "Epoch 3, Step 24199: Loss = 0.2580447494983673\n",
            "Epoch 3, Step 24200: Loss = 0.30089065432548523\n",
            "Epoch 3, Step 24201: Loss = 0.2681550681591034\n",
            "Epoch 3, Step 24202: Loss = 0.30084988474845886\n",
            "Epoch 3, Step 24203: Loss = 0.4878988564014435\n",
            "Epoch 3, Step 24204: Loss = 0.4025086760520935\n",
            "Epoch 3, Step 24205: Loss = 0.18868808448314667\n",
            "Epoch 3, Step 24206: Loss = 0.32297343015670776\n",
            "Epoch 3, Step 24207: Loss = 0.5445777773857117\n",
            "Epoch 3, Step 24208: Loss = 0.43586769700050354\n",
            "Epoch 3, Step 24209: Loss = 0.38647326827049255\n",
            "Epoch 3, Step 24210: Loss = 0.36775854229927063\n",
            "Epoch 3, Step 24211: Loss = 0.2275293618440628\n",
            "Epoch 3, Step 24212: Loss = 0.3059336543083191\n",
            "Epoch 3, Step 24213: Loss = 0.10892191529273987\n",
            "Epoch 3, Step 24214: Loss = 0.3656211495399475\n",
            "Epoch 3, Step 24215: Loss = 0.48359382152557373\n",
            "Epoch 3, Step 24216: Loss = 0.5118582248687744\n",
            "Epoch 3, Step 24217: Loss = 0.41761237382888794\n",
            "Epoch 3, Step 24218: Loss = 0.41078701615333557\n",
            "Epoch 3, Step 24219: Loss = 0.40882426500320435\n",
            "Epoch 3, Step 24220: Loss = 0.5043504238128662\n",
            "Epoch 3, Step 24221: Loss = 0.28769198060035706\n",
            "Epoch 3, Step 24222: Loss = 0.2255047857761383\n",
            "Epoch 3, Step 24223: Loss = 0.19114981591701508\n",
            "Epoch 3, Step 24224: Loss = 0.3947420120239258\n",
            "Epoch 3, Step 24225: Loss = 0.4433307945728302\n",
            "Epoch 3, Step 24226: Loss = 0.2872075140476227\n",
            "Epoch 3, Step 24227: Loss = 0.3429917097091675\n",
            "Epoch 3, Step 24228: Loss = 0.275712788105011\n",
            "Epoch 3, Step 24229: Loss = 0.18820135295391083\n",
            "Epoch 3, Step 24230: Loss = 0.22143378853797913\n",
            "Epoch 3, Step 24231: Loss = 0.6861511468887329\n",
            "Epoch 3, Step 24232: Loss = 0.33038535714149475\n",
            "Epoch 3, Step 24233: Loss = 0.2699389159679413\n",
            "Epoch 3, Step 24234: Loss = 0.2165604829788208\n",
            "Epoch 3, Step 24235: Loss = 0.41634896397590637\n",
            "Epoch 3, Step 24236: Loss = 0.3517954647541046\n",
            "Epoch 3, Step 24237: Loss = 0.3554570972919464\n",
            "Epoch 3, Step 24238: Loss = 0.25426921248435974\n",
            "Epoch 3, Step 24239: Loss = 0.44810381531715393\n",
            "Epoch 3, Step 24240: Loss = 0.3469575047492981\n",
            "Epoch 3, Step 24241: Loss = 0.2327948808670044\n",
            "Epoch 3, Step 24242: Loss = 0.344791442155838\n",
            "Epoch 3, Step 24243: Loss = 0.7190216183662415\n",
            "Epoch 3, Step 24244: Loss = 0.3283192813396454\n",
            "Epoch 3, Step 24245: Loss = 0.2388456016778946\n",
            "Epoch 3, Step 24246: Loss = 0.30383238196372986\n",
            "Epoch 3, Step 24247: Loss = 0.25378870964050293\n",
            "Epoch 3, Step 24248: Loss = 0.49425622820854187\n",
            "Epoch 3, Step 24249: Loss = 0.2858988642692566\n",
            "Epoch 3, Step 24250: Loss = 0.5665401816368103\n",
            "Epoch 3, Step 24251: Loss = 0.30362793803215027\n",
            "Epoch 3, Step 24252: Loss = 0.4061053693294525\n",
            "Epoch 3, Step 24253: Loss = 0.300283282995224\n",
            "Epoch 3, Step 24254: Loss = 0.2739638388156891\n",
            "Epoch 3, Step 24255: Loss = 0.3279852569103241\n",
            "Epoch 3, Step 24256: Loss = 0.28023362159729004\n",
            "Epoch 3, Step 24257: Loss = 0.22168324887752533\n",
            "Epoch 3, Step 24258: Loss = 0.2707350254058838\n",
            "Epoch 3, Step 24259: Loss = 0.2129504233598709\n",
            "Epoch 3, Step 24260: Loss = 0.43189331889152527\n",
            "Epoch 3, Step 24261: Loss = 0.4522581696510315\n",
            "Epoch 3, Step 24262: Loss = 0.25151532888412476\n",
            "Epoch 3, Step 24263: Loss = 0.1570534110069275\n",
            "Epoch 3, Step 24264: Loss = 0.2570929229259491\n",
            "Epoch 3, Step 24265: Loss = 0.564697802066803\n",
            "Epoch 3, Step 24266: Loss = 0.2532467246055603\n",
            "Epoch 3, Step 24267: Loss = 0.3113178014755249\n",
            "Epoch 3, Step 24268: Loss = 0.5947089791297913\n",
            "Epoch 3, Step 24269: Loss = 0.2357061207294464\n",
            "Epoch 3, Step 24270: Loss = 0.4176887273788452\n",
            "Epoch 3, Step 24271: Loss = 0.2580805718898773\n",
            "Epoch 3, Step 24272: Loss = 0.21894919872283936\n",
            "Epoch 3, Step 24273: Loss = 0.3130464255809784\n",
            "Epoch 3, Step 24274: Loss = 0.24581417441368103\n",
            "Epoch 3, Step 24275: Loss = 0.3777365982532501\n",
            "Epoch 3, Step 24276: Loss = 0.40843459963798523\n",
            "Epoch 3, Step 24277: Loss = 0.3185880482196808\n",
            "Epoch 3, Step 24278: Loss = 0.32797449827194214\n",
            "Epoch 3, Step 24279: Loss = 0.356372207403183\n",
            "Epoch 3, Step 24280: Loss = 0.22547440230846405\n",
            "Epoch 3, Step 24281: Loss = 0.21168452501296997\n",
            "Epoch 3, Step 24282: Loss = 0.39327749609947205\n",
            "Epoch 3, Step 24283: Loss = 0.3175002634525299\n",
            "Epoch 3, Step 24284: Loss = 0.32096317410469055\n",
            "Epoch 3, Step 24285: Loss = 0.3974412679672241\n",
            "Epoch 3, Step 24286: Loss = 0.17337633669376373\n",
            "Epoch 3, Step 24287: Loss = 0.26681727170944214\n",
            "Epoch 3, Step 24288: Loss = 0.29386186599731445\n",
            "Epoch 3, Step 24289: Loss = 0.21191073954105377\n",
            "Epoch 3, Step 24290: Loss = 0.27331313490867615\n",
            "Epoch 3, Step 24291: Loss = 0.4128095507621765\n",
            "Epoch 3, Step 24292: Loss = 0.37804919481277466\n",
            "Epoch 3, Step 24293: Loss = 0.6419627666473389\n",
            "Epoch 3, Step 24294: Loss = 0.33490824699401855\n",
            "Epoch 3, Step 24295: Loss = 0.4470435082912445\n",
            "Epoch 3, Step 24296: Loss = 0.23510867357254028\n",
            "Epoch 3, Step 24297: Loss = 0.14922687411308289\n",
            "Epoch 3, Step 24298: Loss = 0.2779252827167511\n",
            "Epoch 3, Step 24299: Loss = 0.2846857011318207\n",
            "Epoch 3, Step 24300: Loss = 0.29216912388801575\n",
            "Epoch 3, Step 24301: Loss = 0.32106637954711914\n",
            "Epoch 3, Step 24302: Loss = 0.32044517993927\n",
            "Epoch 3, Step 24303: Loss = 0.38887113332748413\n",
            "Epoch 3, Step 24304: Loss = 0.35175877809524536\n",
            "Epoch 3, Step 24305: Loss = 0.2640213966369629\n",
            "Epoch 3, Step 24306: Loss = 0.635686457157135\n",
            "Epoch 3, Step 24307: Loss = 0.2710497975349426\n",
            "Epoch 3, Step 24308: Loss = 0.37540069222450256\n",
            "Epoch 3, Step 24309: Loss = 0.3073199689388275\n",
            "Epoch 3, Step 24310: Loss = 0.2829519808292389\n",
            "Epoch 3, Step 24311: Loss = 0.2427094429731369\n",
            "Epoch 3, Step 24312: Loss = 0.45590102672576904\n",
            "Epoch 3, Step 24313: Loss = 0.41020238399505615\n",
            "Epoch 3, Step 24314: Loss = 0.4637470841407776\n",
            "Epoch 3, Step 24315: Loss = 0.23457551002502441\n",
            "Epoch 3, Step 24316: Loss = 0.4818595051765442\n",
            "Epoch 3, Step 24317: Loss = 0.23816631734371185\n",
            "Epoch 3, Step 24318: Loss = 0.2404477596282959\n",
            "Epoch 3, Step 24319: Loss = 0.2482224702835083\n",
            "Epoch 3, Step 24320: Loss = 0.32889750599861145\n",
            "Epoch 3, Step 24321: Loss = 0.14816616475582123\n",
            "Epoch 3, Step 24322: Loss = 0.23520518839359283\n",
            "Epoch 3, Step 24323: Loss = 0.11290328204631805\n",
            "Epoch 3, Step 24324: Loss = 0.24554389715194702\n",
            "Epoch 3, Step 24325: Loss = 0.41997167468070984\n",
            "Epoch 3, Step 24326: Loss = 0.448012113571167\n",
            "Epoch 3, Step 24327: Loss = 0.16931886970996857\n",
            "Epoch 3, Step 24328: Loss = 0.2233428806066513\n",
            "Epoch 3, Step 24329: Loss = 0.2615858018398285\n",
            "Epoch 3, Step 24330: Loss = 0.2579941749572754\n",
            "Epoch 3, Step 24331: Loss = 0.3183532655239105\n",
            "Epoch 3, Step 24332: Loss = 0.4422915279865265\n",
            "Epoch 3, Step 24333: Loss = 0.28813135623931885\n",
            "Epoch 3, Step 24334: Loss = 0.22969119250774384\n",
            "Epoch 3, Step 24335: Loss = 0.16137219965457916\n",
            "Epoch 3, Step 24336: Loss = 0.2823393642902374\n",
            "Epoch 3, Step 24337: Loss = 0.22290892899036407\n",
            "Epoch 3, Step 24338: Loss = 0.20030036568641663\n",
            "Epoch 3, Step 24339: Loss = 0.35402414202690125\n",
            "Epoch 3, Step 24340: Loss = 0.6296476125717163\n",
            "Epoch 3, Step 24341: Loss = 0.36212357878685\n",
            "Epoch 3, Step 24342: Loss = 0.6196390986442566\n",
            "Epoch 3, Step 24343: Loss = 0.579216480255127\n",
            "Epoch 3, Step 24344: Loss = 0.13060703873634338\n",
            "Epoch 3, Step 24345: Loss = 0.3906986713409424\n",
            "Epoch 3, Step 24346: Loss = 0.3687153160572052\n",
            "Epoch 3, Step 24347: Loss = 0.37083983421325684\n",
            "Epoch 3, Step 24348: Loss = 0.38475486636161804\n",
            "Epoch 3, Step 24349: Loss = 0.2971157729625702\n",
            "Epoch 3, Step 24350: Loss = 0.3954644203186035\n",
            "Epoch 3, Step 24351: Loss = 0.4428430497646332\n",
            "Epoch 3, Step 24352: Loss = 0.3399958908557892\n",
            "Epoch 3, Step 24353: Loss = 0.20466989278793335\n",
            "Epoch 3, Step 24354: Loss = 0.33560290932655334\n",
            "Epoch 3, Step 24355: Loss = 0.5196555852890015\n",
            "Epoch 3, Step 24356: Loss = 0.48585495352745056\n",
            "Epoch 3, Step 24357: Loss = 0.344739705324173\n",
            "Epoch 3, Step 24358: Loss = 0.20972712337970734\n",
            "Epoch 3, Step 24359: Loss = 0.38043302297592163\n",
            "Epoch 3, Step 24360: Loss = 0.2558911442756653\n",
            "Epoch 3, Step 24361: Loss = 0.2775077521800995\n",
            "Epoch 3, Step 24362: Loss = 0.46348491311073303\n",
            "Epoch 3, Step 24363: Loss = 0.28437185287475586\n",
            "Epoch 3, Step 24364: Loss = 0.3890615999698639\n",
            "Epoch 3, Step 24365: Loss = 0.47721123695373535\n",
            "Epoch 3, Step 24366: Loss = 0.1588430255651474\n",
            "Epoch 3, Step 24367: Loss = 0.32573291659355164\n",
            "Epoch 3, Step 24368: Loss = 0.21044740080833435\n",
            "Epoch 3, Step 24369: Loss = 0.21718460321426392\n",
            "Epoch 3, Step 24370: Loss = 0.4111040532588959\n",
            "Epoch 3, Step 24371: Loss = 0.246978297829628\n",
            "Epoch 3, Step 24372: Loss = 0.4895345866680145\n",
            "Epoch 3, Step 24373: Loss = 0.5294614434242249\n",
            "Epoch 3, Step 24374: Loss = 0.3138878047466278\n",
            "Epoch 3, Step 24375: Loss = 0.3297269344329834\n",
            "Epoch 3, Step 24376: Loss = 0.20996883511543274\n",
            "Epoch 3, Step 24377: Loss = 0.3602459728717804\n",
            "Epoch 3, Step 24378: Loss = 0.277403324842453\n",
            "Epoch 3, Step 24379: Loss = 0.22519239783287048\n",
            "Epoch 3, Step 24380: Loss = 0.11035679280757904\n",
            "Epoch 3, Step 24381: Loss = 0.272146612405777\n",
            "Epoch 3, Step 24382: Loss = 0.23705050349235535\n",
            "Epoch 3, Step 24383: Loss = 0.2358809858560562\n",
            "Epoch 3, Step 24384: Loss = 0.4150547683238983\n",
            "Epoch 3, Step 24385: Loss = 0.48611995577812195\n",
            "Epoch 3, Step 24386: Loss = 0.3512752950191498\n",
            "Epoch 3, Step 24387: Loss = 0.3053257167339325\n",
            "Epoch 3, Step 24388: Loss = 0.23630402982234955\n",
            "Epoch 3, Step 24389: Loss = 0.16629189252853394\n",
            "Epoch 3, Step 24390: Loss = 0.5114542245864868\n",
            "Epoch 3, Step 24391: Loss = 0.32648131251335144\n",
            "Epoch 3, Step 24392: Loss = 0.6341904401779175\n",
            "Epoch 3, Step 24393: Loss = 0.26727205514907837\n",
            "Epoch 3, Step 24394: Loss = 0.44160690903663635\n",
            "Epoch 3, Step 24395: Loss = 0.1728343367576599\n",
            "Epoch 3, Step 24396: Loss = 0.2716010510921478\n",
            "Epoch 3, Step 24397: Loss = 0.2412717044353485\n",
            "Epoch 3, Step 24398: Loss = 0.3483233153820038\n",
            "Epoch 3, Step 24399: Loss = 0.2128877192735672\n",
            "Epoch 3, Step 24400: Loss = 0.37644028663635254\n",
            "Epoch 3, Step 24401: Loss = 0.32771527767181396\n",
            "Epoch 3, Step 24402: Loss = 0.27054667472839355\n",
            "Epoch 3, Step 24403: Loss = 0.33127561211586\n",
            "Epoch 3, Step 24404: Loss = 0.2813953757286072\n",
            "Epoch 3, Step 24405: Loss = 0.5132433772087097\n",
            "Epoch 3, Step 24406: Loss = 0.32512298226356506\n",
            "Epoch 3, Step 24407: Loss = 0.4106874167919159\n",
            "Epoch 3, Step 24408: Loss = 0.2748846709728241\n",
            "Epoch 3, Step 24409: Loss = 0.3993430733680725\n",
            "Epoch 3, Step 24410: Loss = 0.6074950098991394\n",
            "Epoch 3, Step 24411: Loss = 0.32816022634506226\n",
            "Epoch 3, Step 24412: Loss = 0.23852881789207458\n",
            "Epoch 3, Step 24413: Loss = 0.3899803161621094\n",
            "Epoch 3, Step 24414: Loss = 0.40776634216308594\n",
            "Epoch 3, Step 24415: Loss = 0.3535308539867401\n",
            "Epoch 3, Step 24416: Loss = 0.31683671474456787\n",
            "Epoch 3, Step 24417: Loss = 0.6651309132575989\n",
            "Epoch 3, Step 24418: Loss = 0.26234275102615356\n",
            "Epoch 3, Step 24419: Loss = 0.23680473864078522\n",
            "Epoch 3, Step 24420: Loss = 0.14555148780345917\n",
            "Epoch 3, Step 24421: Loss = 0.3100873827934265\n",
            "Epoch 3, Step 24422: Loss = 0.2037285417318344\n",
            "Epoch 3, Step 24423: Loss = 0.1806570440530777\n",
            "Epoch 3, Step 24424: Loss = 0.43545007705688477\n",
            "Epoch 3, Step 24425: Loss = 0.2674568295478821\n",
            "Epoch 3, Step 24426: Loss = 0.5655192732810974\n",
            "Epoch 3, Step 24427: Loss = 0.3448014259338379\n",
            "Epoch 3, Step 24428: Loss = 0.30982714891433716\n",
            "Epoch 3, Step 24429: Loss = 0.20761820673942566\n",
            "Epoch 3, Step 24430: Loss = 0.33132874965667725\n",
            "Epoch 3, Step 24431: Loss = 0.4388546049594879\n",
            "Epoch 3, Step 24432: Loss = 0.31654587388038635\n",
            "Epoch 3, Step 24433: Loss = 0.48004013299942017\n",
            "Epoch 3, Step 24434: Loss = 0.4145153760910034\n",
            "Epoch 3, Step 24435: Loss = 0.20946042239665985\n",
            "Epoch 3, Step 24436: Loss = 0.2550780773162842\n",
            "Epoch 3, Step 24437: Loss = 0.23741677403450012\n",
            "Epoch 3, Step 24438: Loss = 0.49648624658584595\n",
            "Epoch 3, Step 24439: Loss = 0.4805045425891876\n",
            "Epoch 3, Step 24440: Loss = 0.3710820972919464\n",
            "Epoch 3, Step 24441: Loss = 0.4129831790924072\n",
            "Epoch 3, Step 24442: Loss = 0.4202289283275604\n",
            "Epoch 3, Step 24443: Loss = 0.35425522923469543\n",
            "Epoch 3, Step 24444: Loss = 0.4317866563796997\n",
            "Epoch 3, Step 24445: Loss = 0.27526217699050903\n",
            "Epoch 3, Step 24446: Loss = 0.41619983315467834\n",
            "Epoch 3, Step 24447: Loss = 0.20579837262630463\n",
            "Epoch 3, Step 24448: Loss = 0.3262907564640045\n",
            "Epoch 3, Step 24449: Loss = 0.19265615940093994\n",
            "Epoch 3, Step 24450: Loss = 0.3407593071460724\n",
            "Epoch 3, Step 24451: Loss = 0.40866076946258545\n",
            "Epoch 3, Step 24452: Loss = 0.5504029989242554\n",
            "Epoch 3, Step 24453: Loss = 0.3930729627609253\n",
            "Epoch 3, Step 24454: Loss = 0.310151606798172\n",
            "Epoch 3, Step 24455: Loss = 0.26121455430984497\n",
            "Epoch 3, Step 24456: Loss = 0.2599504292011261\n",
            "Epoch 3, Step 24457: Loss = 0.21844026446342468\n",
            "Epoch 3, Step 24458: Loss = 0.38369205594062805\n",
            "Epoch 3, Step 24459: Loss = 0.38530176877975464\n",
            "Epoch 3, Step 24460: Loss = 0.36155271530151367\n",
            "Epoch 3, Step 24461: Loss = 0.39367735385894775\n",
            "Epoch 3, Step 24462: Loss = 0.38293391466140747\n",
            "Epoch 3, Step 24463: Loss = 0.2700616121292114\n",
            "Epoch 3, Step 24464: Loss = 0.2641846239566803\n",
            "Epoch 3, Step 24465: Loss = 0.22561903297901154\n",
            "Epoch 3, Step 24466: Loss = 0.2542426884174347\n",
            "Epoch 3, Step 24467: Loss = 0.5444751381874084\n",
            "Epoch 3, Step 24468: Loss = 0.5076744556427002\n",
            "Epoch 3, Step 24469: Loss = 0.28911536931991577\n",
            "Epoch 3, Step 24470: Loss = 0.3562332093715668\n",
            "Epoch 3, Step 24471: Loss = 0.4294460117816925\n",
            "Epoch 3, Step 24472: Loss = 0.3084225058555603\n",
            "Epoch 3, Step 24473: Loss = 0.535979688167572\n",
            "Epoch 3, Step 24474: Loss = 0.32935553789138794\n",
            "Epoch 3, Step 24475: Loss = 0.3915034234523773\n",
            "Epoch 3, Step 24476: Loss = 0.40418383479118347\n",
            "Epoch 3, Step 24477: Loss = 0.5342491269111633\n",
            "Epoch 3, Step 24478: Loss = 0.27152207493782043\n",
            "Epoch 3, Step 24479: Loss = 0.4772959053516388\n",
            "Epoch 3, Step 24480: Loss = 0.6135163307189941\n",
            "Epoch 3, Step 24481: Loss = 0.19659923017024994\n",
            "Epoch 3, Step 24482: Loss = 0.31888043880462646\n",
            "Epoch 3, Step 24483: Loss = 0.44255363941192627\n",
            "Epoch 3, Step 24484: Loss = 0.30518147349357605\n",
            "Epoch 3, Step 24485: Loss = 0.3487016260623932\n",
            "Epoch 3, Step 24486: Loss = 0.14688022434711456\n",
            "Epoch 3, Step 24487: Loss = 0.1783626675605774\n",
            "Epoch 3, Step 24488: Loss = 0.192725270986557\n",
            "Epoch 3, Step 24489: Loss = 0.17318689823150635\n",
            "Epoch 3, Step 24490: Loss = 0.3445199429988861\n",
            "Epoch 3, Step 24491: Loss = 0.2867061197757721\n",
            "Epoch 3, Step 24492: Loss = 0.33348068594932556\n",
            "Epoch 3, Step 24493: Loss = 0.5333369374275208\n",
            "Epoch 3, Step 24494: Loss = 0.29546141624450684\n",
            "Epoch 3, Step 24495: Loss = 0.3634502589702606\n",
            "Epoch 3, Step 24496: Loss = 0.26014479994773865\n",
            "Epoch 3, Step 24497: Loss = 0.16748811304569244\n",
            "Epoch 3, Step 24498: Loss = 0.4021304249763489\n",
            "Epoch 3, Step 24499: Loss = 0.34122785925865173\n",
            "Epoch 3, Step 24500: Loss = 0.40170779824256897\n",
            "Epoch 3, Step 24501: Loss = 0.28759172558784485\n",
            "Epoch 3, Step 24502: Loss = 0.3604198694229126\n",
            "Epoch 3, Step 24503: Loss = 0.42238929867744446\n",
            "Epoch 3, Step 24504: Loss = 0.3134685754776001\n",
            "Epoch 3, Step 24505: Loss = 0.6648286581039429\n",
            "Epoch 3, Step 24506: Loss = 0.19497820734977722\n",
            "Epoch 3, Step 24507: Loss = 0.44382622838020325\n",
            "Epoch 3, Step 24508: Loss = 0.44929537177085876\n",
            "Epoch 3, Step 24509: Loss = 0.463114857673645\n",
            "Epoch 3, Step 24510: Loss = 0.2479204535484314\n",
            "Epoch 3, Step 24511: Loss = 0.5062265992164612\n",
            "Epoch 3, Step 24512: Loss = 0.18499508500099182\n",
            "Epoch 3, Step 24513: Loss = 0.2865395247936249\n",
            "Epoch 3, Step 24514: Loss = 0.2625453472137451\n",
            "Epoch 3, Step 24515: Loss = 0.3863006830215454\n",
            "Epoch 3, Step 24516: Loss = 0.4292834997177124\n",
            "Epoch 3, Step 24517: Loss = 0.3209981620311737\n",
            "Epoch 3, Step 24518: Loss = 0.25706255435943604\n",
            "Epoch 3, Step 24519: Loss = 0.4269694685935974\n",
            "Epoch 3, Step 24520: Loss = 0.42248690128326416\n",
            "Epoch 3, Step 24521: Loss = 0.437945693731308\n",
            "Epoch 3, Step 24522: Loss = 0.3742719888687134\n",
            "Epoch 3, Step 24523: Loss = 0.5168080925941467\n",
            "Epoch 3, Step 24524: Loss = 0.4680955410003662\n",
            "Epoch 3, Step 24525: Loss = 0.22528915107250214\n",
            "Epoch 3, Step 24526: Loss = 0.29254665970802307\n",
            "Epoch 3, Step 24527: Loss = 0.27341753244400024\n",
            "Epoch 3, Step 24528: Loss = 0.1857692003250122\n",
            "Epoch 3, Step 24529: Loss = 0.3611617088317871\n",
            "Epoch 3, Step 24530: Loss = 0.24593853950500488\n",
            "Epoch 3, Step 24531: Loss = 0.32209673523902893\n",
            "Epoch 3, Step 24532: Loss = 0.21684446930885315\n",
            "Epoch 3, Step 24533: Loss = 0.6113053560256958\n",
            "Epoch 3, Step 24534: Loss = 0.2610554099082947\n",
            "Epoch 3, Step 24535: Loss = 0.3054676651954651\n",
            "Epoch 3, Step 24536: Loss = 0.17662551999092102\n",
            "Epoch 3, Step 24537: Loss = 0.2977122962474823\n",
            "Epoch 3, Step 24538: Loss = 0.3464241027832031\n",
            "Epoch 3, Step 24539: Loss = 0.21937598288059235\n",
            "Epoch 3, Step 24540: Loss = 0.1738775074481964\n",
            "Epoch 3, Step 24541: Loss = 0.3592991232872009\n",
            "Epoch 3, Step 24542: Loss = 0.4409947991371155\n",
            "Epoch 3, Step 24543: Loss = 0.2925163209438324\n",
            "Epoch 3, Step 24544: Loss = 0.6868480443954468\n",
            "Epoch 3, Step 24545: Loss = 0.48123234510421753\n",
            "Epoch 3, Step 24546: Loss = 0.33535003662109375\n",
            "Epoch 3, Step 24547: Loss = 0.1760505884885788\n",
            "Epoch 3, Step 24548: Loss = 0.1575826108455658\n",
            "Epoch 3, Step 24549: Loss = 0.4728030860424042\n",
            "Epoch 3, Step 24550: Loss = 0.2567468583583832\n",
            "Epoch 3, Step 24551: Loss = 0.6443985104560852\n",
            "Epoch 3, Step 24552: Loss = 0.3067384660243988\n",
            "Epoch 3, Step 24553: Loss = 0.28486818075180054\n",
            "Epoch 3, Step 24554: Loss = 0.21939261257648468\n",
            "Epoch 3, Step 24555: Loss = 0.1689002364873886\n",
            "Epoch 3, Step 24556: Loss = 0.29187625646591187\n",
            "Epoch 3, Step 24557: Loss = 0.3305479884147644\n",
            "Epoch 3, Step 24558: Loss = 0.3390720784664154\n",
            "Epoch 3, Step 24559: Loss = 0.31126323342323303\n",
            "Epoch 3, Step 24560: Loss = 0.18388034403324127\n",
            "Epoch 3, Step 24561: Loss = 0.4105808436870575\n",
            "Epoch 3, Step 24562: Loss = 0.32874226570129395\n",
            "Epoch 3, Step 24563: Loss = 0.34062111377716064\n",
            "Epoch 3, Step 24564: Loss = 0.24686554074287415\n",
            "Epoch 3, Step 24565: Loss = 0.4495658576488495\n",
            "Epoch 3, Step 24566: Loss = 0.41364261507987976\n",
            "Epoch 3, Step 24567: Loss = 0.5272752046585083\n",
            "Epoch 3, Step 24568: Loss = 0.21339374780654907\n",
            "Epoch 3, Step 24569: Loss = 0.3268668055534363\n",
            "Epoch 3, Step 24570: Loss = 0.3078135848045349\n",
            "Epoch 3, Step 24571: Loss = 0.1680181324481964\n",
            "Epoch 3, Step 24572: Loss = 0.5535179376602173\n",
            "Epoch 3, Step 24573: Loss = 0.37467852234840393\n",
            "Epoch 3, Step 24574: Loss = 0.6912772059440613\n",
            "Epoch 3, Step 24575: Loss = 0.28459078073501587\n",
            "Epoch 3, Step 24576: Loss = 0.5450093150138855\n",
            "Epoch 3, Step 24577: Loss = 0.47249937057495117\n",
            "Epoch 3, Step 24578: Loss = 0.35626766085624695\n",
            "Epoch 3, Step 24579: Loss = 0.2657070457935333\n",
            "Epoch 3, Step 24580: Loss = 0.48557817935943604\n",
            "Epoch 3, Step 24581: Loss = 0.1734284907579422\n",
            "Epoch 3, Step 24582: Loss = 0.4070119559764862\n",
            "Epoch 3, Step 24583: Loss = 0.25914672017097473\n",
            "Epoch 3, Step 24584: Loss = 0.358639657497406\n",
            "Epoch 3, Step 24585: Loss = 0.30080509185791016\n",
            "Epoch 3, Step 24586: Loss = 0.27141454815864563\n",
            "Epoch 3, Step 24587: Loss = 0.35509729385375977\n",
            "Epoch 3, Step 24588: Loss = 0.3389571011066437\n",
            "Epoch 3, Step 24589: Loss = 0.28724050521850586\n",
            "Epoch 3, Step 24590: Loss = 0.3478778898715973\n",
            "Epoch 3, Step 24591: Loss = 0.23177789151668549\n",
            "Epoch 3, Step 24592: Loss = 0.9641538858413696\n",
            "Epoch 3, Step 24593: Loss = 0.9969320893287659\n",
            "Epoch 3, Step 24594: Loss = 0.3377557098865509\n",
            "Epoch 3, Step 24595: Loss = 0.430181622505188\n",
            "Epoch 3, Step 24596: Loss = 0.3683093190193176\n",
            "Epoch 3, Step 24597: Loss = 0.32215338945388794\n",
            "Epoch 3, Step 24598: Loss = 0.4217088520526886\n",
            "Epoch 3, Step 24599: Loss = 0.2941955327987671\n",
            "Epoch 3, Step 24600: Loss = 0.2043484002351761\n",
            "Epoch 3, Step 24601: Loss = 0.12971165776252747\n",
            "Epoch 3, Step 24602: Loss = 0.4201575219631195\n",
            "Epoch 3, Step 24603: Loss = 0.48129090666770935\n",
            "Epoch 3, Step 24604: Loss = 0.39552804827690125\n",
            "Epoch 3, Step 24605: Loss = 0.3550707995891571\n",
            "Epoch 3, Step 24606: Loss = 0.2767162024974823\n",
            "Epoch 3, Step 24607: Loss = 0.346929132938385\n",
            "Epoch 3, Step 24608: Loss = 0.22396939992904663\n",
            "Epoch 3, Step 24609: Loss = 0.3453189432621002\n",
            "Epoch 3, Step 24610: Loss = 0.3030950129032135\n",
            "Epoch 3, Step 24611: Loss = 0.132308691740036\n",
            "Epoch 3, Step 24612: Loss = 0.41957399249076843\n",
            "Epoch 3, Step 24613: Loss = 0.39429184794425964\n",
            "Epoch 3, Step 24614: Loss = 0.21014054119586945\n",
            "Epoch 3, Step 24615: Loss = 0.2926310896873474\n",
            "Epoch 3, Step 24616: Loss = 0.12998029589653015\n",
            "Epoch 3, Step 24617: Loss = 0.2507849335670471\n",
            "Epoch 3, Step 24618: Loss = 0.5936159491539001\n",
            "Epoch 3, Step 24619: Loss = 0.4750003516674042\n",
            "Epoch 3, Step 24620: Loss = 0.2754006087779999\n",
            "Epoch 3, Step 24621: Loss = 0.45618975162506104\n",
            "Epoch 3, Step 24622: Loss = 0.47274544835090637\n",
            "Epoch 3, Step 24623: Loss = 0.2577950060367584\n",
            "Epoch 3, Step 24624: Loss = 0.22986546158790588\n",
            "Epoch 3, Step 24625: Loss = 0.4634227156639099\n",
            "Epoch 3, Step 24626: Loss = 0.48958295583724976\n",
            "Epoch 3, Step 24627: Loss = 0.2838810682296753\n",
            "Epoch 3, Step 24628: Loss = 0.34315967559814453\n",
            "Epoch 3, Step 24629: Loss = 0.3391261100769043\n",
            "Epoch 3, Step 24630: Loss = 0.26238322257995605\n",
            "Epoch 3, Step 24631: Loss = 0.30751895904541016\n",
            "Epoch 3, Step 24632: Loss = 0.24154208600521088\n",
            "Epoch 3, Step 24633: Loss = 0.5212175846099854\n",
            "Epoch 3, Step 24634: Loss = 0.3043377697467804\n",
            "Epoch 3, Step 24635: Loss = 0.33655673265457153\n",
            "Epoch 3, Step 24636: Loss = 0.3434043526649475\n",
            "Epoch 3, Step 24637: Loss = 0.6298876404762268\n",
            "Epoch 3, Step 24638: Loss = 0.2204349935054779\n",
            "Epoch 3, Step 24639: Loss = 0.32991281151771545\n",
            "Epoch 3, Step 24640: Loss = 0.1627202033996582\n",
            "Epoch 3, Step 24641: Loss = 0.42066332697868347\n",
            "Epoch 3, Step 24642: Loss = 0.17427662014961243\n",
            "Epoch 3, Step 24643: Loss = 0.24629907310009003\n",
            "Epoch 3, Step 24644: Loss = 0.35754358768463135\n",
            "Epoch 3, Step 24645: Loss = 0.20025727152824402\n",
            "Epoch 3, Step 24646: Loss = 0.41574957966804504\n",
            "Epoch 3, Step 24647: Loss = 0.1477172076702118\n",
            "Epoch 3, Step 24648: Loss = 0.24267585575580597\n",
            "Epoch 3, Step 24649: Loss = 0.25936463475227356\n",
            "Epoch 3, Step 24650: Loss = 0.37892410159111023\n",
            "Epoch 3, Step 24651: Loss = 0.2682272493839264\n",
            "Epoch 3, Step 24652: Loss = 0.289492130279541\n",
            "Epoch 3, Step 24653: Loss = 0.42677053809165955\n",
            "Epoch 3, Step 24654: Loss = 0.31548693776130676\n",
            "Epoch 3, Step 24655: Loss = 0.17169348895549774\n",
            "Epoch 3, Step 24656: Loss = 0.5619356632232666\n",
            "Epoch 3, Step 24657: Loss = 0.18660429120063782\n",
            "Epoch 3, Step 24658: Loss = 0.3579837381839752\n",
            "Epoch 3, Step 24659: Loss = 0.31191617250442505\n",
            "Epoch 3, Step 24660: Loss = 0.4473966062068939\n",
            "Epoch 3, Step 24661: Loss = 0.16680733859539032\n",
            "Epoch 3, Step 24662: Loss = 0.30218470096588135\n",
            "Epoch 3, Step 24663: Loss = 0.20304392278194427\n",
            "Epoch 3, Step 24664: Loss = 0.310263067483902\n",
            "Epoch 3, Step 24665: Loss = 0.19299638271331787\n",
            "Epoch 3, Step 24666: Loss = 0.27366137504577637\n",
            "Epoch 3, Step 24667: Loss = 0.2313830405473709\n",
            "Epoch 3, Step 24668: Loss = 0.246010884642601\n",
            "Epoch 3, Step 24669: Loss = 0.2532578110694885\n",
            "Epoch 3, Step 24670: Loss = 0.2446369081735611\n",
            "Epoch 3, Step 24671: Loss = 0.36253607273101807\n",
            "Epoch 3, Step 24672: Loss = 0.38778191804885864\n",
            "Epoch 3, Step 24673: Loss = 0.26227545738220215\n",
            "Epoch 3, Step 24674: Loss = 0.2817533612251282\n",
            "Epoch 3, Step 24675: Loss = 0.6469758152961731\n",
            "Epoch 3, Step 24676: Loss = 0.6385805010795593\n",
            "Epoch 3, Step 24677: Loss = 0.2813672423362732\n",
            "Epoch 3, Step 24678: Loss = 0.3079438805580139\n",
            "Epoch 3, Step 24679: Loss = 0.3472898006439209\n",
            "Epoch 3, Step 24680: Loss = 0.2563687860965729\n",
            "Epoch 3, Step 24681: Loss = 0.2135472446680069\n",
            "Epoch 3, Step 24682: Loss = 0.4384269714355469\n",
            "Epoch 3, Step 24683: Loss = 0.52210932970047\n",
            "Epoch 3, Step 24684: Loss = 0.3573232591152191\n",
            "Epoch 3, Step 24685: Loss = 0.483584463596344\n",
            "Epoch 3, Step 24686: Loss = 0.3033992648124695\n",
            "Epoch 3, Step 24687: Loss = 0.26317068934440613\n",
            "Epoch 3, Step 24688: Loss = 0.303960382938385\n",
            "Epoch 3, Step 24689: Loss = 0.2527816593647003\n",
            "Epoch 3, Step 24690: Loss = 0.23655259609222412\n",
            "Epoch 3, Step 24691: Loss = 0.3022248446941376\n",
            "Epoch 3, Step 24692: Loss = 0.3856979310512543\n",
            "Epoch 3, Step 24693: Loss = 0.2734817564487457\n",
            "Epoch 3, Step 24694: Loss = 0.4724922776222229\n",
            "Epoch 3, Step 24695: Loss = 0.34346359968185425\n",
            "Epoch 3, Step 24696: Loss = 0.20882785320281982\n",
            "Epoch 3, Step 24697: Loss = 0.2119809240102768\n",
            "Epoch 3, Step 24698: Loss = 0.29580721259117126\n",
            "Epoch 3, Step 24699: Loss = 0.5778170824050903\n",
            "Epoch 3, Step 24700: Loss = 0.437105268239975\n",
            "Epoch 3, Step 24701: Loss = 0.2548210620880127\n",
            "Epoch 3, Step 24702: Loss = 0.21540872752666473\n",
            "Epoch 3, Step 24703: Loss = 0.4474969804286957\n",
            "Epoch 3, Step 24704: Loss = 0.5567782521247864\n",
            "Epoch 3, Step 24705: Loss = 0.4086773991584778\n",
            "Epoch 3, Step 24706: Loss = 0.4840884506702423\n",
            "Epoch 3, Step 24707: Loss = 0.33740711212158203\n",
            "Epoch 3, Step 24708: Loss = 0.4461670517921448\n",
            "Epoch 3, Step 24709: Loss = 0.2763020992279053\n",
            "Epoch 3, Step 24710: Loss = 0.3464570641517639\n",
            "Epoch 3, Step 24711: Loss = 0.7266054153442383\n",
            "Epoch 3, Step 24712: Loss = 0.49050045013427734\n",
            "Epoch 3, Step 24713: Loss = 0.44183430075645447\n",
            "Epoch 3, Step 24714: Loss = 0.4163476526737213\n",
            "Epoch 3, Step 24715: Loss = 0.3560212254524231\n",
            "Epoch 3, Step 24716: Loss = 0.233407124876976\n",
            "Epoch 3, Step 24717: Loss = 0.198797345161438\n",
            "Epoch 3, Step 24718: Loss = 0.31777891516685486\n",
            "Epoch 3, Step 24719: Loss = 0.26991796493530273\n",
            "Epoch 3, Step 24720: Loss = 0.26690199971199036\n",
            "Epoch 3, Step 24721: Loss = 0.2826976776123047\n",
            "Epoch 3, Step 24722: Loss = 0.2626449465751648\n",
            "Epoch 3, Step 24723: Loss = 0.42159292101860046\n",
            "Epoch 3, Step 24724: Loss = 0.3869926631450653\n",
            "Epoch 3, Step 24725: Loss = 0.47144803404808044\n",
            "Epoch 3, Step 24726: Loss = 0.21959154307842255\n",
            "Epoch 3, Step 24727: Loss = 0.36217063665390015\n",
            "Epoch 3, Step 24728: Loss = 0.23930247128009796\n",
            "Epoch 3, Step 24729: Loss = 0.17101408541202545\n",
            "Epoch 3, Step 24730: Loss = 0.4149854779243469\n",
            "Epoch 3, Step 24731: Loss = 0.1415553092956543\n",
            "Epoch 3, Step 24732: Loss = 0.39922356605529785\n",
            "Epoch 3, Step 24733: Loss = 0.26333096623420715\n",
            "Epoch 3, Step 24734: Loss = 0.3960425853729248\n",
            "Epoch 3, Step 24735: Loss = 0.23398196697235107\n",
            "Epoch 3, Step 24736: Loss = 0.4464724361896515\n",
            "Epoch 3, Step 24737: Loss = 0.4761489927768707\n",
            "Epoch 3, Step 24738: Loss = 0.30940720438957214\n",
            "Epoch 3, Step 24739: Loss = 0.3098265826702118\n",
            "Epoch 3, Step 24740: Loss = 0.44506946206092834\n",
            "Epoch 3, Step 24741: Loss = 0.2351921945810318\n",
            "Epoch 3, Step 24742: Loss = 0.27536264061927795\n",
            "Epoch 3, Step 24743: Loss = 0.2296948879957199\n",
            "Epoch 3, Step 24744: Loss = 0.48197633028030396\n",
            "Epoch 3, Step 24745: Loss = 0.25763851404190063\n",
            "Epoch 3, Step 24746: Loss = 0.22100211679935455\n",
            "Epoch 3, Step 24747: Loss = 0.36896079778671265\n",
            "Epoch 3, Step 24748: Loss = 0.21704232692718506\n",
            "Epoch 3, Step 24749: Loss = 0.2369341105222702\n",
            "Epoch 3, Step 24750: Loss = 0.2844007909297943\n",
            "Epoch 3, Step 24751: Loss = 0.28825995326042175\n",
            "Epoch 3, Step 24752: Loss = 0.3302142322063446\n",
            "Epoch 3, Step 24753: Loss = 0.16400842368602753\n",
            "Epoch 3, Step 24754: Loss = 0.12544867396354675\n",
            "Epoch 3, Step 24755: Loss = 0.5742226839065552\n",
            "Epoch 3, Step 24756: Loss = 0.2620754837989807\n",
            "Epoch 3, Step 24757: Loss = 0.18473105132579803\n",
            "Epoch 3, Step 24758: Loss = 0.2788987457752228\n",
            "Epoch 3, Step 24759: Loss = 0.2992284595966339\n",
            "Epoch 3, Step 24760: Loss = 0.2704511284828186\n",
            "Epoch 3, Step 24761: Loss = 0.21978770196437836\n",
            "Epoch 3, Step 24762: Loss = 0.30807366967201233\n",
            "Epoch 3, Step 24763: Loss = 0.29759812355041504\n",
            "Epoch 3, Step 24764: Loss = 0.29100385308265686\n",
            "Epoch 3, Step 24765: Loss = 0.25307202339172363\n",
            "Epoch 3, Step 24766: Loss = 0.4738791882991791\n",
            "Epoch 3, Step 24767: Loss = 0.31480592489242554\n",
            "Epoch 3, Step 24768: Loss = 0.3665526807308197\n",
            "Epoch 3, Step 24769: Loss = 0.19663994014263153\n",
            "Epoch 3, Step 24770: Loss = 0.28141215443611145\n",
            "Epoch 3, Step 24771: Loss = 0.31408414244651794\n",
            "Epoch 3, Step 24772: Loss = 0.4741743206977844\n",
            "Epoch 3, Step 24773: Loss = 0.344551682472229\n",
            "Epoch 3, Step 24774: Loss = 0.27749478816986084\n",
            "Epoch 3, Step 24775: Loss = 0.6267208456993103\n",
            "Epoch 3, Step 24776: Loss = 0.6069678068161011\n",
            "Epoch 3, Step 24777: Loss = 0.2933982014656067\n",
            "Epoch 3, Step 24778: Loss = 0.32667213678359985\n",
            "Epoch 3, Step 24779: Loss = 0.2724105715751648\n",
            "Epoch 3, Step 24780: Loss = 0.2591165602207184\n",
            "Epoch 3, Step 24781: Loss = 0.2949990928173065\n",
            "Epoch 3, Step 24782: Loss = 0.2912144064903259\n",
            "Epoch 3, Step 24783: Loss = 0.33294248580932617\n",
            "Epoch 3, Step 24784: Loss = 0.24802067875862122\n",
            "Epoch 3, Step 24785: Loss = 0.2726879119873047\n",
            "Epoch 3, Step 24786: Loss = 0.3078164756298065\n",
            "Epoch 3, Step 24787: Loss = 0.300265371799469\n",
            "Epoch 3, Step 24788: Loss = 0.2769748568534851\n",
            "Epoch 3, Step 24789: Loss = 0.34499818086624146\n",
            "Epoch 3, Step 24790: Loss = 0.1923619508743286\n",
            "Epoch 3, Step 24791: Loss = 0.6108161211013794\n",
            "Epoch 3, Step 24792: Loss = 0.3390856981277466\n",
            "Epoch 3, Step 24793: Loss = 0.387128084897995\n",
            "Epoch 3, Step 24794: Loss = 0.2867114841938019\n",
            "Epoch 3, Step 24795: Loss = 0.44735270738601685\n",
            "Epoch 3, Step 24796: Loss = 0.27335822582244873\n",
            "Epoch 3, Step 24797: Loss = 0.24047474563121796\n",
            "Epoch 3, Step 24798: Loss = 0.30456438660621643\n",
            "Epoch 3, Step 24799: Loss = 0.34698083996772766\n",
            "Epoch 3, Step 24800: Loss = 0.7035216689109802\n",
            "Epoch 3, Step 24801: Loss = 0.506492018699646\n",
            "Epoch 3, Step 24802: Loss = 0.7307539582252502\n",
            "Epoch 3, Step 24803: Loss = 0.4227716326713562\n",
            "Epoch 3, Step 24804: Loss = 0.28494539856910706\n",
            "Epoch 3, Step 24805: Loss = 0.22096122801303864\n",
            "Epoch 3, Step 24806: Loss = 0.4754129946231842\n",
            "Epoch 3, Step 24807: Loss = 0.24843651056289673\n",
            "Epoch 3, Step 24808: Loss = 0.26126301288604736\n",
            "Epoch 3, Step 24809: Loss = 0.25023630261421204\n",
            "Epoch 3, Step 24810: Loss = 0.4282935559749603\n",
            "Epoch 3, Step 24811: Loss = 0.4461453855037689\n",
            "Epoch 3, Step 24812: Loss = 0.4243237376213074\n",
            "Epoch 3, Step 24813: Loss = 0.2047535926103592\n",
            "Epoch 3, Step 24814: Loss = 0.3520699739456177\n",
            "Epoch 3, Step 24815: Loss = 0.4381256103515625\n",
            "Epoch 3, Step 24816: Loss = 0.25429514050483704\n",
            "Epoch 3, Step 24817: Loss = 0.31942564249038696\n",
            "Epoch 3, Step 24818: Loss = 0.22978031635284424\n",
            "Epoch 3, Step 24819: Loss = 0.2888583838939667\n",
            "Epoch 3, Step 24820: Loss = 0.43082764744758606\n",
            "Epoch 3, Step 24821: Loss = 0.41687729954719543\n",
            "Epoch 3, Step 24822: Loss = 0.48898372054100037\n",
            "Epoch 3, Step 24823: Loss = 0.17739830911159515\n",
            "Epoch 3, Step 24824: Loss = 0.19736388325691223\n",
            "Epoch 3, Step 24825: Loss = 0.2915792167186737\n",
            "Epoch 3, Step 24826: Loss = 0.39241960644721985\n",
            "Epoch 3, Step 24827: Loss = 0.2842761278152466\n",
            "Epoch 3, Step 24828: Loss = 0.3548985421657562\n",
            "Epoch 3, Step 24829: Loss = 0.12133911997079849\n",
            "Epoch 3, Step 24830: Loss = 0.189570814371109\n",
            "Epoch 3, Step 24831: Loss = 0.3719716966152191\n",
            "Epoch 3, Step 24832: Loss = 0.5089030265808105\n",
            "Epoch 3, Step 24833: Loss = 0.22227509319782257\n",
            "Epoch 3, Step 24834: Loss = 0.1948131024837494\n",
            "Epoch 3, Step 24835: Loss = 0.3916022777557373\n",
            "Epoch 3, Step 24836: Loss = 0.2562715709209442\n",
            "Epoch 3, Step 24837: Loss = 0.3391820192337036\n",
            "Epoch 3, Step 24838: Loss = 0.5247259140014648\n",
            "Epoch 3, Step 24839: Loss = 0.15050776302814484\n",
            "Epoch 3, Step 24840: Loss = 0.435348778963089\n",
            "Epoch 3, Step 24841: Loss = 0.5997034311294556\n",
            "Epoch 3, Step 24842: Loss = 0.5963498950004578\n",
            "Epoch 3, Step 24843: Loss = 0.4413307011127472\n",
            "Epoch 3, Step 24844: Loss = 0.3867843449115753\n",
            "Epoch 3, Step 24845: Loss = 0.5032883882522583\n",
            "Epoch 3, Step 24846: Loss = 0.5526592135429382\n",
            "Epoch 3, Step 24847: Loss = 0.38906338810920715\n",
            "Epoch 3, Step 24848: Loss = 0.433782696723938\n",
            "Epoch 3, Step 24849: Loss = 0.5216292142868042\n",
            "Epoch 3, Step 24850: Loss = 0.46355366706848145\n",
            "Epoch 3, Step 24851: Loss = 0.3630470633506775\n",
            "Epoch 3, Step 24852: Loss = 0.182354137301445\n",
            "Epoch 3, Step 24853: Loss = 0.12655822932720184\n",
            "Epoch 3, Step 24854: Loss = 0.35496872663497925\n",
            "Epoch 3, Step 24855: Loss = 0.25544145703315735\n",
            "Epoch 3, Step 24856: Loss = 0.3747224807739258\n",
            "Epoch 3, Step 24857: Loss = 0.17515632510185242\n",
            "Epoch 3, Step 24858: Loss = 0.3170652985572815\n",
            "Epoch 3, Step 24859: Loss = 0.3710237741470337\n",
            "Epoch 3, Step 24860: Loss = 0.4178830087184906\n",
            "Epoch 3, Step 24861: Loss = 0.3625287711620331\n",
            "Epoch 3, Step 24862: Loss = 0.3862271010875702\n",
            "Epoch 3, Step 24863: Loss = 0.2064637541770935\n",
            "Epoch 3, Step 24864: Loss = 0.20916205644607544\n",
            "Epoch 3, Step 24865: Loss = 0.36559733748435974\n",
            "Epoch 3, Step 24866: Loss = 0.3468901216983795\n",
            "Epoch 3, Step 24867: Loss = 0.2951045036315918\n",
            "Epoch 3, Step 24868: Loss = 0.2505747675895691\n",
            "Epoch 3, Step 24869: Loss = 0.2812466025352478\n",
            "Epoch 3, Step 24870: Loss = 0.22393463551998138\n",
            "Epoch 3, Step 24871: Loss = 0.2587687075138092\n",
            "Epoch 3, Step 24872: Loss = 0.2937760353088379\n",
            "Epoch 3, Step 24873: Loss = 0.4909050166606903\n",
            "Epoch 3, Step 24874: Loss = 0.36751559376716614\n",
            "Epoch 3, Step 24875: Loss = 0.3203912377357483\n",
            "Epoch 3, Step 24876: Loss = 0.1237075924873352\n",
            "Epoch 3, Step 24877: Loss = 0.23957672715187073\n",
            "Epoch 3, Step 24878: Loss = 0.3491320013999939\n",
            "Epoch 3, Step 24879: Loss = 0.1993981897830963\n",
            "Epoch 3, Step 24880: Loss = 0.3307642936706543\n",
            "Epoch 3, Step 24881: Loss = 0.18194766342639923\n",
            "Epoch 3, Step 24882: Loss = 0.2274298369884491\n",
            "Epoch 3, Step 24883: Loss = 0.2516096532344818\n",
            "Epoch 3, Step 24884: Loss = 0.36517542600631714\n",
            "Epoch 3, Step 24885: Loss = 0.45222461223602295\n",
            "Epoch 3, Step 24886: Loss = 0.21950313448905945\n",
            "Epoch 3, Step 24887: Loss = 0.40354782342910767\n",
            "Epoch 3, Step 24888: Loss = 0.1278517246246338\n",
            "Epoch 3, Step 24889: Loss = 0.3201582729816437\n",
            "Epoch 3, Step 24890: Loss = 0.328788697719574\n",
            "Epoch 3, Step 24891: Loss = 0.41191935539245605\n",
            "Epoch 3, Step 24892: Loss = 0.31374332308769226\n",
            "Epoch 3, Step 24893: Loss = 0.3311569094657898\n",
            "Epoch 3, Step 24894: Loss = 0.3179553747177124\n",
            "Epoch 3, Step 24895: Loss = 0.3617037534713745\n",
            "Epoch 3, Step 24896: Loss = 0.17637400329113007\n",
            "Epoch 3, Step 24897: Loss = 0.3164515495300293\n",
            "Epoch 3, Step 24898: Loss = 0.3721908926963806\n",
            "Epoch 3, Step 24899: Loss = 0.2431102991104126\n",
            "Epoch 3, Step 24900: Loss = 0.2642146050930023\n",
            "Epoch 3, Step 24901: Loss = 0.16933679580688477\n",
            "Epoch 3, Step 24902: Loss = 0.39867180585861206\n",
            "Epoch 3, Step 24903: Loss = 0.3982488512992859\n",
            "Epoch 3, Step 24904: Loss = 0.4295673668384552\n",
            "Epoch 3, Step 24905: Loss = 0.3786429762840271\n",
            "Epoch 3, Step 24906: Loss = 0.3349451422691345\n",
            "Epoch 3, Step 24907: Loss = 0.3643924295902252\n",
            "Epoch 3, Step 24908: Loss = 0.46451109647750854\n",
            "Epoch 3, Step 24909: Loss = 0.39975836873054504\n",
            "Epoch 3, Step 24910: Loss = 0.6661949157714844\n",
            "Epoch 3, Step 24911: Loss = 0.2198999524116516\n",
            "Epoch 3, Step 24912: Loss = 0.31390807032585144\n",
            "Epoch 3, Step 24913: Loss = 0.41018715500831604\n",
            "Epoch 3, Step 24914: Loss = 0.4823284447193146\n",
            "Epoch 3, Step 24915: Loss = 0.28463056683540344\n",
            "Epoch 3, Step 24916: Loss = 0.23850467801094055\n",
            "Epoch 3, Step 24917: Loss = 0.3949175179004669\n",
            "Epoch 3, Step 24918: Loss = 0.33323734998703003\n",
            "Epoch 3, Step 24919: Loss = 0.4511044919490814\n",
            "Epoch 3, Step 24920: Loss = 0.2929500341415405\n",
            "Epoch 3, Step 24921: Loss = 0.31874004006385803\n",
            "Epoch 3, Step 24922: Loss = 0.16535717248916626\n",
            "Epoch 3, Step 24923: Loss = 0.5602989792823792\n",
            "Epoch 3, Step 24924: Loss = 0.3414282500743866\n",
            "Epoch 3, Step 24925: Loss = 0.3276124894618988\n",
            "Epoch 3, Step 24926: Loss = 0.35271981358528137\n",
            "Epoch 3, Step 24927: Loss = 0.35875096917152405\n",
            "Epoch 3, Step 24928: Loss = 0.3151320517063141\n",
            "Epoch 3, Step 24929: Loss = 0.284675270318985\n",
            "Epoch 3, Step 24930: Loss = 0.479397714138031\n",
            "Epoch 3, Step 24931: Loss = 0.27348050475120544\n",
            "Epoch 3, Step 24932: Loss = 0.18173469603061676\n",
            "Epoch 3, Step 24933: Loss = 0.3606477975845337\n",
            "Epoch 3, Step 24934: Loss = 0.2892167270183563\n",
            "Epoch 3, Step 24935: Loss = 0.3962390124797821\n",
            "Epoch 3, Step 24936: Loss = 0.7311895489692688\n",
            "Epoch 3, Step 24937: Loss = 0.3097776472568512\n",
            "Epoch 3, Step 24938: Loss = 0.1946953982114792\n",
            "Epoch 3, Step 24939: Loss = 0.3055950999259949\n",
            "Epoch 3, Step 24940: Loss = 0.38311800360679626\n",
            "Epoch 3, Step 24941: Loss = 0.6114876866340637\n",
            "Epoch 3, Step 24942: Loss = 0.325469046831131\n",
            "Epoch 3, Step 24943: Loss = 0.2614063322544098\n",
            "Epoch 3, Step 24944: Loss = 0.27241748571395874\n",
            "Epoch 3, Step 24945: Loss = 0.23749537765979767\n",
            "Epoch 3, Step 24946: Loss = 0.30127018690109253\n",
            "Epoch 3, Step 24947: Loss = 0.29720643162727356\n",
            "Epoch 3, Step 24948: Loss = 0.1979147046804428\n",
            "Epoch 3, Step 24949: Loss = 0.13379471004009247\n",
            "Epoch 3, Step 24950: Loss = 0.34234654903411865\n",
            "Epoch 3, Step 24951: Loss = 0.32826077938079834\n",
            "Epoch 3, Step 24952: Loss = 0.3319002687931061\n",
            "Epoch 3, Step 24953: Loss = 0.24250689148902893\n",
            "Epoch 3, Step 24954: Loss = 0.3381027579307556\n",
            "Epoch 3, Step 24955: Loss = 0.2914852201938629\n",
            "Epoch 3, Step 24956: Loss = 0.45609748363494873\n",
            "Epoch 3, Step 24957: Loss = 0.2323504537343979\n",
            "Epoch 3, Step 24958: Loss = 0.44514739513397217\n",
            "Epoch 3, Step 24959: Loss = 0.26421451568603516\n",
            "Epoch 3, Step 24960: Loss = 0.39528724551200867\n",
            "Epoch 3, Step 24961: Loss = 0.344539612531662\n",
            "Epoch 3, Step 24962: Loss = 0.256960391998291\n",
            "Epoch 3, Step 24963: Loss = 0.19852390885353088\n",
            "Epoch 3, Step 24964: Loss = 0.244557186961174\n",
            "Epoch 3, Step 24965: Loss = 0.26829788088798523\n",
            "Epoch 3, Step 24966: Loss = 0.4896126687526703\n",
            "Epoch 3, Step 24967: Loss = 0.25422435998916626\n",
            "Epoch 3, Step 24968: Loss = 0.19332414865493774\n",
            "Epoch 3, Step 24969: Loss = 0.3043610751628876\n",
            "Epoch 3, Step 24970: Loss = 0.35031095147132874\n",
            "Epoch 3, Step 24971: Loss = 0.7317671179771423\n",
            "Epoch 3, Step 24972: Loss = 0.34457927942276\n",
            "Epoch 3, Step 24973: Loss = 0.321476548910141\n",
            "Epoch 3, Step 24974: Loss = 0.31530094146728516\n",
            "Epoch 3, Step 24975: Loss = 0.374830961227417\n",
            "Epoch 3, Step 24976: Loss = 0.527655839920044\n",
            "Epoch 3, Step 24977: Loss = 0.4961976706981659\n",
            "Epoch 3, Step 24978: Loss = 0.25474634766578674\n",
            "Epoch 3, Step 24979: Loss = 0.5823718905448914\n",
            "Epoch 3, Step 24980: Loss = 0.36446717381477356\n",
            "Epoch 3, Step 24981: Loss = 0.1357499063014984\n",
            "Epoch 3, Step 24982: Loss = 0.11267586052417755\n",
            "Epoch 3, Step 24983: Loss = 0.3124242126941681\n",
            "Epoch 3, Step 24984: Loss = 0.5312439203262329\n",
            "Epoch 3, Step 24985: Loss = 0.5754203200340271\n",
            "Epoch 3, Step 24986: Loss = 0.40343308448791504\n",
            "Epoch 3, Step 24987: Loss = 0.3870358169078827\n",
            "Epoch 3, Step 24988: Loss = 0.28171485662460327\n",
            "Epoch 3, Step 24989: Loss = 0.5207296013832092\n",
            "Epoch 3, Step 24990: Loss = 0.22248566150665283\n",
            "Epoch 3, Step 24991: Loss = 0.2536352276802063\n",
            "Epoch 3, Step 24992: Loss = 0.24648885428905487\n",
            "Epoch 3, Step 24993: Loss = 0.3862946629524231\n",
            "Epoch 3, Step 24994: Loss = 0.3919539153575897\n",
            "Epoch 3, Step 24995: Loss = 0.5961141586303711\n",
            "Epoch 3, Step 24996: Loss = 0.3736281991004944\n",
            "Epoch 3, Step 24997: Loss = 0.3644898235797882\n",
            "Epoch 3, Step 24998: Loss = 0.41998928785324097\n",
            "Epoch 3, Step 24999: Loss = 0.21925348043441772\n",
            "Epoch 3, Step 25000: Loss = 0.2535143196582794\n",
            "Epoch 3, Step 25001: Loss = 0.24295251071453094\n",
            "Epoch 3, Step 25002: Loss = 0.39179104566574097\n",
            "Epoch 3, Step 25003: Loss = 0.48827898502349854\n",
            "Epoch 3, Step 25004: Loss = 0.366477370262146\n",
            "Epoch 3, Step 25005: Loss = 0.2940916419029236\n",
            "Epoch 3, Step 25006: Loss = 0.4865778088569641\n",
            "Epoch 3, Step 25007: Loss = 0.3099948465824127\n",
            "Epoch 3, Step 25008: Loss = 0.18209509551525116\n",
            "Epoch 3, Step 25009: Loss = 0.26829713582992554\n",
            "Epoch 3, Step 25010: Loss = 0.2349085658788681\n",
            "Epoch 3, Step 25011: Loss = 0.22079242765903473\n",
            "Epoch 3, Step 25012: Loss = 0.2067335546016693\n",
            "Epoch 3, Step 25013: Loss = 0.2741135060787201\n",
            "Epoch 3, Step 25014: Loss = 0.4787185490131378\n",
            "Epoch 3, Step 25015: Loss = 0.2479412853717804\n",
            "Epoch 3, Step 25016: Loss = 0.2914353311061859\n",
            "Epoch 3, Step 25017: Loss = 0.3182947337627411\n",
            "Epoch 3, Step 25018: Loss = 0.22548489272594452\n",
            "Epoch 3, Step 25019: Loss = 0.4967501759529114\n",
            "Epoch 3, Step 25020: Loss = 0.5189820528030396\n",
            "Epoch 3, Step 25021: Loss = 0.4080980718135834\n",
            "Epoch 3, Step 25022: Loss = 0.274137407541275\n",
            "Epoch 3, Step 25023: Loss = 0.2501547932624817\n",
            "Epoch 3, Step 25024: Loss = 0.3084830343723297\n",
            "Epoch 3, Step 25025: Loss = 0.23044303059577942\n",
            "Epoch 3, Step 25026: Loss = 0.3103424608707428\n",
            "Epoch 3, Step 25027: Loss = 0.32124486565589905\n",
            "Epoch 3, Step 25028: Loss = 0.26575344800949097\n",
            "Epoch 3, Step 25029: Loss = 0.3180711269378662\n",
            "Epoch 3, Step 25030: Loss = 0.23719848692417145\n",
            "Epoch 3, Step 25031: Loss = 0.15579620003700256\n",
            "Epoch 3, Step 25032: Loss = 0.3360957205295563\n",
            "Epoch 3, Step 25033: Loss = 0.2630597949028015\n",
            "Epoch 3, Step 25034: Loss = 0.19903336465358734\n",
            "Epoch 3, Step 25035: Loss = 0.3807217478752136\n",
            "Epoch 3, Step 25036: Loss = 0.2707843482494354\n",
            "Epoch 3, Step 25037: Loss = 0.2481803447008133\n",
            "Epoch 3, Step 25038: Loss = 0.3157876133918762\n",
            "Epoch 3, Step 25039: Loss = 0.346100389957428\n",
            "Epoch 3, Step 25040: Loss = 0.48608362674713135\n",
            "Epoch 3, Step 25041: Loss = 0.18347087502479553\n",
            "Epoch 3, Step 25042: Loss = 0.40276700258255005\n",
            "Epoch 3, Step 25043: Loss = 0.2990272343158722\n",
            "Epoch 3, Step 25044: Loss = 0.5038985013961792\n",
            "Epoch 3, Step 25045: Loss = 0.2072327584028244\n",
            "Epoch 3, Step 25046: Loss = 0.19785365462303162\n",
            "Epoch 3, Step 25047: Loss = 0.20801490545272827\n",
            "Epoch 3, Step 25048: Loss = 0.45007094740867615\n",
            "Epoch 3, Step 25049: Loss = 0.20763859152793884\n",
            "Epoch 3, Step 25050: Loss = 0.32908815145492554\n",
            "Epoch 3, Step 25051: Loss = 0.22710363566875458\n",
            "Epoch 3, Step 25052: Loss = 0.4977983832359314\n",
            "Epoch 3, Step 25053: Loss = 0.18502166867256165\n",
            "Epoch 3, Step 25054: Loss = 0.7182446718215942\n",
            "Epoch 3, Step 25055: Loss = 0.22560250759124756\n",
            "Epoch 3, Step 25056: Loss = 0.25548455119132996\n",
            "Epoch 3, Step 25057: Loss = 0.26186007261276245\n",
            "Epoch 3, Step 25058: Loss = 0.47371459007263184\n",
            "Epoch 3, Step 25059: Loss = 0.4815604090690613\n",
            "Epoch 3, Step 25060: Loss = 0.33574172854423523\n",
            "Epoch 3, Step 25061: Loss = 0.321699321269989\n",
            "Epoch 3, Step 25062: Loss = 0.3704720437526703\n",
            "Epoch 3, Step 25063: Loss = 0.2669869363307953\n",
            "Epoch 3, Step 25064: Loss = 0.29878631234169006\n",
            "Epoch 3, Step 25065: Loss = 0.3034880459308624\n",
            "Epoch 3, Step 25066: Loss = 0.20970582962036133\n",
            "Epoch 3, Step 25067: Loss = 0.29595711827278137\n",
            "Epoch 3, Step 25068: Loss = 0.49000805616378784\n",
            "Epoch 3, Step 25069: Loss = 0.3556211590766907\n",
            "Epoch 3, Step 25070: Loss = 0.5620591640472412\n",
            "Epoch 3, Step 25071: Loss = 0.27709633111953735\n",
            "Epoch 3, Step 25072: Loss = 0.24228352308273315\n",
            "Epoch 3, Step 25073: Loss = 0.5475060939788818\n",
            "Epoch 3, Step 25074: Loss = 0.27666041254997253\n",
            "Epoch 3, Step 25075: Loss = 0.36340615153312683\n",
            "Epoch 3, Step 25076: Loss = 0.3717586398124695\n",
            "Epoch 3, Step 25077: Loss = 0.1668090671300888\n",
            "Epoch 3, Step 25078: Loss = 0.41744548082351685\n",
            "Epoch 3, Step 25079: Loss = 0.5680035352706909\n",
            "Epoch 3, Step 25080: Loss = 0.6794126629829407\n",
            "Epoch 3, Step 25081: Loss = 0.532042384147644\n",
            "Epoch 3, Step 25082: Loss = 0.3767566978931427\n",
            "Epoch 3, Step 25083: Loss = 0.5291098952293396\n",
            "Epoch 3, Step 25084: Loss = 0.8788101077079773\n",
            "Epoch 3, Step 25085: Loss = 0.368706077337265\n",
            "Epoch 3, Step 25086: Loss = 0.3546748757362366\n",
            "Epoch 3, Step 25087: Loss = 0.33570346236228943\n",
            "Epoch 3, Step 25088: Loss = 0.3948746919631958\n",
            "Epoch 3, Step 25089: Loss = 0.4776822626590729\n",
            "Epoch 3, Step 25090: Loss = 0.4803368151187897\n",
            "Epoch 3, Step 25091: Loss = 0.34360724687576294\n",
            "Epoch 3, Step 25092: Loss = 0.2944939136505127\n",
            "Epoch 3, Step 25093: Loss = 0.27556970715522766\n",
            "Epoch 3, Step 25094: Loss = 0.40053853392601013\n",
            "Epoch 3, Step 25095: Loss = 0.3601623475551605\n",
            "Epoch 3, Step 25096: Loss = 0.2717723250389099\n",
            "Epoch 3, Step 25097: Loss = 0.2072352170944214\n",
            "Epoch 3, Step 25098: Loss = 0.46767503023147583\n",
            "Epoch 3, Step 25099: Loss = 0.24319705367088318\n",
            "Epoch 3, Step 25100: Loss = 0.1883123368024826\n",
            "Epoch 3, Step 25101: Loss = 0.2536012530326843\n",
            "Epoch 3, Step 25102: Loss = 0.2905142903327942\n",
            "Epoch 3, Step 25103: Loss = 0.37876200675964355\n",
            "Epoch 3, Step 25104: Loss = 0.45221978425979614\n",
            "Epoch 3, Step 25105: Loss = 0.1795799881219864\n",
            "Epoch 3, Step 25106: Loss = 0.19714350998401642\n",
            "Epoch 3, Step 25107: Loss = 0.21419458091259003\n",
            "Epoch 3, Step 25108: Loss = 0.42636236548423767\n",
            "Epoch 3, Step 25109: Loss = 0.667466938495636\n",
            "Epoch 3, Step 25110: Loss = 0.5598784685134888\n",
            "Epoch 3, Step 25111: Loss = 0.38169994950294495\n",
            "Epoch 3, Step 25112: Loss = 0.5496900677680969\n",
            "Epoch 3, Step 25113: Loss = 0.21929210424423218\n",
            "Epoch 3, Step 25114: Loss = 0.3700849115848541\n",
            "Epoch 3, Step 25115: Loss = 0.31790563464164734\n",
            "Epoch 3, Step 25116: Loss = 0.3989277482032776\n",
            "Epoch 3, Step 25117: Loss = 0.25297996401786804\n",
            "Epoch 3, Step 25118: Loss = 0.2757691442966461\n",
            "Epoch 3, Step 25119: Loss = 0.4805304706096649\n",
            "Epoch 3, Step 25120: Loss = 0.25625917315483093\n",
            "Epoch 3, Step 25121: Loss = 0.4719347357749939\n",
            "Epoch 3, Step 25122: Loss = 0.2632873058319092\n",
            "Epoch 3, Step 25123: Loss = 0.28340649604797363\n",
            "Epoch 3, Step 25124: Loss = 0.31457263231277466\n",
            "Epoch 3, Step 25125: Loss = 0.37585148215293884\n",
            "Epoch 3, Step 25126: Loss = 0.32558614015579224\n",
            "Epoch 3, Step 25127: Loss = 0.28196951746940613\n",
            "Epoch 3, Step 25128: Loss = 0.31606850028038025\n",
            "Epoch 3, Step 25129: Loss = 0.18239319324493408\n",
            "Epoch 3, Step 25130: Loss = 0.24750648438930511\n",
            "Epoch 3, Step 25131: Loss = 0.250356525182724\n",
            "Epoch 3, Step 25132: Loss = 0.3745248019695282\n",
            "Epoch 3, Step 25133: Loss = 0.2965492606163025\n",
            "Epoch 3, Step 25134: Loss = 0.5346350073814392\n",
            "Epoch 3, Step 25135: Loss = 0.3857388496398926\n",
            "Epoch 3, Step 25136: Loss = 0.31422948837280273\n",
            "Epoch 3, Step 25137: Loss = 0.3164949417114258\n",
            "Epoch 3, Step 25138: Loss = 0.4848736822605133\n",
            "Epoch 3, Step 25139: Loss = 0.26167166233062744\n",
            "Epoch 3, Step 25140: Loss = 0.3596639037132263\n",
            "Epoch 3, Step 25141: Loss = 0.40389376878738403\n",
            "Epoch 3, Step 25142: Loss = 0.3946891129016876\n",
            "Epoch 3, Step 25143: Loss = 0.4675693213939667\n",
            "Epoch 3, Step 25144: Loss = 0.3791959583759308\n",
            "Epoch 3, Step 25145: Loss = 0.20328491926193237\n",
            "Epoch 3, Step 25146: Loss = 0.42085543274879456\n",
            "Epoch 3, Step 25147: Loss = 0.18586468696594238\n",
            "Epoch 3, Step 25148: Loss = 0.3938106596469879\n",
            "Epoch 3, Step 25149: Loss = 0.18431581556797028\n",
            "Epoch 3, Step 25150: Loss = 0.3149193823337555\n",
            "Epoch 3, Step 25151: Loss = 0.16557618975639343\n",
            "Epoch 3, Step 25152: Loss = 0.24153177440166473\n",
            "Epoch 3, Step 25153: Loss = 0.3611559271812439\n",
            "Epoch 3, Step 25154: Loss = 0.22427859902381897\n",
            "Epoch 3, Step 25155: Loss = 0.2806657552719116\n",
            "Epoch 3, Step 25156: Loss = 0.30630752444267273\n",
            "Epoch 3, Step 25157: Loss = 0.23044805228710175\n",
            "Epoch 3, Step 25158: Loss = 0.1484752893447876\n",
            "Epoch 3, Step 25159: Loss = 0.22601115703582764\n",
            "Epoch 3, Step 25160: Loss = 0.30538633465766907\n",
            "Epoch 3, Step 25161: Loss = 0.2954960763454437\n",
            "Epoch 3, Step 25162: Loss = 0.2838444411754608\n",
            "Epoch 3, Step 25163: Loss = 0.3981483280658722\n",
            "Epoch 3, Step 25164: Loss = 0.38358545303344727\n",
            "Epoch 3, Step 25165: Loss = 0.2126532644033432\n",
            "Epoch 3, Step 25166: Loss = 0.3088824450969696\n",
            "Epoch 3, Step 25167: Loss = 0.26501935720443726\n",
            "Epoch 3, Step 25168: Loss = 0.17545336484909058\n",
            "Epoch 3, Step 25169: Loss = 0.1800040751695633\n",
            "Epoch 3, Step 25170: Loss = 0.3200116455554962\n",
            "Epoch 3, Step 25171: Loss = 0.17877021431922913\n",
            "Epoch 3, Step 25172: Loss = 0.2282724231481552\n",
            "Epoch 3, Step 25173: Loss = 0.18394893407821655\n",
            "Epoch 3, Step 25174: Loss = 0.2713428735733032\n",
            "Epoch 3, Step 25175: Loss = 0.34006184339523315\n",
            "Epoch 3, Step 25176: Loss = 0.1380869448184967\n",
            "Epoch 3, Step 25177: Loss = 0.17225822806358337\n",
            "Epoch 3, Step 25178: Loss = 0.14218761026859283\n",
            "Epoch 3, Step 25179: Loss = 0.20035743713378906\n",
            "Epoch 3, Step 25180: Loss = 0.3982710540294647\n",
            "Epoch 3, Step 25181: Loss = 0.38049909472465515\n",
            "Epoch 3, Step 25182: Loss = 0.46127909421920776\n",
            "Epoch 3, Step 25183: Loss = 0.22525997459888458\n",
            "Epoch 3, Step 25184: Loss = 0.16987115144729614\n",
            "Epoch 3, Step 25185: Loss = 0.23883478343486786\n",
            "Epoch 3, Step 25186: Loss = 0.5735489130020142\n",
            "Epoch 3, Step 25187: Loss = 0.2720363438129425\n",
            "Epoch 3, Step 25188: Loss = 0.42038416862487793\n",
            "Epoch 3, Step 25189: Loss = 0.290432870388031\n",
            "Epoch 3, Step 25190: Loss = 0.39466652274131775\n",
            "Epoch 3, Step 25191: Loss = 0.14318814873695374\n",
            "Epoch 3, Step 25192: Loss = 0.20844654738903046\n",
            "Epoch 3, Step 25193: Loss = 0.5068995952606201\n",
            "Epoch 3, Step 25194: Loss = 0.20102240145206451\n",
            "Epoch 3, Step 25195: Loss = 0.17656344175338745\n",
            "Epoch 3, Step 25196: Loss = 0.35902971029281616\n",
            "Epoch 3, Step 25197: Loss = 0.5266128182411194\n",
            "Epoch 3, Step 25198: Loss = 0.4210602343082428\n",
            "Epoch 3, Step 25199: Loss = 0.2696074843406677\n",
            "Epoch 3, Step 25200: Loss = 0.23105987906455994\n",
            "Epoch 3, Step 25201: Loss = 0.1966734379529953\n",
            "Epoch 3, Step 25202: Loss = 0.19394153356552124\n",
            "Epoch 3, Step 25203: Loss = 0.2784391939640045\n",
            "Epoch 3, Step 25204: Loss = 0.22424927353858948\n",
            "Epoch 3, Step 25205: Loss = 0.6359050273895264\n",
            "Epoch 3, Step 25206: Loss = 0.08735140413045883\n",
            "Epoch 3, Step 25207: Loss = 0.23695993423461914\n",
            "Epoch 3, Step 25208: Loss = 0.5203747153282166\n",
            "Epoch 3, Step 25209: Loss = 0.337546706199646\n",
            "Epoch 3, Step 25210: Loss = 0.380156546831131\n",
            "Epoch 3, Step 25211: Loss = 0.15452758967876434\n",
            "Epoch 3, Step 25212: Loss = 0.29113057255744934\n",
            "Epoch 3, Step 25213: Loss = 0.213640496134758\n",
            "Epoch 3, Step 25214: Loss = 0.3477170169353485\n",
            "Epoch 3, Step 25215: Loss = 0.2546655833721161\n",
            "Epoch 3, Step 25216: Loss = 0.4807489812374115\n",
            "Epoch 3, Step 25217: Loss = 0.3926638662815094\n",
            "Epoch 3, Step 25218: Loss = 0.5032290816307068\n",
            "Epoch 3, Step 25219: Loss = 0.24603265523910522\n",
            "Epoch 3, Step 25220: Loss = 0.41137486696243286\n",
            "Epoch 3, Step 25221: Loss = 0.45987462997436523\n",
            "Epoch 3, Step 25222: Loss = 0.47478750348091125\n",
            "Epoch 3, Step 25223: Loss = 0.3111487030982971\n",
            "Epoch 3, Step 25224: Loss = 0.4503718912601471\n",
            "Epoch 3, Step 25225: Loss = 0.3100370466709137\n",
            "Epoch 3, Step 25226: Loss = 0.299826979637146\n",
            "Epoch 3, Step 25227: Loss = 0.24760401248931885\n",
            "Epoch 3, Step 25228: Loss = 0.2971192002296448\n",
            "Epoch 3, Step 25229: Loss = 0.5102482438087463\n",
            "Epoch 3, Step 25230: Loss = 0.3307943344116211\n",
            "Epoch 3, Step 25231: Loss = 0.25571998953819275\n",
            "Epoch 3, Step 25232: Loss = 0.4438081681728363\n",
            "Epoch 3, Step 25233: Loss = 0.25865548849105835\n",
            "Epoch 3, Step 25234: Loss = 0.26412931084632874\n",
            "Epoch 3, Step 25235: Loss = 0.26905038952827454\n",
            "Epoch 3, Step 25236: Loss = 0.3424703776836395\n",
            "Epoch 3, Step 25237: Loss = 0.22606618702411652\n",
            "Epoch 3, Step 25238: Loss = 0.26001453399658203\n",
            "Epoch 3, Step 25239: Loss = 0.48601746559143066\n",
            "Epoch 3, Step 25240: Loss = 0.19521768391132355\n",
            "Epoch 3, Step 25241: Loss = 0.5845036506652832\n",
            "Epoch 3, Step 25242: Loss = 0.4193498194217682\n",
            "Epoch 3, Step 25243: Loss = 0.2079371213912964\n",
            "Epoch 3, Step 25244: Loss = 0.2867676913738251\n",
            "Epoch 3, Step 25245: Loss = 0.4080328643321991\n",
            "Epoch 3, Step 25246: Loss = 0.25661763548851013\n",
            "Epoch 3, Step 25247: Loss = 0.2542238235473633\n",
            "Epoch 3, Step 25248: Loss = 0.4189636707305908\n",
            "Epoch 3, Step 25249: Loss = 0.2356143444776535\n",
            "Epoch 3, Step 25250: Loss = 0.2992174029350281\n",
            "Epoch 3, Step 25251: Loss = 0.5442261695861816\n",
            "Epoch 3, Step 25252: Loss = 0.39109131693840027\n",
            "Epoch 3, Step 25253: Loss = 0.3665021061897278\n",
            "Epoch 3, Step 25254: Loss = 0.5089167356491089\n",
            "Epoch 3, Step 25255: Loss = 0.43933549523353577\n",
            "Epoch 3, Step 25256: Loss = 0.3667251169681549\n",
            "Epoch 3, Step 25257: Loss = 0.21625082194805145\n",
            "Epoch 3, Step 25258: Loss = 0.28045380115509033\n",
            "Epoch 3, Step 25259: Loss = 0.28502020239830017\n",
            "Epoch 3, Step 25260: Loss = 0.43270066380500793\n",
            "Epoch 3, Step 25261: Loss = 0.4389381408691406\n",
            "Epoch 3, Step 25262: Loss = 0.2531256675720215\n",
            "Epoch 3, Step 25263: Loss = 0.33157455921173096\n",
            "Epoch 3, Step 25264: Loss = 0.262614905834198\n",
            "Epoch 3, Step 25265: Loss = 0.40633639693260193\n",
            "Epoch 3, Step 25266: Loss = 0.3224383294582367\n",
            "Epoch 3, Step 25267: Loss = 0.38200822472572327\n",
            "Epoch 3, Step 25268: Loss = 0.2736523449420929\n",
            "Epoch 3, Step 25269: Loss = 0.33456748723983765\n",
            "Epoch 3, Step 25270: Loss = 0.2745753824710846\n",
            "Epoch 3, Step 25271: Loss = 0.2328447848558426\n",
            "Epoch 3, Step 25272: Loss = 0.31479009985923767\n",
            "Epoch 3, Step 25273: Loss = 0.21632236242294312\n",
            "Epoch 3, Step 25274: Loss = 0.38314563035964966\n",
            "Epoch 3, Step 25275: Loss = 0.49871113896369934\n",
            "Epoch 3, Step 25276: Loss = 0.5727735161781311\n",
            "Epoch 3, Step 25277: Loss = 0.2957746684551239\n",
            "Epoch 3, Step 25278: Loss = 0.18137243390083313\n",
            "Epoch 3, Step 25279: Loss = 0.2944331169128418\n",
            "Epoch 3, Step 25280: Loss = 0.2189900428056717\n",
            "Epoch 3, Step 25281: Loss = 0.34258949756622314\n",
            "Epoch 3, Step 25282: Loss = 0.27068379521369934\n",
            "Epoch 3, Step 25283: Loss = 0.3955610990524292\n",
            "Epoch 3, Step 25284: Loss = 0.3540583550930023\n",
            "Epoch 3, Step 25285: Loss = 0.3234948217868805\n",
            "Epoch 3, Step 25286: Loss = 0.28312739729881287\n",
            "Epoch 3, Step 25287: Loss = 0.22757650911808014\n",
            "Epoch 3, Step 25288: Loss = 0.30098146200180054\n",
            "Epoch 3, Step 25289: Loss = 0.3755464553833008\n",
            "Epoch 3, Step 25290: Loss = 0.22242975234985352\n",
            "Epoch 3, Step 25291: Loss = 0.3035104274749756\n",
            "Epoch 3, Step 25292: Loss = 0.45425093173980713\n",
            "Epoch 3, Step 25293: Loss = 0.20438413321971893\n",
            "Epoch 3, Step 25294: Loss = 0.2665044963359833\n",
            "Epoch 3, Step 25295: Loss = 0.3796544373035431\n",
            "Epoch 3, Step 25296: Loss = 0.2915753722190857\n",
            "Epoch 3, Step 25297: Loss = 0.35235801339149475\n",
            "Epoch 3, Step 25298: Loss = 0.37431779503822327\n",
            "Epoch 3, Step 25299: Loss = 0.30760911107063293\n",
            "Epoch 3, Step 25300: Loss = 0.29705479741096497\n",
            "Epoch 3, Step 25301: Loss = 0.24471333622932434\n",
            "Epoch 3, Step 25302: Loss = 0.23521758615970612\n",
            "Epoch 3, Step 25303: Loss = 0.4438665211200714\n",
            "Epoch 3, Step 25304: Loss = 0.33007094264030457\n",
            "Epoch 3, Step 25305: Loss = 0.4290052652359009\n",
            "Epoch 3, Step 25306: Loss = 0.5861753821372986\n",
            "Epoch 3, Step 25307: Loss = 0.20024289190769196\n",
            "Epoch 3, Step 25308: Loss = 0.48178207874298096\n",
            "Epoch 3, Step 25309: Loss = 0.5737050175666809\n",
            "Epoch 3, Step 25310: Loss = 0.37957045435905457\n",
            "Epoch 3, Step 25311: Loss = 0.5228996276855469\n",
            "Epoch 3, Step 25312: Loss = 0.5067873597145081\n",
            "Epoch 3, Step 25313: Loss = 0.2970723509788513\n",
            "Epoch 3, Step 25314: Loss = 0.31411507725715637\n",
            "Epoch 3, Step 25315: Loss = 0.3533468544483185\n",
            "Epoch 3, Step 25316: Loss = 0.46186286211013794\n",
            "Epoch 3, Step 25317: Loss = 0.31047317385673523\n",
            "Epoch 3, Step 25318: Loss = 0.19887015223503113\n",
            "Epoch 3, Step 25319: Loss = 0.3367120027542114\n",
            "Epoch 3, Step 25320: Loss = 0.3242652714252472\n",
            "Epoch 3, Step 25321: Loss = 0.4805084466934204\n",
            "Epoch 3, Step 25322: Loss = 0.2515040338039398\n",
            "Epoch 3, Step 25323: Loss = 0.3684457838535309\n",
            "Epoch 3, Step 25324: Loss = 0.2520964443683624\n",
            "Epoch 3, Step 25325: Loss = 0.5670959949493408\n",
            "Epoch 3, Step 25326: Loss = 0.39760857820510864\n",
            "Epoch 3, Step 25327: Loss = 0.11940141767263412\n",
            "Epoch 3, Step 25328: Loss = 0.37502819299697876\n",
            "Epoch 3, Step 25329: Loss = 0.3540023863315582\n",
            "Epoch 3, Step 25330: Loss = 0.36925986409187317\n",
            "Epoch 3, Step 25331: Loss = 0.25232669711112976\n",
            "Epoch 3, Step 25332: Loss = 0.4494040906429291\n",
            "Epoch 3, Step 25333: Loss = 0.2322702407836914\n",
            "Epoch 3, Step 25334: Loss = 0.29503241181373596\n",
            "Epoch 3, Step 25335: Loss = 0.23789019882678986\n",
            "Epoch 3, Step 25336: Loss = 0.5658665299415588\n",
            "Epoch 3, Step 25337: Loss = 0.37847408652305603\n",
            "Epoch 3, Step 25338: Loss = 0.24795569479465485\n",
            "Epoch 3, Step 25339: Loss = 0.37118837237358093\n",
            "Epoch 3, Step 25340: Loss = 0.4042997658252716\n",
            "Epoch 3, Step 25341: Loss = 0.2438850998878479\n",
            "Epoch 3, Step 25342: Loss = 0.294913649559021\n",
            "Epoch 3, Step 25343: Loss = 0.3330914080142975\n",
            "Epoch 3, Step 25344: Loss = 0.24654674530029297\n",
            "Epoch 3, Step 25345: Loss = 0.4288904070854187\n",
            "Epoch 3, Step 25346: Loss = 0.3258545994758606\n",
            "Epoch 3, Step 25347: Loss = 0.4771364629268646\n",
            "Epoch 3, Step 25348: Loss = 0.34394633769989014\n",
            "Epoch 3, Step 25349: Loss = 0.2679455876350403\n",
            "Epoch 3, Step 25350: Loss = 0.2835908532142639\n",
            "Epoch 3, Step 25351: Loss = 0.4732687771320343\n",
            "Epoch 3, Step 25352: Loss = 0.42931365966796875\n",
            "Epoch 3, Step 25353: Loss = 0.33192482590675354\n",
            "Epoch 3, Step 25354: Loss = 0.34678196907043457\n",
            "Epoch 3, Step 25355: Loss = 0.32246482372283936\n",
            "Epoch 3, Step 25356: Loss = 0.2883603870868683\n",
            "Epoch 3, Step 25357: Loss = 0.23048840463161469\n",
            "Epoch 3, Step 25358: Loss = 0.2877047657966614\n",
            "Epoch 3, Step 25359: Loss = 0.35639581084251404\n",
            "Epoch 3, Step 25360: Loss = 0.3896574378013611\n",
            "Epoch 3, Step 25361: Loss = 0.35595667362213135\n",
            "Epoch 3, Step 25362: Loss = 0.24064067006111145\n",
            "Epoch 3, Step 25363: Loss = 0.20425279438495636\n",
            "Epoch 3, Step 25364: Loss = 0.2694503962993622\n",
            "Epoch 3, Step 25365: Loss = 0.285823255777359\n",
            "Epoch 3, Step 25366: Loss = 0.18852412700653076\n",
            "Epoch 3, Step 25367: Loss = 0.38366955518722534\n",
            "Epoch 3, Step 25368: Loss = 0.2653108835220337\n",
            "Epoch 3, Step 25369: Loss = 0.25775301456451416\n",
            "Epoch 3, Step 25370: Loss = 0.36541301012039185\n",
            "Epoch 3, Step 25371: Loss = 0.353474885225296\n",
            "Epoch 3, Step 25372: Loss = 0.21708062291145325\n",
            "Epoch 3, Step 25373: Loss = 0.3897840976715088\n",
            "Epoch 3, Step 25374: Loss = 0.1811486780643463\n",
            "Epoch 3, Step 25375: Loss = 0.3489847183227539\n",
            "Epoch 3, Step 25376: Loss = 0.3589211404323578\n",
            "Epoch 3, Step 25377: Loss = 0.31597796082496643\n",
            "Epoch 3, Step 25378: Loss = 0.39068740606307983\n",
            "Epoch 3, Step 25379: Loss = 0.2969690263271332\n",
            "Epoch 3, Step 25380: Loss = 0.4013632833957672\n",
            "Epoch 3, Step 25381: Loss = 0.34191685914993286\n",
            "Epoch 3, Step 25382: Loss = 0.40439972281455994\n",
            "Epoch 3, Step 25383: Loss = 0.11236198991537094\n",
            "Epoch 3, Step 25384: Loss = 0.33161571621894836\n",
            "Epoch 3, Step 25385: Loss = 0.4401700794696808\n",
            "Epoch 3, Step 25386: Loss = 0.1699991226196289\n",
            "Epoch 3, Step 25387: Loss = 0.2657357454299927\n",
            "Epoch 3, Step 25388: Loss = 0.2934534251689911\n",
            "Epoch 3, Step 25389: Loss = 0.4817487299442291\n",
            "Epoch 3, Step 25390: Loss = 0.3622000515460968\n",
            "Epoch 3, Step 25391: Loss = 0.43442481756210327\n",
            "Epoch 3, Step 25392: Loss = 0.3179364502429962\n",
            "Epoch 3, Step 25393: Loss = 0.18427850306034088\n",
            "Epoch 3, Step 25394: Loss = 0.3600495457649231\n",
            "Epoch 3, Step 25395: Loss = 0.19719775021076202\n",
            "Epoch 3, Step 25396: Loss = 0.2871434688568115\n",
            "Epoch 3, Step 25397: Loss = 0.2875887453556061\n",
            "Epoch 3, Step 25398: Loss = 0.254334032535553\n",
            "Epoch 3, Step 25399: Loss = 0.30658796429634094\n",
            "Epoch 3, Step 25400: Loss = 0.38649699091911316\n",
            "Epoch 3, Step 25401: Loss = 0.28786131739616394\n",
            "Epoch 3, Step 25402: Loss = 0.1688637137413025\n",
            "Epoch 3, Step 25403: Loss = 0.3760144114494324\n",
            "Epoch 3, Step 25404: Loss = 0.41521576046943665\n",
            "Epoch 3, Step 25405: Loss = 0.38609981536865234\n",
            "Epoch 3, Step 25406: Loss = 0.17038732767105103\n",
            "Epoch 3, Step 25407: Loss = 0.47185903787612915\n",
            "Epoch 3, Step 25408: Loss = 0.3950960636138916\n",
            "Epoch 3, Step 25409: Loss = 0.27217090129852295\n",
            "Epoch 3, Step 25410: Loss = 0.679801881313324\n",
            "Epoch 3, Step 25411: Loss = 0.35224267840385437\n",
            "Epoch 3, Step 25412: Loss = 0.22533603012561798\n",
            "Epoch 3, Step 25413: Loss = 0.2003433108329773\n",
            "Epoch 3, Step 25414: Loss = 0.40610894560813904\n",
            "Epoch 3, Step 25415: Loss = 0.3971937298774719\n",
            "Epoch 3, Step 25416: Loss = 0.3190048635005951\n",
            "Epoch 3, Step 25417: Loss = 0.29679620265960693\n",
            "Epoch 3, Step 25418: Loss = 0.3751320540904999\n",
            "Epoch 3, Step 25419: Loss = 0.40013742446899414\n",
            "Epoch 3, Step 25420: Loss = 0.4163706302642822\n",
            "Epoch 3, Step 25421: Loss = 0.32917487621307373\n",
            "Epoch 3, Step 25422: Loss = 0.32126346230506897\n",
            "Epoch 3, Step 25423: Loss = 0.2661483585834503\n",
            "Epoch 3, Step 25424: Loss = 0.28011539578437805\n",
            "Epoch 3, Step 25425: Loss = 0.4636036455631256\n",
            "Epoch 3, Step 25426: Loss = 0.2643166184425354\n",
            "Epoch 3, Step 25427: Loss = 0.24503293633460999\n",
            "Epoch 3, Step 25428: Loss = 0.3422117531299591\n",
            "Epoch 3, Step 25429: Loss = 0.48780789971351624\n",
            "Epoch 3, Step 25430: Loss = 0.3569190502166748\n",
            "Epoch 3, Step 25431: Loss = 0.4855743646621704\n",
            "Epoch 3, Step 25432: Loss = 0.41424694657325745\n",
            "Epoch 3, Step 25433: Loss = 0.5299728512763977\n",
            "Epoch 3, Step 25434: Loss = 0.5522032976150513\n",
            "Epoch 3, Step 25435: Loss = 0.3051551282405853\n",
            "Epoch 3, Step 25436: Loss = 0.44101855158805847\n",
            "Epoch 3, Step 25437: Loss = 0.24895285069942474\n",
            "Epoch 3, Step 25438: Loss = 0.31353089213371277\n",
            "Epoch 3, Step 25439: Loss = 0.40151873230934143\n",
            "Epoch 3, Step 25440: Loss = 0.5315335392951965\n",
            "Epoch 3, Step 25441: Loss = 0.39623183012008667\n",
            "Epoch 3, Step 25442: Loss = 0.46743902564048767\n",
            "Epoch 3, Step 25443: Loss = 0.31817343831062317\n",
            "Epoch 3, Step 25444: Loss = 0.29513686895370483\n",
            "Epoch 3, Step 25445: Loss = 0.4174683392047882\n",
            "Epoch 3, Step 25446: Loss = 0.30882886052131653\n",
            "Epoch 3, Step 25447: Loss = 0.21130973100662231\n",
            "Epoch 3, Step 25448: Loss = 0.2725864350795746\n",
            "Epoch 3, Step 25449: Loss = 0.19844181835651398\n",
            "Epoch 3, Step 25450: Loss = 0.4687308967113495\n",
            "Epoch 3, Step 25451: Loss = 0.3186766505241394\n",
            "Epoch 3, Step 25452: Loss = 0.20109736919403076\n",
            "Epoch 3, Step 25453: Loss = 0.2984509766101837\n",
            "Epoch 3, Step 25454: Loss = 0.32440096139907837\n",
            "Epoch 3, Step 25455: Loss = 0.41302618384361267\n",
            "Epoch 3, Step 25456: Loss = 0.48605844378471375\n",
            "Epoch 3, Step 25457: Loss = 0.49080634117126465\n",
            "Epoch 3, Step 25458: Loss = 0.12225005030632019\n",
            "Epoch 3, Step 25459: Loss = 0.2970861792564392\n",
            "Epoch 3, Step 25460: Loss = 0.2750634551048279\n",
            "Epoch 3, Step 25461: Loss = 0.5585010647773743\n",
            "Epoch 3, Step 25462: Loss = 0.4886956512928009\n",
            "Epoch 3, Step 25463: Loss = 0.27565497159957886\n",
            "Epoch 3, Step 25464: Loss = 0.30190327763557434\n",
            "Epoch 3, Step 25465: Loss = 0.44430649280548096\n",
            "Epoch 3, Step 25466: Loss = 0.38289931416511536\n",
            "Epoch 3, Step 25467: Loss = 0.606542706489563\n",
            "Epoch 3, Step 25468: Loss = 0.7526947259902954\n",
            "Epoch 3, Step 25469: Loss = 0.2358006238937378\n",
            "Epoch 3, Step 25470: Loss = 0.20508289337158203\n",
            "Epoch 3, Step 25471: Loss = 0.5040971040725708\n",
            "Epoch 3, Step 25472: Loss = 0.24160678684711456\n",
            "Epoch 3, Step 25473: Loss = 0.24433037638664246\n",
            "Epoch 3, Step 25474: Loss = 0.23926681280136108\n",
            "Epoch 3, Step 25475: Loss = 0.21239028871059418\n",
            "Epoch 3, Step 25476: Loss = 0.3002769947052002\n",
            "Epoch 3, Step 25477: Loss = 0.2980610132217407\n",
            "Epoch 3, Step 25478: Loss = 0.32601308822631836\n",
            "Epoch 3, Step 25479: Loss = 0.20749959349632263\n",
            "Epoch 3, Step 25480: Loss = 0.2627648413181305\n",
            "Epoch 3, Step 25481: Loss = 0.4120193123817444\n",
            "Epoch 3, Step 25482: Loss = 0.33027786016464233\n",
            "Epoch 3, Step 25483: Loss = 0.36563703417778015\n",
            "Epoch 3, Step 25484: Loss = 0.3324795961380005\n",
            "Epoch 3, Step 25485: Loss = 0.45740804076194763\n",
            "Epoch 3, Step 25486: Loss = 0.1772507131099701\n",
            "Epoch 3, Step 25487: Loss = 0.3172551691532135\n",
            "Epoch 3, Step 25488: Loss = 0.2020392119884491\n",
            "Epoch 3, Step 25489: Loss = 0.2389434427022934\n",
            "Epoch 3, Step 25490: Loss = 0.18875809013843536\n",
            "Epoch 3, Step 25491: Loss = 0.19673334062099457\n",
            "Epoch 3, Step 25492: Loss = 0.32513853907585144\n",
            "Epoch 3, Step 25493: Loss = 0.30731001496315\n",
            "Epoch 3, Step 25494: Loss = 0.4804227650165558\n",
            "Epoch 3, Step 25495: Loss = 0.33229801058769226\n",
            "Epoch 3, Step 25496: Loss = 0.26023221015930176\n",
            "Epoch 3, Step 25497: Loss = 0.6769646406173706\n",
            "Epoch 3, Step 25498: Loss = 0.1715041846036911\n",
            "Epoch 3, Step 25499: Loss = 0.3533722162246704\n",
            "Epoch 3, Step 25500: Loss = 0.24685531854629517\n",
            "Epoch 3, Step 25501: Loss = 0.2682148814201355\n",
            "Epoch 3, Step 25502: Loss = 0.1830318719148636\n",
            "Epoch 3, Step 25503: Loss = 0.37912020087242126\n",
            "Epoch 3, Step 25504: Loss = 0.44431939721107483\n",
            "Epoch 3, Step 25505: Loss = 0.2610197067260742\n",
            "Epoch 3, Step 25506: Loss = 0.38144370913505554\n",
            "Epoch 3, Step 25507: Loss = 0.3547373414039612\n",
            "Epoch 3, Step 25508: Loss = 0.2486332505941391\n",
            "Epoch 3, Step 25509: Loss = 0.4774085283279419\n",
            "Epoch 3, Step 25510: Loss = 0.6809735298156738\n",
            "Epoch 3, Step 25511: Loss = 0.24421219527721405\n",
            "Epoch 3, Step 25512: Loss = 0.31306037306785583\n",
            "Epoch 3, Step 25513: Loss = 0.260919988155365\n",
            "Epoch 3, Step 25514: Loss = 0.17891934514045715\n",
            "Epoch 3, Step 25515: Loss = 0.37769100069999695\n",
            "Epoch 3, Step 25516: Loss = 0.2454478144645691\n",
            "Epoch 3, Step 25517: Loss = 0.4216448962688446\n",
            "Epoch 3, Step 25518: Loss = 0.27233055233955383\n",
            "Epoch 3, Step 25519: Loss = 0.2914077341556549\n",
            "Epoch 3, Step 25520: Loss = 0.34263527393341064\n",
            "Epoch 3, Step 25521: Loss = 0.2638903558254242\n",
            "Epoch 3, Step 25522: Loss = 0.22397512197494507\n",
            "Epoch 3, Step 25523: Loss = 0.37088826298713684\n",
            "Epoch 3, Step 25524: Loss = 0.28589144349098206\n",
            "Epoch 3, Step 25525: Loss = 0.2658628821372986\n",
            "Epoch 3, Step 25526: Loss = 0.342199444770813\n",
            "Epoch 3, Step 25527: Loss = 0.2397209107875824\n",
            "Epoch 3, Step 25528: Loss = 0.2500760853290558\n",
            "Epoch 3, Step 25529: Loss = 0.22741903364658356\n",
            "Epoch 3, Step 25530: Loss = 0.38655564188957214\n",
            "Epoch 3, Step 25531: Loss = 0.34545594453811646\n",
            "Epoch 3, Step 25532: Loss = 0.4574581980705261\n",
            "Epoch 3, Step 25533: Loss = 0.1888841837644577\n",
            "Epoch 3, Step 25534: Loss = 0.3394034206867218\n",
            "Epoch 3, Step 25535: Loss = 0.30139756202697754\n",
            "Epoch 3, Step 25536: Loss = 0.353047251701355\n",
            "Epoch 3, Step 25537: Loss = 0.18426325917243958\n",
            "Epoch 3, Step 25538: Loss = 0.5504083037376404\n",
            "Epoch 3, Step 25539: Loss = 0.2942138910293579\n",
            "Epoch 3, Step 25540: Loss = 0.20502081513404846\n",
            "Epoch 3, Step 25541: Loss = 0.48982301354408264\n",
            "Epoch 3, Step 25542: Loss = 0.4084834158420563\n",
            "Epoch 3, Step 25543: Loss = 0.4642709493637085\n",
            "Epoch 3, Step 25544: Loss = 0.2986637353897095\n",
            "Epoch 3, Step 25545: Loss = 0.30700188875198364\n",
            "Epoch 3, Step 25546: Loss = 0.4947238564491272\n",
            "Epoch 3, Step 25547: Loss = 0.3839239776134491\n",
            "Epoch 3, Step 25548: Loss = 0.4887673556804657\n",
            "Epoch 3, Step 25549: Loss = 0.31388571858406067\n",
            "Epoch 3, Step 25550: Loss = 0.37792670726776123\n",
            "Epoch 3, Step 25551: Loss = 0.31265369057655334\n",
            "Epoch 3, Step 25552: Loss = 0.34734246134757996\n",
            "Epoch 3, Step 25553: Loss = 0.27164426445961\n",
            "Epoch 3, Step 25554: Loss = 0.3225453197956085\n",
            "Epoch 3, Step 25555: Loss = 0.2560310959815979\n",
            "Epoch 3, Step 25556: Loss = 0.3858228325843811\n",
            "Epoch 3, Step 25557: Loss = 0.1501522958278656\n",
            "Epoch 3, Step 25558: Loss = 0.2937026917934418\n",
            "Epoch 3, Step 25559: Loss = 0.29012924432754517\n",
            "Epoch 3, Step 25560: Loss = 0.41005566716194153\n",
            "Epoch 3, Step 25561: Loss = 0.1736903339624405\n",
            "Epoch 3, Step 25562: Loss = 0.2045425921678543\n",
            "Epoch 3, Step 25563: Loss = 0.23068749904632568\n",
            "Epoch 3, Step 25564: Loss = 0.41514670848846436\n",
            "Epoch 3, Step 25565: Loss = 0.2882198989391327\n",
            "Epoch 3, Step 25566: Loss = 0.25502681732177734\n",
            "Epoch 3, Step 25567: Loss = 0.2989078462123871\n",
            "Epoch 3, Step 25568: Loss = 0.2663346529006958\n",
            "Epoch 3, Step 25569: Loss = 0.3435189723968506\n",
            "Epoch 3, Step 25570: Loss = 0.40471217036247253\n",
            "Epoch 3, Step 25571: Loss = 0.37682032585144043\n",
            "Epoch 3, Step 25572: Loss = 0.2914019525051117\n",
            "Epoch 3, Step 25573: Loss = 0.41524603962898254\n",
            "Epoch 3, Step 25574: Loss = 0.21299980580806732\n",
            "Epoch 3, Step 25575: Loss = 0.28502383828163147\n",
            "Epoch 3, Step 25576: Loss = 0.2830400764942169\n",
            "Epoch 3, Step 25577: Loss = 0.13510321080684662\n",
            "Epoch 3, Step 25578: Loss = 0.35140523314476013\n",
            "Epoch 3, Step 25579: Loss = 0.2837429940700531\n",
            "Epoch 3, Step 25580: Loss = 0.3880070745944977\n",
            "Epoch 3, Step 25581: Loss = 0.4384946823120117\n",
            "Epoch 3, Step 25582: Loss = 0.1934622973203659\n",
            "Epoch 3, Step 25583: Loss = 0.47617170214653015\n",
            "Epoch 3, Step 25584: Loss = 0.22540447115898132\n",
            "Epoch 3, Step 25585: Loss = 0.24686886370182037\n",
            "Epoch 3, Step 25586: Loss = 0.40310952067375183\n",
            "Epoch 3, Step 25587: Loss = 0.3558379113674164\n",
            "Epoch 3, Step 25588: Loss = 0.3147658705711365\n",
            "Epoch 3, Step 25589: Loss = 0.37100750207901\n",
            "Epoch 3, Step 25590: Loss = 0.6148716807365417\n",
            "Epoch 3, Step 25591: Loss = 0.24964846670627594\n",
            "Epoch 3, Step 25592: Loss = 0.21926599740982056\n",
            "Epoch 3, Step 25593: Loss = 0.5371217131614685\n",
            "Epoch 3, Step 25594: Loss = 0.4357360005378723\n",
            "Epoch 3, Step 25595: Loss = 0.36204633116722107\n",
            "Epoch 3, Step 25596: Loss = 0.6550491452217102\n",
            "Epoch 3, Step 25597: Loss = 0.3753950595855713\n",
            "Epoch 3, Step 25598: Loss = 0.36006730794906616\n",
            "Epoch 3, Step 25599: Loss = 0.2874854803085327\n",
            "Epoch 3, Step 25600: Loss = 0.5408257246017456\n",
            "Epoch 3, Step 25601: Loss = 0.13939359784126282\n",
            "Epoch 3, Step 25602: Loss = 0.4275287091732025\n",
            "Epoch 3, Step 25603: Loss = 0.24615906178951263\n",
            "Epoch 3, Step 25604: Loss = 0.22943751513957977\n",
            "Epoch 3, Step 25605: Loss = 0.4076535105705261\n",
            "Epoch 3, Step 25606: Loss = 0.21673911809921265\n",
            "Epoch 3, Step 25607: Loss = 0.49732306599617004\n",
            "Epoch 3, Step 25608: Loss = 0.8968254923820496\n",
            "Epoch 3, Step 25609: Loss = 0.263984739780426\n",
            "Epoch 3, Step 25610: Loss = 0.24890489876270294\n",
            "Epoch 3, Step 25611: Loss = 0.24075143039226532\n",
            "Epoch 3, Step 25612: Loss = 0.19225959479808807\n",
            "Epoch 3, Step 25613: Loss = 0.2692403793334961\n",
            "Epoch 3, Step 25614: Loss = 0.35179436206817627\n",
            "Epoch 3, Step 25615: Loss = 0.34602633118629456\n",
            "Epoch 3, Step 25616: Loss = 0.40131640434265137\n",
            "Epoch 3, Step 25617: Loss = 0.19310322403907776\n",
            "Epoch 3, Step 25618: Loss = 0.44108378887176514\n",
            "Epoch 3, Step 25619: Loss = 0.22282002866268158\n",
            "Epoch 3, Step 25620: Loss = 0.2499096691608429\n",
            "Epoch 3, Step 25621: Loss = 0.1751231700181961\n",
            "Epoch 3, Step 25622: Loss = 0.2899776101112366\n",
            "Epoch 3, Step 25623: Loss = 0.49282506108283997\n",
            "Epoch 3, Step 25624: Loss = 0.37375709414482117\n",
            "Epoch 3, Step 25625: Loss = 0.20378074049949646\n",
            "Epoch 3, Step 25626: Loss = 0.33989208936691284\n",
            "Epoch 3, Step 25627: Loss = 0.3929658830165863\n",
            "Epoch 3, Step 25628: Loss = 0.37902161478996277\n",
            "Epoch 3, Step 25629: Loss = 0.3569681942462921\n",
            "Epoch 3, Step 25630: Loss = 0.3787669241428375\n",
            "Epoch 3, Step 25631: Loss = 0.29087594151496887\n",
            "Epoch 3, Step 25632: Loss = 0.21584177017211914\n",
            "Epoch 3, Step 25633: Loss = 0.27190545201301575\n",
            "Epoch 3, Step 25634: Loss = 0.3561039865016937\n",
            "Epoch 3, Step 25635: Loss = 0.38231414556503296\n",
            "Epoch 3, Step 25636: Loss = 0.2560209035873413\n",
            "Epoch 3, Step 25637: Loss = 0.47305089235305786\n",
            "Epoch 3, Step 25638: Loss = 0.4707600772380829\n",
            "Epoch 3, Step 25639: Loss = 0.27993401885032654\n",
            "Epoch 3, Step 25640: Loss = 0.37306350469589233\n",
            "Epoch 3, Step 25641: Loss = 0.3014664053916931\n",
            "Epoch 3, Step 25642: Loss = 0.35767078399658203\n",
            "Epoch 3, Step 25643: Loss = 0.46259546279907227\n",
            "Epoch 3, Step 25644: Loss = 0.21025991439819336\n",
            "Epoch 3, Step 25645: Loss = 0.46870341897010803\n",
            "Epoch 3, Step 25646: Loss = 0.3096138536930084\n",
            "Epoch 3, Step 25647: Loss = 0.31400588154792786\n",
            "Epoch 3, Step 25648: Loss = 0.2842561602592468\n",
            "Epoch 3, Step 25649: Loss = 0.15497969090938568\n",
            "Epoch 3, Step 25650: Loss = 0.2581750154495239\n",
            "Epoch 3, Step 25651: Loss = 0.3400290310382843\n",
            "Epoch 3, Step 25652: Loss = 0.2946787178516388\n",
            "Epoch 3, Step 25653: Loss = 0.3877110481262207\n",
            "Epoch 3, Step 25654: Loss = 0.3072056472301483\n",
            "Epoch 3, Step 25655: Loss = 0.16986510157585144\n",
            "Epoch 3, Step 25656: Loss = 0.23529691994190216\n",
            "Epoch 3, Step 25657: Loss = 0.5026816129684448\n",
            "Epoch 3, Step 25658: Loss = 0.25185054540634155\n",
            "Epoch 3, Step 25659: Loss = 0.15291641652584076\n",
            "Epoch 3, Step 25660: Loss = 0.5564414262771606\n",
            "Epoch 3, Step 25661: Loss = 0.45192840695381165\n",
            "Epoch 3, Step 25662: Loss = 0.29366812109947205\n",
            "Epoch 3, Step 25663: Loss = 0.1755695790052414\n",
            "Epoch 3, Step 25664: Loss = 0.3221959173679352\n",
            "Epoch 3, Step 25665: Loss = 0.31475815176963806\n",
            "Epoch 3, Step 25666: Loss = 0.3835269510746002\n",
            "Epoch 3, Step 25667: Loss = 0.5736282467842102\n",
            "Epoch 3, Step 25668: Loss = 0.2751430869102478\n",
            "Epoch 3, Step 25669: Loss = 0.2758248746395111\n",
            "Epoch 3, Step 25670: Loss = 0.2552453279495239\n",
            "Epoch 3, Step 25671: Loss = 0.5482831001281738\n",
            "Epoch 3, Step 25672: Loss = 0.3367029130458832\n",
            "Epoch 3, Step 25673: Loss = 0.334452748298645\n",
            "Epoch 3, Step 25674: Loss = 0.2328723520040512\n",
            "Epoch 3, Step 25675: Loss = 0.3994379937648773\n",
            "Epoch 3, Step 25676: Loss = 0.252297967672348\n",
            "Epoch 3, Step 25677: Loss = 0.35225018858909607\n",
            "Epoch 3, Step 25678: Loss = 0.24389638006687164\n",
            "Epoch 3, Step 25679: Loss = 0.3712009787559509\n",
            "Epoch 3, Step 25680: Loss = 0.14535363018512726\n",
            "Epoch 3, Step 25681: Loss = 0.2535618841648102\n",
            "Epoch 3, Step 25682: Loss = 0.2747332751750946\n",
            "Epoch 3, Step 25683: Loss = 0.3870760500431061\n",
            "Epoch 3, Step 25684: Loss = 0.3434467911720276\n",
            "Epoch 3, Step 25685: Loss = 0.22599247097969055\n",
            "Epoch 3, Step 25686: Loss = 0.46313267946243286\n",
            "Epoch 3, Step 25687: Loss = 0.39719241857528687\n",
            "Epoch 3, Step 25688: Loss = 0.6971759796142578\n",
            "Epoch 3, Step 25689: Loss = 0.27932485938072205\n",
            "Epoch 3, Step 25690: Loss = 0.22614358365535736\n",
            "Epoch 3, Step 25691: Loss = 0.22721736133098602\n",
            "Epoch 3, Step 25692: Loss = 0.2772289216518402\n",
            "Epoch 3, Step 25693: Loss = 0.3572681248188019\n",
            "Epoch 3, Step 25694: Loss = 0.23037096858024597\n",
            "Epoch 3, Step 25695: Loss = 0.2702592611312866\n",
            "Epoch 3, Step 25696: Loss = 0.27387434244155884\n",
            "Epoch 3, Step 25697: Loss = 0.342741459608078\n",
            "Epoch 3, Step 25698: Loss = 0.15006311237812042\n",
            "Epoch 3, Step 25699: Loss = 0.24645906686782837\n",
            "Epoch 3, Step 25700: Loss = 0.4059484899044037\n",
            "Epoch 3, Step 25701: Loss = 0.26171502470970154\n",
            "Epoch 3, Step 25702: Loss = 0.17437951266765594\n",
            "Epoch 3, Step 25703: Loss = 0.2120504528284073\n",
            "Epoch 3, Step 25704: Loss = 0.36371877789497375\n",
            "Epoch 3, Step 25705: Loss = 0.28301191329956055\n",
            "Epoch 3, Step 25706: Loss = 0.3268417418003082\n",
            "Epoch 3, Step 25707: Loss = 0.20656780898571014\n",
            "Epoch 3, Step 25708: Loss = 0.2418237030506134\n",
            "Epoch 3, Step 25709: Loss = 0.266984224319458\n",
            "Epoch 3, Step 25710: Loss = 0.5306991934776306\n",
            "Epoch 3, Step 25711: Loss = 0.4851187467575073\n",
            "Epoch 3, Step 25712: Loss = 0.4618707299232483\n",
            "Epoch 3, Step 25713: Loss = 0.21770261228084564\n",
            "Epoch 3, Step 25714: Loss = 0.45775577425956726\n",
            "Epoch 3, Step 25715: Loss = 0.20787249505519867\n",
            "Epoch 3, Step 25716: Loss = 0.44157522916793823\n",
            "Epoch 3, Step 25717: Loss = 0.23610997200012207\n",
            "Epoch 3, Step 25718: Loss = 0.2782852351665497\n",
            "Epoch 3, Step 25719: Loss = 0.3490888774394989\n",
            "Epoch 3, Step 25720: Loss = 0.24641041457653046\n",
            "Epoch 3, Step 25721: Loss = 0.24388420581817627\n",
            "Epoch 3, Step 25722: Loss = 0.1766698658466339\n",
            "Epoch 3, Step 25723: Loss = 0.41090062260627747\n",
            "Epoch 3, Step 25724: Loss = 0.6062939167022705\n",
            "Epoch 3, Step 25725: Loss = 0.6602438688278198\n",
            "Epoch 3, Step 25726: Loss = 0.4876037538051605\n",
            "Epoch 3, Step 25727: Loss = 0.3775397539138794\n",
            "Epoch 3, Step 25728: Loss = 0.37195661664009094\n",
            "Epoch 3, Step 25729: Loss = 0.2292201966047287\n",
            "Epoch 3, Step 25730: Loss = 0.25874873995780945\n",
            "Epoch 3, Step 25731: Loss = 0.24208521842956543\n",
            "Epoch 3, Step 25732: Loss = 0.5503440499305725\n",
            "Epoch 3, Step 25733: Loss = 0.337257981300354\n",
            "Epoch 3, Step 25734: Loss = 0.22430799901485443\n",
            "Epoch 3, Step 25735: Loss = 0.27821215987205505\n",
            "Epoch 3, Step 25736: Loss = 0.18373598158359528\n",
            "Epoch 3, Step 25737: Loss = 0.3153268098831177\n",
            "Epoch 3, Step 25738: Loss = 0.2796289324760437\n",
            "Epoch 3, Step 25739: Loss = 0.3478722870349884\n",
            "Epoch 3, Step 25740: Loss = 0.30522263050079346\n",
            "Epoch 3, Step 25741: Loss = 0.3256194293498993\n",
            "Epoch 3, Step 25742: Loss = 0.2501821517944336\n",
            "Epoch 3, Step 25743: Loss = 0.5700557231903076\n",
            "Epoch 3, Step 25744: Loss = 0.540116012096405\n",
            "Epoch 3, Step 25745: Loss = 0.35525423288345337\n",
            "Epoch 3, Step 25746: Loss = 0.41848042607307434\n",
            "Epoch 3, Step 25747: Loss = 0.2813361585140228\n",
            "Epoch 3, Step 25748: Loss = 0.2260136753320694\n",
            "Epoch 3, Step 25749: Loss = 0.4065178632736206\n",
            "Epoch 3, Step 25750: Loss = 0.3423463702201843\n",
            "Epoch 3, Step 25751: Loss = 0.4045202136039734\n",
            "Epoch 3, Step 25752: Loss = 0.13480547070503235\n",
            "Epoch 3, Step 25753: Loss = 0.0983598455786705\n",
            "Epoch 3, Step 25754: Loss = 0.3266819715499878\n",
            "Epoch 3, Step 25755: Loss = 0.3774118721485138\n",
            "Epoch 3, Step 25756: Loss = 0.32157132029533386\n",
            "Epoch 3, Step 25757: Loss = 0.27508583664894104\n",
            "Epoch 3, Step 25758: Loss = 0.2658303380012512\n",
            "Epoch 3, Step 25759: Loss = 0.3698306083679199\n",
            "Epoch 3, Step 25760: Loss = 0.5042287707328796\n",
            "Epoch 3, Step 25761: Loss = 0.367338627576828\n",
            "Epoch 3, Step 25762: Loss = 0.190459743142128\n",
            "Epoch 3, Step 25763: Loss = 0.3157489001750946\n",
            "Epoch 3, Step 25764: Loss = 0.4311298727989197\n",
            "Epoch 3, Step 25765: Loss = 0.6818394064903259\n",
            "Epoch 3, Step 25766: Loss = 0.5360979437828064\n",
            "Epoch 3, Step 25767: Loss = 0.3299257159233093\n",
            "Epoch 3, Step 25768: Loss = 0.41206610202789307\n",
            "Epoch 3, Step 25769: Loss = 0.2843990921974182\n",
            "Epoch 3, Step 25770: Loss = 0.27075204253196716\n",
            "Epoch 3, Step 25771: Loss = 0.5710315704345703\n",
            "Epoch 3, Step 25772: Loss = 0.30616647005081177\n",
            "Epoch 3, Step 25773: Loss = 0.1897895634174347\n",
            "Epoch 3, Step 25774: Loss = 0.35055235028266907\n",
            "Epoch 3, Step 25775: Loss = 0.3933636248111725\n",
            "Epoch 3, Step 25776: Loss = 0.8532021641731262\n",
            "Epoch 3, Step 25777: Loss = 0.2869425117969513\n",
            "Epoch 3, Step 25778: Loss = 0.20557016134262085\n",
            "Epoch 3, Step 25779: Loss = 0.26238885521888733\n",
            "Epoch 3, Step 25780: Loss = 0.393343448638916\n",
            "Epoch 3, Step 25781: Loss = 0.2710140645503998\n",
            "Epoch 3, Step 25782: Loss = 0.20639708638191223\n",
            "Epoch 3, Step 25783: Loss = 0.5898478627204895\n",
            "Epoch 3, Step 25784: Loss = 0.46840333938598633\n",
            "Epoch 3, Step 25785: Loss = 0.3619273602962494\n",
            "Epoch 3, Step 25786: Loss = 0.40379029512405396\n",
            "Epoch 3, Step 25787: Loss = 0.41199207305908203\n",
            "Epoch 3, Step 25788: Loss = 0.4195685088634491\n",
            "Epoch 3, Step 25789: Loss = 0.3508025109767914\n",
            "Epoch 3, Step 25790: Loss = 0.3157406151294708\n",
            "Epoch 3, Step 25791: Loss = 0.4813174605369568\n",
            "Epoch 3, Step 25792: Loss = 0.5424432754516602\n",
            "Epoch 3, Step 25793: Loss = 0.2629196047782898\n",
            "Epoch 3, Step 25794: Loss = 0.3101915717124939\n",
            "Epoch 3, Step 25795: Loss = 0.41289860010147095\n",
            "Epoch 3, Step 25796: Loss = 0.34848538041114807\n",
            "Epoch 3, Step 25797: Loss = 0.21205571293830872\n",
            "Epoch 3, Step 25798: Loss = 0.31859657168388367\n",
            "Epoch 3, Step 25799: Loss = 0.40823715925216675\n",
            "Epoch 3, Step 25800: Loss = 0.18794123828411102\n",
            "Epoch 3, Step 25801: Loss = 0.1785193234682083\n",
            "Epoch 3, Step 25802: Loss = 0.48347944021224976\n",
            "Epoch 3, Step 25803: Loss = 0.49324408173561096\n",
            "Epoch 3, Step 25804: Loss = 0.17137347161769867\n",
            "Epoch 3, Step 25805: Loss = 0.3920868933200836\n",
            "Epoch 3, Step 25806: Loss = 0.2816978991031647\n",
            "Epoch 3, Step 25807: Loss = 0.3778240382671356\n",
            "Epoch 3, Step 25808: Loss = 0.39657533168792725\n",
            "Epoch 3, Step 25809: Loss = 0.3694687783718109\n",
            "Epoch 3, Step 25810: Loss = 0.6163226962089539\n",
            "Epoch 3, Step 25811: Loss = 0.5002664923667908\n",
            "Epoch 3, Step 25812: Loss = 0.3696742355823517\n",
            "Epoch 3, Step 25813: Loss = 0.20473386347293854\n",
            "Epoch 3, Step 25814: Loss = 0.19177040457725525\n",
            "Epoch 3, Step 25815: Loss = 0.20473267138004303\n",
            "Epoch 3, Step 25816: Loss = 0.16994139552116394\n",
            "Epoch 3, Step 25817: Loss = 0.22736899554729462\n",
            "Epoch 3, Step 25818: Loss = 0.28086769580841064\n",
            "Epoch 3, Step 25819: Loss = 0.28498873114585876\n",
            "Epoch 3, Step 25820: Loss = 0.24327880144119263\n",
            "Epoch 3, Step 25821: Loss = 0.3369765877723694\n",
            "Epoch 3, Step 25822: Loss = 0.5419098734855652\n",
            "Epoch 3, Step 25823: Loss = 0.42970743775367737\n",
            "Epoch 3, Step 25824: Loss = 0.2770649492740631\n",
            "Epoch 3, Step 25825: Loss = 0.25511088967323303\n",
            "Epoch 3, Step 25826: Loss = 0.3080894351005554\n",
            "Epoch 3, Step 25827: Loss = 0.3234057128429413\n",
            "Epoch 3, Step 25828: Loss = 0.2887124717235565\n",
            "Epoch 3, Step 25829: Loss = 0.34916776418685913\n",
            "Epoch 3, Step 25830: Loss = 0.20696097612380981\n",
            "Epoch 3, Step 25831: Loss = 0.38392746448516846\n",
            "Epoch 3, Step 25832: Loss = 0.3735732436180115\n",
            "Epoch 3, Step 25833: Loss = 0.504787266254425\n",
            "Epoch 3, Step 25834: Loss = 0.25178229808807373\n",
            "Epoch 3, Step 25835: Loss = 0.3593618869781494\n",
            "Epoch 3, Step 25836: Loss = 0.22086898982524872\n",
            "Epoch 3, Step 25837: Loss = 0.2409156709909439\n",
            "Epoch 3, Step 25838: Loss = 0.30285006761550903\n",
            "Epoch 3, Step 25839: Loss = 0.21513283252716064\n",
            "Epoch 3, Step 25840: Loss = 0.696020245552063\n",
            "Epoch 3, Step 25841: Loss = 0.3232596516609192\n",
            "Epoch 3, Step 25842: Loss = 0.22099241614341736\n",
            "Epoch 3, Step 25843: Loss = 0.3406715989112854\n",
            "Epoch 3, Step 25844: Loss = 0.3326161205768585\n",
            "Epoch 3, Step 25845: Loss = 0.32480940222740173\n",
            "Epoch 3, Step 25846: Loss = 0.19978860020637512\n",
            "Epoch 3, Step 25847: Loss = 0.46047243475914\n",
            "Epoch 3, Step 25848: Loss = 0.2377556562423706\n",
            "Epoch 3, Step 25849: Loss = 0.564592719078064\n",
            "Epoch 3, Step 25850: Loss = 0.6927947998046875\n",
            "Epoch 3, Step 25851: Loss = 0.32591354846954346\n",
            "Epoch 3, Step 25852: Loss = 0.2600131630897522\n",
            "Epoch 3, Step 25853: Loss = 0.3124600350856781\n",
            "Epoch 3, Step 25854: Loss = 0.42504802346229553\n",
            "Epoch 3, Step 25855: Loss = 0.6211934089660645\n",
            "Epoch 3, Step 25856: Loss = 0.2728692591190338\n",
            "Epoch 3, Step 25857: Loss = 0.37643566727638245\n",
            "Epoch 3, Step 25858: Loss = 0.14976543188095093\n",
            "Epoch 3, Step 25859: Loss = 0.2727011740207672\n",
            "Epoch 3, Step 25860: Loss = 0.2138112634420395\n",
            "Epoch 3, Step 25861: Loss = 0.3010386824607849\n",
            "Epoch 3, Step 25862: Loss = 0.2974436283111572\n",
            "Epoch 3, Step 25863: Loss = 0.36673861742019653\n",
            "Epoch 3, Step 25864: Loss = 0.2709974944591522\n",
            "Epoch 3, Step 25865: Loss = 0.29873669147491455\n",
            "Epoch 3, Step 25866: Loss = 0.34298017621040344\n",
            "Epoch 3, Step 25867: Loss = 0.3008444011211395\n",
            "Epoch 3, Step 25868: Loss = 0.26744747161865234\n",
            "Epoch 3, Step 25869: Loss = 0.2870428264141083\n",
            "Epoch 3, Step 25870: Loss = 0.2493584007024765\n",
            "Epoch 3, Step 25871: Loss = 0.19912324845790863\n",
            "Epoch 3, Step 25872: Loss = 0.2060159295797348\n",
            "Epoch 3, Step 25873: Loss = 0.2557479441165924\n",
            "Epoch 3, Step 25874: Loss = 0.12027893215417862\n",
            "Epoch 3, Step 25875: Loss = 0.24788491427898407\n",
            "Epoch 3, Step 25876: Loss = 0.2098706066608429\n",
            "Epoch 3, Step 25877: Loss = 0.2738543748855591\n",
            "Epoch 3, Step 25878: Loss = 0.3352228105068207\n",
            "Epoch 3, Step 25879: Loss = 0.2980612814426422\n",
            "Epoch 3, Step 25880: Loss = 0.2673289477825165\n",
            "Epoch 3, Step 25881: Loss = 0.3658562898635864\n",
            "Epoch 3, Step 25882: Loss = 0.4293453097343445\n",
            "Epoch 3, Step 25883: Loss = 0.32811135053634644\n",
            "Epoch 3, Step 25884: Loss = 0.3409542143344879\n",
            "Epoch 3, Step 25885: Loss = 0.5173558592796326\n",
            "Epoch 3, Step 25886: Loss = 0.22154632210731506\n",
            "Epoch 3, Step 25887: Loss = 0.41495823860168457\n",
            "Epoch 3, Step 25888: Loss = 0.3228205144405365\n",
            "Epoch 3, Step 25889: Loss = 0.3054194450378418\n",
            "Epoch 3, Step 25890: Loss = 0.46375587582588196\n",
            "Epoch 3, Step 25891: Loss = 0.1805182546377182\n",
            "Epoch 3, Step 25892: Loss = 0.24367882311344147\n",
            "Epoch 3, Step 25893: Loss = 0.1825927197933197\n",
            "Epoch 3, Step 25894: Loss = 0.330997496843338\n",
            "Epoch 3, Step 25895: Loss = 0.40946975350379944\n",
            "Epoch 3, Step 25896: Loss = 0.2957814335823059\n",
            "Epoch 3, Step 25897: Loss = 0.5177266597747803\n",
            "Epoch 3, Step 25898: Loss = 0.18538278341293335\n",
            "Epoch 3, Step 25899: Loss = 0.22494560480117798\n",
            "Epoch 3, Step 25900: Loss = 0.26521286368370056\n",
            "Epoch 3, Step 25901: Loss = 0.29359450936317444\n",
            "Epoch 3, Step 25902: Loss = 0.384832501411438\n",
            "Epoch 3, Step 25903: Loss = 0.33438485860824585\n",
            "Epoch 3, Step 25904: Loss = 0.2450752854347229\n",
            "Epoch 3, Step 25905: Loss = 0.4025648832321167\n",
            "Epoch 3, Step 25906: Loss = 0.34386759996414185\n",
            "Epoch 3, Step 25907: Loss = 0.5222441554069519\n",
            "Epoch 3, Step 25908: Loss = 0.24845409393310547\n",
            "Epoch 3, Step 25909: Loss = 0.5083417892456055\n",
            "Epoch 3, Step 25910: Loss = 0.2889607846736908\n",
            "Epoch 3, Step 25911: Loss = 0.25740811228752136\n",
            "Epoch 3, Step 25912: Loss = 0.18189053237438202\n",
            "Epoch 3, Step 25913: Loss = 0.6799113154411316\n",
            "Epoch 3, Step 25914: Loss = 0.2660755515098572\n",
            "Epoch 3, Step 25915: Loss = 0.25311633944511414\n",
            "Epoch 3, Step 25916: Loss = 0.2514153718948364\n",
            "Epoch 3, Step 25917: Loss = 0.3402888774871826\n",
            "Epoch 3, Step 25918: Loss = 0.3462596833705902\n",
            "Epoch 3, Step 25919: Loss = 0.26786890625953674\n",
            "Epoch 3, Step 25920: Loss = 0.287808358669281\n",
            "Epoch 3, Step 25921: Loss = 0.23057805001735687\n",
            "Epoch 3, Step 25922: Loss = 0.42785611748695374\n",
            "Epoch 3, Step 25923: Loss = 0.3663291037082672\n",
            "Epoch 3, Step 25924: Loss = 0.3500524163246155\n",
            "Epoch 3, Step 25925: Loss = 0.3460516333580017\n",
            "Epoch 3, Step 25926: Loss = 0.33715924620628357\n",
            "Epoch 3, Step 25927: Loss = 0.3149280250072479\n",
            "Epoch 3, Step 25928: Loss = 0.25036531686782837\n",
            "Epoch 3, Step 25929: Loss = 0.4781270921230316\n",
            "Epoch 3, Step 25930: Loss = 0.33906272053718567\n",
            "Epoch 3, Step 25931: Loss = 0.5938938856124878\n",
            "Epoch 3, Step 25932: Loss = 0.20549710094928741\n",
            "Epoch 3, Step 25933: Loss = 0.3690830171108246\n",
            "Epoch 3, Step 25934: Loss = 0.2608732283115387\n",
            "Epoch 3, Step 25935: Loss = 0.3218226730823517\n",
            "Epoch 3, Step 25936: Loss = 0.2997245192527771\n",
            "Epoch 3, Step 25937: Loss = 0.2045884132385254\n",
            "Epoch 3, Step 25938: Loss = 0.20577582716941833\n",
            "Epoch 3, Step 25939: Loss = 0.3714875876903534\n",
            "Epoch 3, Step 25940: Loss = 0.45373281836509705\n",
            "Epoch 3, Step 25941: Loss = 0.3598838746547699\n",
            "Epoch 3, Step 25942: Loss = 0.5610800385475159\n",
            "Epoch 3, Step 25943: Loss = 0.5103207230567932\n",
            "Epoch 3, Step 25944: Loss = 0.2449374943971634\n",
            "Epoch 3, Step 25945: Loss = 0.28479406237602234\n",
            "Epoch 3, Step 25946: Loss = 0.1964539885520935\n",
            "Epoch 3, Step 25947: Loss = 0.25295591354370117\n",
            "Epoch 3, Step 25948: Loss = 0.23800884187221527\n",
            "Epoch 3, Step 25949: Loss = 0.37676599621772766\n",
            "Epoch 3, Step 25950: Loss = 0.30753880739212036\n",
            "Epoch 3, Step 25951: Loss = 0.20319293439388275\n",
            "Epoch 3, Step 25952: Loss = 0.3866945207118988\n",
            "Epoch 3, Step 25953: Loss = 0.2764465808868408\n",
            "Epoch 3, Step 25954: Loss = 0.34447020292282104\n",
            "Epoch 3, Step 25955: Loss = 0.5149584412574768\n",
            "Epoch 3, Step 25956: Loss = 0.305466890335083\n",
            "Epoch 3, Step 25957: Loss = 0.24102318286895752\n",
            "Epoch 3, Step 25958: Loss = 0.29895779490470886\n",
            "Epoch 3, Step 25959: Loss = 0.1735042929649353\n",
            "Epoch 3, Step 25960: Loss = 0.22339625656604767\n",
            "Epoch 3, Step 25961: Loss = 0.2836054265499115\n",
            "Epoch 3, Step 25962: Loss = 0.2591981887817383\n",
            "Epoch 3, Step 25963: Loss = 0.30609434843063354\n",
            "Epoch 3, Step 25964: Loss = 0.27812713384628296\n",
            "Epoch 3, Step 25965: Loss = 0.24724191427230835\n",
            "Epoch 3, Step 25966: Loss = 0.2966434061527252\n",
            "Epoch 3, Step 25967: Loss = 0.3201192617416382\n",
            "Epoch 3, Step 25968: Loss = 0.35579222440719604\n",
            "Epoch 3, Step 25969: Loss = 0.21187245845794678\n",
            "Epoch 3, Step 25970: Loss = 0.39642783999443054\n",
            "Epoch 3, Step 25971: Loss = 0.2983079254627228\n",
            "Epoch 3, Step 25972: Loss = 0.47865012288093567\n",
            "Epoch 3, Step 25973: Loss = 0.1499929428100586\n",
            "Epoch 3, Step 25974: Loss = 0.42442595958709717\n",
            "Epoch 3, Step 25975: Loss = 0.546363890171051\n",
            "Epoch 3, Step 25976: Loss = 0.14385145902633667\n",
            "Epoch 3, Step 25977: Loss = 0.25978851318359375\n",
            "Epoch 3, Step 25978: Loss = 0.4586404860019684\n",
            "Epoch 3, Step 25979: Loss = 0.6741189360618591\n",
            "Epoch 3, Step 25980: Loss = 0.25749579071998596\n",
            "Epoch 3, Step 25981: Loss = 0.2692504823207855\n",
            "Epoch 3, Step 25982: Loss = 0.2789929211139679\n",
            "Epoch 3, Step 25983: Loss = 0.6122715473175049\n",
            "Epoch 3, Step 25984: Loss = 0.132581427693367\n",
            "Epoch 3, Step 25985: Loss = 0.163995161652565\n",
            "Epoch 3, Step 25986: Loss = 0.37058156728744507\n",
            "Epoch 3, Step 25987: Loss = 0.3429945707321167\n",
            "Epoch 3, Step 25988: Loss = 0.4141280949115753\n",
            "Epoch 3, Step 25989: Loss = 0.22536487877368927\n",
            "Epoch 3, Step 25990: Loss = 0.2167665958404541\n",
            "Epoch 3, Step 25991: Loss = 0.18365637958049774\n",
            "Epoch 3, Step 25992: Loss = 0.16698814928531647\n",
            "Epoch 3, Step 25993: Loss = 0.3506285846233368\n",
            "Epoch 3, Step 25994: Loss = 0.3063261806964874\n",
            "Epoch 3, Step 25995: Loss = 0.37852731347084045\n",
            "Epoch 3, Step 25996: Loss = 0.39591383934020996\n",
            "Epoch 3, Step 25997: Loss = 0.29314878582954407\n",
            "Epoch 3, Step 25998: Loss = 0.5155144929885864\n",
            "Epoch 3, Step 25999: Loss = 0.516319990158081\n",
            "Epoch 3, Step 26000: Loss = 0.26270705461502075\n",
            "Epoch 3, Step 26001: Loss = 0.43676891922950745\n",
            "Epoch 3, Step 26002: Loss = 0.5352765917778015\n",
            "Epoch 3, Step 26003: Loss = 0.483183890581131\n",
            "Epoch 3, Step 26004: Loss = 0.2510451078414917\n",
            "Epoch 3, Step 26005: Loss = 0.3830518126487732\n",
            "Epoch 3, Step 26006: Loss = 0.5780678391456604\n",
            "Epoch 3, Step 26007: Loss = 0.2641666531562805\n",
            "Epoch 3, Step 26008: Loss = 0.42290008068084717\n",
            "Epoch 3, Step 26009: Loss = 0.26947513222694397\n",
            "Epoch 3, Step 26010: Loss = 0.5295616984367371\n",
            "Epoch 3, Step 26011: Loss = 0.184442400932312\n",
            "Epoch 3, Step 26012: Loss = 0.20722903311252594\n",
            "Epoch 3, Step 26013: Loss = 0.19918446242809296\n",
            "Epoch 3, Step 26014: Loss = 0.5106629133224487\n",
            "Epoch 3, Step 26015: Loss = 0.41214296221733093\n",
            "Epoch 3, Step 26016: Loss = 0.26547563076019287\n",
            "Epoch 3, Step 26017: Loss = 0.4735490381717682\n",
            "Epoch 3, Step 26018: Loss = 0.379596471786499\n",
            "Epoch 3, Step 26019: Loss = 0.36943376064300537\n",
            "Epoch 3, Step 26020: Loss = 0.23122841119766235\n",
            "Epoch 3, Step 26021: Loss = 0.16555547714233398\n",
            "Epoch 3, Step 26022: Loss = 0.29991617798805237\n",
            "Epoch 3, Step 26023: Loss = 0.2021414339542389\n",
            "Epoch 3, Step 26024: Loss = 0.4876091480255127\n",
            "Epoch 3, Step 26025: Loss = 0.3587527275085449\n",
            "Epoch 3, Step 26026: Loss = 0.34571877121925354\n",
            "Epoch 3, Step 26027: Loss = 0.5048388838768005\n",
            "Epoch 3, Step 26028: Loss = 0.3628707826137543\n",
            "Epoch 3, Step 26029: Loss = 0.3772566020488739\n",
            "Epoch 3, Step 26030: Loss = 0.2360382378101349\n",
            "Epoch 3, Step 26031: Loss = 0.32715529203414917\n",
            "Epoch 3, Step 26032: Loss = 0.3082985281944275\n",
            "Epoch 3, Step 26033: Loss = 0.4240086078643799\n",
            "Epoch 3, Step 26034: Loss = 0.21474026143550873\n",
            "Epoch 3, Step 26035: Loss = 0.2618076205253601\n",
            "Epoch 3, Step 26036: Loss = 0.29466649889945984\n",
            "Epoch 3, Step 26037: Loss = 0.3227447271347046\n",
            "Epoch 3, Step 26038: Loss = 0.40302979946136475\n",
            "Epoch 3, Step 26039: Loss = 0.3452664017677307\n",
            "Epoch 3, Step 26040: Loss = 0.15064191818237305\n",
            "Epoch 3, Step 26041: Loss = 0.417606383562088\n",
            "Epoch 3, Step 26042: Loss = 0.37831705808639526\n",
            "Epoch 3, Step 26043: Loss = 0.24160605669021606\n",
            "Epoch 3, Step 26044: Loss = 0.16081462800502777\n",
            "Epoch 3, Step 26045: Loss = 0.2102937549352646\n",
            "Epoch 3, Step 26046: Loss = 0.31169459223747253\n",
            "Epoch 3, Step 26047: Loss = 0.3974228501319885\n",
            "Epoch 3, Step 26048: Loss = 0.3703879117965698\n",
            "Epoch 3, Step 26049: Loss = 0.30603858828544617\n",
            "Epoch 3, Step 26050: Loss = 0.29567092657089233\n",
            "Epoch 3, Step 26051: Loss = 0.38245803117752075\n",
            "Epoch 3, Step 26052: Loss = 0.3389500081539154\n",
            "Epoch 3, Step 26053: Loss = 0.2744990885257721\n",
            "Epoch 3, Step 26054: Loss = 0.1726749688386917\n",
            "Epoch 3, Step 26055: Loss = 0.18325571715831757\n",
            "Epoch 3, Step 26056: Loss = 0.3363187611103058\n",
            "Epoch 3, Step 26057: Loss = 0.2991565465927124\n",
            "Epoch 3, Step 26058: Loss = 0.3164861500263214\n",
            "Epoch 3, Step 26059: Loss = 0.29678624868392944\n",
            "Epoch 3, Step 26060: Loss = 0.3203909397125244\n",
            "Epoch 3, Step 26061: Loss = 0.2927892506122589\n",
            "Epoch 3, Step 26062: Loss = 0.39079761505126953\n",
            "Epoch 3, Step 26063: Loss = 0.6734168529510498\n",
            "Epoch 3, Step 26064: Loss = 0.49273908138275146\n",
            "Epoch 3, Step 26065: Loss = 0.33273616433143616\n",
            "Epoch 3, Step 26066: Loss = 0.537196934223175\n",
            "Epoch 3, Step 26067: Loss = 0.415872186422348\n",
            "Epoch 3, Step 26068: Loss = 0.4489011764526367\n",
            "Epoch 3, Step 26069: Loss = 0.47988587617874146\n",
            "Epoch 3, Step 26070: Loss = 0.2694891095161438\n",
            "Epoch 3, Step 26071: Loss = 0.29898640513420105\n",
            "Epoch 3, Step 26072: Loss = 0.2904171049594879\n",
            "Epoch 3, Step 26073: Loss = 0.24446582794189453\n",
            "Epoch 3, Step 26074: Loss = 0.3363790214061737\n",
            "Epoch 3, Step 26075: Loss = 0.3595966398715973\n",
            "Epoch 3, Step 26076: Loss = 0.2831689119338989\n",
            "Epoch 3, Step 26077: Loss = 0.29993897676467896\n",
            "Epoch 3, Step 26078: Loss = 0.4049787223339081\n",
            "Epoch 3, Step 26079: Loss = 0.28962817788124084\n",
            "Epoch 3, Step 26080: Loss = 0.26692235469818115\n",
            "Epoch 3, Step 26081: Loss = 0.36148619651794434\n",
            "Epoch 3, Step 26082: Loss = 0.3754674792289734\n",
            "Epoch 3, Step 26083: Loss = 0.6281082034111023\n",
            "Epoch 3, Step 26084: Loss = 0.2458854615688324\n",
            "Epoch 3, Step 26085: Loss = 0.4999079406261444\n",
            "Epoch 3, Step 26086: Loss = 0.15743021667003632\n",
            "Epoch 3, Step 26087: Loss = 0.35315579175949097\n",
            "Epoch 3, Step 26088: Loss = 0.30488869547843933\n",
            "Epoch 3, Step 26089: Loss = 0.44686371088027954\n",
            "Epoch 3, Step 26090: Loss = 0.24125170707702637\n",
            "Epoch 3, Step 26091: Loss = 0.3326647877693176\n",
            "Epoch 3, Step 26092: Loss = 0.42407411336898804\n",
            "Epoch 3, Step 26093: Loss = 0.18375103175640106\n",
            "Epoch 3, Step 26094: Loss = 0.3659123182296753\n",
            "Epoch 3, Step 26095: Loss = 0.41262006759643555\n",
            "Epoch 3, Step 26096: Loss = 0.3597317337989807\n",
            "Epoch 3, Step 26097: Loss = 0.21945714950561523\n",
            "Epoch 3, Step 26098: Loss = 0.18188922107219696\n",
            "Epoch 3, Step 26099: Loss = 0.2869427800178528\n",
            "Epoch 3, Step 26100: Loss = 0.2908172607421875\n",
            "Epoch 3, Step 26101: Loss = 0.2534694969654083\n",
            "Epoch 3, Step 26102: Loss = 0.2213982790708542\n",
            "Epoch 3, Step 26103: Loss = 0.1522655189037323\n",
            "Epoch 3, Step 26104: Loss = 0.33160263299942017\n",
            "Epoch 3, Step 26105: Loss = 0.6272491216659546\n",
            "Epoch 3, Step 26106: Loss = 0.3382873237133026\n",
            "Epoch 3, Step 26107: Loss = 0.43859896063804626\n",
            "Epoch 3, Step 26108: Loss = 0.3938368260860443\n",
            "Epoch 3, Step 26109: Loss = 0.3048112094402313\n",
            "Epoch 3, Step 26110: Loss = 0.38627415895462036\n",
            "Epoch 3, Step 26111: Loss = 0.3622061014175415\n",
            "Epoch 3, Step 26112: Loss = 0.643770694732666\n",
            "Epoch 3, Step 26113: Loss = 0.4308260381221771\n",
            "Epoch 3, Step 26114: Loss = 0.20903730392456055\n",
            "Epoch 3, Step 26115: Loss = 0.7339468002319336\n",
            "Epoch 3, Step 26116: Loss = 0.24676959216594696\n",
            "Epoch 3, Step 26117: Loss = 0.21674694120883942\n",
            "Epoch 3, Step 26118: Loss = 0.4823077321052551\n",
            "Epoch 3, Step 26119: Loss = 0.4822447597980499\n",
            "Epoch 3, Step 26120: Loss = 0.40239641070365906\n",
            "Epoch 3, Step 26121: Loss = 0.4957451820373535\n",
            "Epoch 3, Step 26122: Loss = 0.42937788367271423\n",
            "Epoch 3, Step 26123: Loss = 0.5931864976882935\n",
            "Epoch 3, Step 26124: Loss = 0.4733339250087738\n",
            "Epoch 3, Step 26125: Loss = 0.4235610365867615\n",
            "Epoch 3, Step 26126: Loss = 0.2016802579164505\n",
            "Epoch 3, Step 26127: Loss = 0.3185432553291321\n",
            "Epoch 3, Step 26128: Loss = 0.5161100029945374\n",
            "Epoch 3, Step 26129: Loss = 0.4046684503555298\n",
            "Epoch 3, Step 26130: Loss = 0.39938369393348694\n",
            "Epoch 3, Step 26131: Loss = 0.2805037796497345\n",
            "Epoch 3, Step 26132: Loss = 0.5507345795631409\n",
            "Epoch 3, Step 26133: Loss = 0.2632000744342804\n",
            "Epoch 3, Step 26134: Loss = 0.35899022221565247\n",
            "Epoch 3, Step 26135: Loss = 0.3816387355327606\n",
            "Epoch 3, Step 26136: Loss = 0.3770177662372589\n",
            "Epoch 3, Step 26137: Loss = 0.33278247714042664\n",
            "Epoch 3, Step 26138: Loss = 0.3496045470237732\n",
            "Epoch 3, Step 26139: Loss = 0.3188302218914032\n",
            "Epoch 3, Step 26140: Loss = 0.37685251235961914\n",
            "Epoch 3, Step 26141: Loss = 0.28235313296318054\n",
            "Epoch 3, Step 26142: Loss = 0.4285888969898224\n",
            "Epoch 3, Step 26143: Loss = 0.2264404296875\n",
            "Epoch 3, Step 26144: Loss = 0.20824621617794037\n",
            "Epoch 3, Step 26145: Loss = 0.3431248366832733\n",
            "Epoch 3, Step 26146: Loss = 0.19579382240772247\n",
            "Epoch 3, Step 26147: Loss = 0.3441230058670044\n",
            "Epoch 3, Step 26148: Loss = 0.2460280954837799\n",
            "Epoch 3, Step 26149: Loss = 0.21748125553131104\n",
            "Epoch 3, Step 26150: Loss = 0.1714288294315338\n",
            "Epoch 3, Step 26151: Loss = 0.425124853849411\n",
            "Epoch 3, Step 26152: Loss = 0.3902163803577423\n",
            "Epoch 3, Step 26153: Loss = 0.43950730562210083\n",
            "Epoch 3, Step 26154: Loss = 0.6681322455406189\n",
            "Epoch 3, Step 26155: Loss = 0.36899814009666443\n",
            "Epoch 3, Step 26156: Loss = 0.26879891753196716\n",
            "Epoch 3, Step 26157: Loss = 0.13743466138839722\n",
            "Epoch 3, Step 26158: Loss = 0.16233424842357635\n",
            "Epoch 3, Step 26159: Loss = 0.2910514771938324\n",
            "Epoch 3, Step 26160: Loss = 0.2772587835788727\n",
            "Epoch 3, Step 26161: Loss = 0.27677789330482483\n",
            "Epoch 3, Step 26162: Loss = 0.23825643956661224\n",
            "Epoch 3, Step 26163: Loss = 0.23635981976985931\n",
            "Epoch 3, Step 26164: Loss = 0.4164762496948242\n",
            "Epoch 3, Step 26165: Loss = 0.4029141962528229\n",
            "Epoch 3, Step 26166: Loss = 0.49014899134635925\n",
            "Epoch 3, Step 26167: Loss = 0.34979626536369324\n",
            "Epoch 3, Step 26168: Loss = 0.41002315282821655\n",
            "Epoch 3, Step 26169: Loss = 0.2567187547683716\n",
            "Epoch 3, Step 26170: Loss = 0.2396126389503479\n",
            "Epoch 3, Step 26171: Loss = 0.3452487885951996\n",
            "Epoch 3, Step 26172: Loss = 0.28359124064445496\n",
            "Epoch 3, Step 26173: Loss = 0.2681114077568054\n",
            "Epoch 3, Step 26174: Loss = 0.35878509283065796\n",
            "Epoch 3, Step 26175: Loss = 0.18583720922470093\n",
            "Epoch 3, Step 26176: Loss = 0.2665790915489197\n",
            "Epoch 3, Step 26177: Loss = 0.3866322934627533\n",
            "Epoch 3, Step 26178: Loss = 0.42380520701408386\n",
            "Epoch 3, Step 26179: Loss = 0.7599183320999146\n",
            "Epoch 3, Step 26180: Loss = 0.3416251838207245\n",
            "Epoch 3, Step 26181: Loss = 0.23303131759166718\n",
            "Epoch 3, Step 26182: Loss = 0.42787274718284607\n",
            "Epoch 3, Step 26183: Loss = 0.3702853322029114\n",
            "Epoch 3, Step 26184: Loss = 0.4703413248062134\n",
            "Epoch 3, Step 26185: Loss = 0.2753308415412903\n",
            "Epoch 3, Step 26186: Loss = 0.3238629400730133\n",
            "Epoch 3, Step 26187: Loss = 0.2274591326713562\n",
            "Epoch 3, Step 26188: Loss = 0.3233935534954071\n",
            "Epoch 3, Step 26189: Loss = 0.374359130859375\n",
            "Epoch 3, Step 26190: Loss = 0.33475592732429504\n",
            "Epoch 3, Step 26191: Loss = 0.3404447138309479\n",
            "Epoch 3, Step 26192: Loss = 0.7923305630683899\n",
            "Epoch 3, Step 26193: Loss = 0.3448268473148346\n",
            "Epoch 3, Step 26194: Loss = 0.4112948179244995\n",
            "Epoch 3, Step 26195: Loss = 0.35317498445510864\n",
            "Epoch 3, Step 26196: Loss = 0.39268577098846436\n",
            "Epoch 3, Step 26197: Loss = 0.2481403946876526\n",
            "Epoch 3, Step 26198: Loss = 0.39068177342414856\n",
            "Epoch 3, Step 26199: Loss = 0.46634748578071594\n",
            "Epoch 3, Step 26200: Loss = 0.0630229040980339\n",
            "Epoch 3, Step 26201: Loss = 0.4493410587310791\n",
            "Epoch 3, Step 26202: Loss = 0.5920141935348511\n",
            "Epoch 3, Step 26203: Loss = 0.29750415682792664\n",
            "Epoch 3, Step 26204: Loss = 0.25849413871765137\n",
            "Epoch 3, Step 26205: Loss = 0.2376922369003296\n",
            "Epoch 3, Step 26206: Loss = 0.2877316474914551\n",
            "Epoch 3, Step 26207: Loss = 0.44817817211151123\n",
            "Epoch 3, Step 26208: Loss = 0.13975124061107635\n",
            "Epoch 3, Step 26209: Loss = 0.297439843416214\n",
            "Epoch 3, Step 26210: Loss = 0.3443038761615753\n",
            "Epoch 3, Step 26211: Loss = 0.4232189655303955\n",
            "Epoch 3, Step 26212: Loss = 0.25985100865364075\n",
            "Epoch 3, Step 26213: Loss = 0.28292208909988403\n",
            "Epoch 3, Step 26214: Loss = 0.3236759901046753\n",
            "Epoch 3, Step 26215: Loss = 0.4720054268836975\n",
            "Epoch 3, Step 26216: Loss = 0.38259389996528625\n",
            "Epoch 3, Step 26217: Loss = 0.609822154045105\n",
            "Epoch 3, Step 26218: Loss = 0.3714883327484131\n",
            "Epoch 3, Step 26219: Loss = 0.2751750946044922\n",
            "Epoch 3, Step 26220: Loss = 0.34586355090141296\n",
            "Epoch 3, Step 26221: Loss = 0.35737934708595276\n",
            "Epoch 3, Step 26222: Loss = 0.3873332738876343\n",
            "Epoch 3, Step 26223: Loss = 0.26690346002578735\n",
            "Epoch 3, Step 26224: Loss = 0.41366255283355713\n",
            "Epoch 3, Step 26225: Loss = 0.3404330313205719\n",
            "Epoch 3, Step 26226: Loss = 0.2524867653846741\n",
            "Epoch 3, Step 26227: Loss = 0.26688963174819946\n",
            "Epoch 3, Step 26228: Loss = 0.20631256699562073\n",
            "Epoch 3, Step 26229: Loss = 0.24066512286663055\n",
            "Epoch 3, Step 26230: Loss = 0.3871609568595886\n",
            "Epoch 3, Step 26231: Loss = 0.4674605131149292\n",
            "Epoch 3, Step 26232: Loss = 0.36671721935272217\n",
            "Epoch 3, Step 26233: Loss = 0.371100515127182\n",
            "Epoch 3, Step 26234: Loss = 0.2662183344364166\n",
            "Epoch 3, Step 26235: Loss = 0.24237628281116486\n",
            "Epoch 3, Step 26236: Loss = 0.22956058382987976\n",
            "Epoch 3, Step 26237: Loss = 0.2038746476173401\n",
            "Epoch 3, Step 26238: Loss = 0.36847928166389465\n",
            "Epoch 3, Step 26239: Loss = 0.19581755995750427\n",
            "Epoch 3, Step 26240: Loss = 0.3136953115463257\n",
            "Epoch 3, Step 26241: Loss = 0.33170345425605774\n",
            "Epoch 3, Step 26242: Loss = 0.42269229888916016\n",
            "Epoch 3, Step 26243: Loss = 0.30496999621391296\n",
            "Epoch 3, Step 26244: Loss = 0.15668988227844238\n",
            "Epoch 3, Step 26245: Loss = 0.34501197934150696\n",
            "Epoch 3, Step 26246: Loss = 0.2649970054626465\n",
            "Epoch 3, Step 26247: Loss = 0.3849264979362488\n",
            "Epoch 3, Step 26248: Loss = 0.32050788402557373\n",
            "Epoch 3, Step 26249: Loss = 0.39153000712394714\n",
            "Epoch 3, Step 26250: Loss = 0.23060490190982819\n",
            "Epoch 3, Step 26251: Loss = 0.28475990891456604\n",
            "Epoch 3, Step 26252: Loss = 0.28320589661598206\n",
            "Epoch 3, Step 26253: Loss = 0.33754056692123413\n",
            "Epoch 3, Step 26254: Loss = 0.24998629093170166\n",
            "Epoch 3, Step 26255: Loss = 0.19203723967075348\n",
            "Epoch 3, Step 26256: Loss = 0.2974860370159149\n",
            "Epoch 3, Step 26257: Loss = 0.45050427317619324\n",
            "Epoch 3, Step 26258: Loss = 0.2514154314994812\n",
            "Epoch 3, Step 26259: Loss = 0.1870221495628357\n",
            "Epoch 3, Step 26260: Loss = 0.17607766389846802\n",
            "Epoch 3, Step 26261: Loss = 0.2214224487543106\n",
            "Epoch 3, Step 26262: Loss = 0.3182523250579834\n",
            "Epoch 3, Step 26263: Loss = 0.32005971670150757\n",
            "Epoch 3, Step 26264: Loss = 0.362922340631485\n",
            "Epoch 3, Step 26265: Loss = 0.23719151318073273\n",
            "Epoch 3, Step 26266: Loss = 0.34028199315071106\n",
            "Epoch 3, Step 26267: Loss = 0.26064372062683105\n",
            "Epoch 3, Step 26268: Loss = 0.5237730741500854\n",
            "Epoch 3, Step 26269: Loss = 0.25415822863578796\n",
            "Epoch 3, Step 26270: Loss = 0.3263591229915619\n",
            "Epoch 3, Step 26271: Loss = 0.21767300367355347\n",
            "Epoch 3, Step 26272: Loss = 0.5377434492111206\n",
            "Epoch 3, Step 26273: Loss = 0.29883554577827454\n",
            "Epoch 3, Step 26274: Loss = 0.4085731506347656\n",
            "Epoch 3, Step 26275: Loss = 0.26470842957496643\n",
            "Epoch 3, Step 26276: Loss = 0.24922233819961548\n",
            "Epoch 3, Step 26277: Loss = 0.2163105309009552\n",
            "Epoch 3, Step 26278: Loss = 0.3512825667858124\n",
            "Epoch 3, Step 26279: Loss = 0.3832171559333801\n",
            "Epoch 3, Step 26280: Loss = 0.5574492812156677\n",
            "Epoch 3, Step 26281: Loss = 0.288739413022995\n",
            "Epoch 3, Step 26282: Loss = 0.31292179226875305\n",
            "Epoch 3, Step 26283: Loss = 0.2559613585472107\n",
            "Epoch 3, Step 26284: Loss = 0.35927581787109375\n",
            "Epoch 3, Step 26285: Loss = 0.4226545989513397\n",
            "Epoch 3, Step 26286: Loss = 0.16971372067928314\n",
            "Epoch 3, Step 26287: Loss = 0.2677779793739319\n",
            "Epoch 3, Step 26288: Loss = 0.33197107911109924\n",
            "Epoch 3, Step 26289: Loss = 0.23664601147174835\n",
            "Epoch 3, Step 26290: Loss = 0.2449052482843399\n",
            "Epoch 3, Step 26291: Loss = 0.3092307150363922\n",
            "Epoch 3, Step 26292: Loss = 0.4402916729450226\n",
            "Epoch 3, Step 26293: Loss = 0.4188147783279419\n",
            "Epoch 3, Step 26294: Loss = 0.3942655920982361\n",
            "Epoch 3, Step 26295: Loss = 0.5072667598724365\n",
            "Epoch 3, Step 26296: Loss = 0.4999546408653259\n",
            "Epoch 3, Step 26297: Loss = 0.23394432663917542\n",
            "Epoch 3, Step 26298: Loss = 0.2899760901927948\n",
            "Epoch 3, Step 26299: Loss = 0.23519328236579895\n",
            "Epoch 3, Step 26300: Loss = 0.26162171363830566\n",
            "Epoch 3, Step 26301: Loss = 0.3826267421245575\n",
            "Epoch 3, Step 26302: Loss = 0.29892948269844055\n",
            "Epoch 3, Step 26303: Loss = 0.4468715786933899\n",
            "Epoch 3, Step 26304: Loss = 0.3026607632637024\n",
            "Epoch 3, Step 26305: Loss = 0.3828711211681366\n",
            "Epoch 3, Step 26306: Loss = 0.28119704127311707\n",
            "Epoch 3, Step 26307: Loss = 0.4780482351779938\n",
            "Epoch 3, Step 26308: Loss = 0.5358808636665344\n",
            "Epoch 3, Step 26309: Loss = 0.512631893157959\n",
            "Epoch 3, Step 26310: Loss = 0.23192819952964783\n",
            "Epoch 3, Step 26311: Loss = 0.20034608244895935\n",
            "Epoch 3, Step 26312: Loss = 0.2833513617515564\n",
            "Epoch 3, Step 26313: Loss = 0.28634271025657654\n",
            "Epoch 3, Step 26314: Loss = 0.3731471300125122\n",
            "Epoch 3, Step 26315: Loss = 0.327174574136734\n",
            "Epoch 3, Step 26316: Loss = 0.327290415763855\n",
            "Epoch 3, Step 26317: Loss = 0.6231489777565002\n",
            "Epoch 3, Step 26318: Loss = 0.45173773169517517\n",
            "Epoch 3, Step 26319: Loss = 0.47360771894454956\n",
            "Epoch 3, Step 26320: Loss = 0.21530626714229584\n",
            "Epoch 3, Step 26321: Loss = 0.46963393688201904\n",
            "Epoch 3, Step 26322: Loss = 0.2320251762866974\n",
            "Epoch 3, Step 26323: Loss = 0.3942731022834778\n",
            "Epoch 3, Step 26324: Loss = 0.20425677299499512\n",
            "Epoch 3, Step 26325: Loss = 0.25187981128692627\n",
            "Epoch 3, Step 26326: Loss = 0.2828816771507263\n",
            "Epoch 3, Step 26327: Loss = 0.6989459991455078\n",
            "Epoch 3, Step 26328: Loss = 0.455096036195755\n",
            "Epoch 3, Step 26329: Loss = 0.4782387316226959\n",
            "Epoch 3, Step 26330: Loss = 0.24075791239738464\n",
            "Epoch 3, Step 26331: Loss = 0.7154548168182373\n",
            "Epoch 3, Step 26332: Loss = 0.5993292331695557\n",
            "Epoch 3, Step 26333: Loss = 0.39354056119918823\n",
            "Epoch 3, Step 26334: Loss = 0.33114296197891235\n",
            "Epoch 3, Step 26335: Loss = 0.24292302131652832\n",
            "Epoch 3, Step 26336: Loss = 0.5435035228729248\n",
            "Epoch 3, Step 26337: Loss = 0.20727033913135529\n",
            "Epoch 3, Step 26338: Loss = 0.275789350271225\n",
            "Epoch 3, Step 26339: Loss = 0.3270820677280426\n",
            "Epoch 3, Step 26340: Loss = 0.31308653950691223\n",
            "Epoch 3, Step 26341: Loss = 0.21496523916721344\n",
            "Epoch 3, Step 26342: Loss = 0.3485175669193268\n",
            "Epoch 3, Step 26343: Loss = 0.3654690086841583\n",
            "Epoch 3, Step 26344: Loss = 0.22049114108085632\n",
            "Epoch 3, Step 26345: Loss = 0.33041486144065857\n",
            "Epoch 3, Step 26346: Loss = 0.2710842490196228\n",
            "Epoch 3, Step 26347: Loss = 0.35605549812316895\n",
            "Epoch 3, Step 26348: Loss = 0.5926777720451355\n",
            "Epoch 3, Step 26349: Loss = 0.4385167360305786\n",
            "Epoch 3, Step 26350: Loss = 0.3614705502986908\n",
            "Epoch 3, Step 26351: Loss = 0.4019966125488281\n",
            "Epoch 3, Step 26352: Loss = 0.299296498298645\n",
            "Epoch 3, Step 26353: Loss = 0.4529435336589813\n",
            "Epoch 3, Step 26354: Loss = 0.261638343334198\n",
            "Epoch 3, Step 26355: Loss = 0.4291299879550934\n",
            "Epoch 3, Step 26356: Loss = 0.6155062317848206\n",
            "Epoch 3, Step 26357: Loss = 0.5670368671417236\n",
            "Epoch 3, Step 26358: Loss = 0.3509129583835602\n",
            "Epoch 3, Step 26359: Loss = 0.32227224111557007\n",
            "Epoch 3, Step 26360: Loss = 0.4092174172401428\n",
            "Epoch 3, Step 26361: Loss = 0.4833019971847534\n",
            "Epoch 3, Step 26362: Loss = 0.27841243147850037\n",
            "Epoch 3, Step 26363: Loss = 0.48299434781074524\n",
            "Epoch 3, Step 26364: Loss = 0.2551369071006775\n",
            "Epoch 3, Step 26365: Loss = 0.30694031715393066\n",
            "Epoch 3, Step 26366: Loss = 0.5153926610946655\n",
            "Epoch 3, Step 26367: Loss = 0.22305919229984283\n",
            "Epoch 3, Step 26368: Loss = 0.26525869965553284\n",
            "Epoch 3, Step 26369: Loss = 0.3615530729293823\n",
            "Epoch 3, Step 26370: Loss = 0.2387460321187973\n",
            "Epoch 3, Step 26371: Loss = 0.39112934470176697\n",
            "Epoch 3, Step 26372: Loss = 0.2578151822090149\n",
            "Epoch 3, Step 26373: Loss = 0.4080144464969635\n",
            "Epoch 3, Step 26374: Loss = 0.23599764704704285\n",
            "Epoch 3, Step 26375: Loss = 0.16387882828712463\n",
            "Epoch 3, Step 26376: Loss = 0.5603564977645874\n",
            "Epoch 3, Step 26377: Loss = 0.5213395953178406\n",
            "Epoch 3, Step 26378: Loss = 0.2096063494682312\n",
            "Epoch 3, Step 26379: Loss = 0.19286367297172546\n",
            "Epoch 3, Step 26380: Loss = 0.2683005630970001\n",
            "Epoch 3, Step 26381: Loss = 0.42441993951797485\n",
            "Epoch 3, Step 26382: Loss = 0.49218714237213135\n",
            "Epoch 3, Step 26383: Loss = 0.14247632026672363\n",
            "Epoch 3, Step 26384: Loss = 0.23225174844264984\n",
            "Epoch 3, Step 26385: Loss = 0.44622984528541565\n",
            "Epoch 3, Step 26386: Loss = 0.2808290421962738\n",
            "Epoch 3, Step 26387: Loss = 0.16363635659217834\n",
            "Epoch 3, Step 26388: Loss = 0.5649451613426208\n",
            "Epoch 3, Step 26389: Loss = 0.17621156573295593\n",
            "Epoch 3, Step 26390: Loss = 0.425454318523407\n",
            "Epoch 3, Step 26391: Loss = 0.21543577313423157\n",
            "Epoch 3, Step 26392: Loss = 0.6030685901641846\n",
            "Epoch 3, Step 26393: Loss = 0.32365232706069946\n",
            "Epoch 3, Step 26394: Loss = 0.20768149197101593\n",
            "Epoch 3, Step 26395: Loss = 0.31913241744041443\n",
            "Epoch 3, Step 26396: Loss = 0.21865257620811462\n",
            "Epoch 3, Step 26397: Loss = 0.3359663486480713\n",
            "Epoch 3, Step 26398: Loss = 0.2542077898979187\n",
            "Epoch 3, Step 26399: Loss = 0.2712157368659973\n",
            "Epoch 3, Step 26400: Loss = 0.21460777521133423\n",
            "Epoch 3, Step 26401: Loss = 0.35365530848503113\n",
            "Epoch 3, Step 26402: Loss = 0.2775678038597107\n",
            "Epoch 3, Step 26403: Loss = 0.3742311894893646\n",
            "Epoch 3, Step 26404: Loss = 0.3986366391181946\n",
            "Epoch 3, Step 26405: Loss = 0.24146489799022675\n",
            "Epoch 3, Step 26406: Loss = 0.4133426249027252\n",
            "Epoch 3, Step 26407: Loss = 0.39800575375556946\n",
            "Epoch 3, Step 26408: Loss = 0.4703808128833771\n",
            "Epoch 3, Step 26409: Loss = 0.3031007945537567\n",
            "Epoch 3, Step 26410: Loss = 0.6406650543212891\n",
            "Epoch 3, Step 26411: Loss = 0.36976537108421326\n",
            "Epoch 3, Step 26412: Loss = 0.19634827971458435\n",
            "Epoch 3, Step 26413: Loss = 0.3031900227069855\n",
            "Epoch 3, Step 26414: Loss = 0.3776896893978119\n",
            "Epoch 3, Step 26415: Loss = 0.5932878255844116\n",
            "Epoch 3, Step 26416: Loss = 0.25914645195007324\n",
            "Epoch 3, Step 26417: Loss = 0.32299119234085083\n",
            "Epoch 3, Step 26418: Loss = 0.3914872407913208\n",
            "Epoch 3, Step 26419: Loss = 0.32970061898231506\n",
            "Epoch 3, Step 26420: Loss = 0.25871434807777405\n",
            "Epoch 3, Step 26421: Loss = 0.5171000957489014\n",
            "Epoch 3, Step 26422: Loss = 0.39288657903671265\n",
            "Epoch 3, Step 26423: Loss = 0.3414040207862854\n",
            "Epoch 3, Step 26424: Loss = 0.41107678413391113\n",
            "Epoch 3, Step 26425: Loss = 0.39668118953704834\n",
            "Epoch 3, Step 26426: Loss = 0.14044246077537537\n",
            "Epoch 3, Step 26427: Loss = 0.2578791081905365\n",
            "Epoch 3, Step 26428: Loss = 0.4960819482803345\n",
            "Epoch 3, Step 26429: Loss = 0.38770681619644165\n",
            "Epoch 3, Step 26430: Loss = 0.6137003898620605\n",
            "Epoch 3, Step 26431: Loss = 0.30353647470474243\n",
            "Epoch 3, Step 26432: Loss = 0.3158184885978699\n",
            "Epoch 3, Step 26433: Loss = 0.4497051537036896\n",
            "Epoch 3, Step 26434: Loss = 0.5448086857795715\n",
            "Epoch 3, Step 26435: Loss = 0.33958446979522705\n",
            "Epoch 3, Step 26436: Loss = 0.32040920853614807\n",
            "Epoch 3, Step 26437: Loss = 0.3582139015197754\n",
            "Epoch 3, Step 26438: Loss = 0.24315422773361206\n",
            "Epoch 3, Step 26439: Loss = 0.2848166823387146\n",
            "Epoch 3, Step 26440: Loss = 0.2018468827009201\n",
            "Epoch 3, Step 26441: Loss = 0.48452410101890564\n",
            "Epoch 3, Step 26442: Loss = 0.18404291570186615\n",
            "Epoch 3, Step 26443: Loss = 0.4184706211090088\n",
            "Epoch 3, Step 26444: Loss = 0.3880101442337036\n",
            "Epoch 3, Step 26445: Loss = 0.5259489417076111\n",
            "Epoch 3, Step 26446: Loss = 0.2585970163345337\n",
            "Epoch 3, Step 26447: Loss = 0.2308529168367386\n",
            "Epoch 3, Step 26448: Loss = 0.3160507380962372\n",
            "Epoch 3, Step 26449: Loss = 0.2664138674736023\n",
            "Epoch 3, Step 26450: Loss = 0.26751577854156494\n",
            "Epoch 3, Step 26451: Loss = 0.2256903201341629\n",
            "Epoch 3, Step 26452: Loss = 0.351027250289917\n",
            "Epoch 3, Step 26453: Loss = 0.26162734627723694\n",
            "Epoch 3, Step 26454: Loss = 0.27601632475852966\n",
            "Epoch 3, Step 26455: Loss = 0.21847552061080933\n",
            "Epoch 3, Step 26456: Loss = 0.3746998906135559\n",
            "Epoch 3, Step 26457: Loss = 0.21566489338874817\n",
            "Epoch 3, Step 26458: Loss = 0.23721155524253845\n",
            "Epoch 3, Step 26459: Loss = 0.19259658455848694\n",
            "Epoch 3, Step 26460: Loss = 0.41127070784568787\n",
            "Epoch 3, Step 26461: Loss = 0.22910915315151215\n",
            "Epoch 3, Step 26462: Loss = 0.54877108335495\n",
            "Epoch 3, Step 26463: Loss = 0.20910407602787018\n",
            "Epoch 3, Step 26464: Loss = 0.17372949421405792\n",
            "Epoch 3, Step 26465: Loss = 0.2708410918712616\n",
            "Epoch 3, Step 26466: Loss = 0.19545061886310577\n",
            "Epoch 3, Step 26467: Loss = 0.38885384798049927\n",
            "Epoch 3, Step 26468: Loss = 0.2725712060928345\n",
            "Epoch 3, Step 26469: Loss = 0.2659887969493866\n",
            "Epoch 3, Step 26470: Loss = 0.2717060148715973\n",
            "Epoch 3, Step 26471: Loss = 0.506712794303894\n",
            "Epoch 3, Step 26472: Loss = 0.2744444012641907\n",
            "Epoch 3, Step 26473: Loss = 0.32831040024757385\n",
            "Epoch 3, Step 26474: Loss = 0.2462342530488968\n",
            "Epoch 3, Step 26475: Loss = 0.31876054406166077\n",
            "Epoch 3, Step 26476: Loss = 0.4195578098297119\n",
            "Epoch 3, Step 26477: Loss = 0.29036009311676025\n",
            "Epoch 3, Step 26478: Loss = 0.17887453734874725\n",
            "Epoch 3, Step 26479: Loss = 0.2134096324443817\n",
            "Epoch 3, Step 26480: Loss = 0.49288666248321533\n",
            "Epoch 3, Step 26481: Loss = 0.35439950227737427\n",
            "Epoch 3, Step 26482: Loss = 0.49193134903907776\n",
            "Epoch 3, Step 26483: Loss = 0.5636677742004395\n",
            "Epoch 3, Step 26484: Loss = 0.2789191007614136\n",
            "Epoch 3, Step 26485: Loss = 0.30900970101356506\n",
            "Epoch 3, Step 26486: Loss = 0.3789314925670624\n",
            "Epoch 3, Step 26487: Loss = 0.4231424927711487\n",
            "Epoch 3, Step 26488: Loss = 0.36329185962677\n",
            "Epoch 3, Step 26489: Loss = 0.34744712710380554\n",
            "Epoch 3, Step 26490: Loss = 0.33888736367225647\n",
            "Epoch 3, Step 26491: Loss = 0.35490962862968445\n",
            "Epoch 3, Step 26492: Loss = 0.21042674779891968\n",
            "Epoch 3, Step 26493: Loss = 0.34429964423179626\n",
            "Epoch 3, Step 26494: Loss = 0.26827841997146606\n",
            "Epoch 3, Step 26495: Loss = 0.2318602353334427\n",
            "Epoch 3, Step 26496: Loss = 0.20025226473808289\n",
            "Epoch 3, Step 26497: Loss = 0.36810415983200073\n",
            "Epoch 3, Step 26498: Loss = 0.334840327501297\n",
            "Epoch 3, Step 26499: Loss = 0.17111177742481232\n",
            "Epoch 3, Step 26500: Loss = 0.2710981070995331\n",
            "Epoch 3, Step 26501: Loss = 0.3143070638179779\n",
            "Epoch 3, Step 26502: Loss = 0.42058640718460083\n",
            "Epoch 3, Step 26503: Loss = 0.22165794670581818\n",
            "Epoch 3, Step 26504: Loss = 0.25461167097091675\n",
            "Epoch 3, Step 26505: Loss = 0.27179649472236633\n",
            "Epoch 3, Step 26506: Loss = 0.2792968451976776\n",
            "Epoch 3, Step 26507: Loss = 0.23220889270305634\n",
            "Epoch 3, Step 26508: Loss = 0.18316543102264404\n",
            "Epoch 3, Step 26509: Loss = 0.4659764766693115\n",
            "Epoch 3, Step 26510: Loss = 0.2661789357662201\n",
            "Epoch 3, Step 26511: Loss = 0.23089809715747833\n",
            "Epoch 3, Step 26512: Loss = 0.34605109691619873\n",
            "Epoch 3, Step 26513: Loss = 0.3966383635997772\n",
            "Epoch 3, Step 26514: Loss = 0.27203524112701416\n",
            "Epoch 3, Step 26515: Loss = 0.3861141800880432\n",
            "Epoch 3, Step 26516: Loss = 0.2955018877983093\n",
            "Epoch 3, Step 26517: Loss = 0.3025859296321869\n",
            "Epoch 3, Step 26518: Loss = 0.32459649443626404\n",
            "Epoch 3, Step 26519: Loss = 0.2774736285209656\n",
            "Epoch 3, Step 26520: Loss = 0.25094348192214966\n",
            "Epoch 3, Step 26521: Loss = 0.520822286605835\n",
            "Epoch 3, Step 26522: Loss = 0.34942033886909485\n",
            "Epoch 3, Step 26523: Loss = 0.20437520742416382\n",
            "Epoch 3, Step 26524: Loss = 0.3449711501598358\n",
            "Epoch 3, Step 26525: Loss = 0.29831477999687195\n",
            "Epoch 3, Step 26526: Loss = 0.2765011191368103\n",
            "Epoch 3, Step 26527: Loss = 0.4891853928565979\n",
            "Epoch 3, Step 26528: Loss = 0.3725607097148895\n",
            "Epoch 3, Step 26529: Loss = 0.37997251749038696\n",
            "Epoch 3, Step 26530: Loss = 0.6735693216323853\n",
            "Epoch 3, Step 26531: Loss = 0.32692649960517883\n",
            "Epoch 3, Step 26532: Loss = 0.38066723942756653\n",
            "Epoch 3, Step 26533: Loss = 0.2712272107601166\n",
            "Epoch 3, Step 26534: Loss = 0.46295443177223206\n",
            "Epoch 3, Step 26535: Loss = 0.3749421536922455\n",
            "Epoch 3, Step 26536: Loss = 0.3299911916255951\n",
            "Epoch 3, Step 26537: Loss = 0.28503578901290894\n",
            "Epoch 3, Step 26538: Loss = 0.26197880506515503\n",
            "Epoch 3, Step 26539: Loss = 0.17740964889526367\n",
            "Epoch 3, Step 26540: Loss = 0.332319051027298\n",
            "Epoch 3, Step 26541: Loss = 0.20252710580825806\n",
            "Epoch 3, Step 26542: Loss = 0.27917128801345825\n",
            "Epoch 3, Step 26543: Loss = 0.3262767791748047\n",
            "Epoch 3, Step 26544: Loss = 0.2170625478029251\n",
            "Epoch 3, Step 26545: Loss = 0.24746061861515045\n",
            "Epoch 3, Step 26546: Loss = 0.3682558536529541\n",
            "Epoch 3, Step 26547: Loss = 0.6387526988983154\n",
            "Epoch 3, Step 26548: Loss = 0.36366280913352966\n",
            "Epoch 3, Step 26549: Loss = 0.39709368348121643\n",
            "Epoch 3, Step 26550: Loss = 0.32330742478370667\n",
            "Epoch 3, Step 26551: Loss = 0.3055277168750763\n",
            "Epoch 3, Step 26552: Loss = 0.2550719976425171\n",
            "Epoch 3, Step 26553: Loss = 0.4114896357059479\n",
            "Epoch 3, Step 26554: Loss = 0.22787676751613617\n",
            "Epoch 3, Step 26555: Loss = 0.2004689872264862\n",
            "Epoch 3, Step 26556: Loss = 0.2575252950191498\n",
            "Epoch 3, Step 26557: Loss = 0.30342721939086914\n",
            "Epoch 3, Step 26558: Loss = 0.24190311133861542\n",
            "Epoch 3, Step 26559: Loss = 0.27502456307411194\n",
            "Epoch 3, Step 26560: Loss = 0.2540413439273834\n",
            "Epoch 3, Step 26561: Loss = 0.2569018006324768\n",
            "Epoch 3, Step 26562: Loss = 0.22204965353012085\n",
            "Epoch 3, Step 26563: Loss = 0.43073976039886475\n",
            "Epoch 3, Step 26564: Loss = 0.161637082695961\n",
            "Epoch 3, Step 26565: Loss = 0.28948840498924255\n",
            "Epoch 3, Step 26566: Loss = 0.3639180362224579\n",
            "Epoch 3, Step 26567: Loss = 0.5346594452857971\n",
            "Epoch 3, Step 26568: Loss = 0.4017588496208191\n",
            "Epoch 3, Step 26569: Loss = 0.4130156636238098\n",
            "Epoch 3, Step 26570: Loss = 0.15650208294391632\n",
            "Epoch 3, Step 26571: Loss = 0.43001291155815125\n",
            "Epoch 3, Step 26572: Loss = 0.39110153913497925\n",
            "Epoch 3, Step 26573: Loss = 0.582420825958252\n",
            "Epoch 3, Step 26574: Loss = 0.4920472800731659\n",
            "Epoch 3, Step 26575: Loss = 0.4097931683063507\n",
            "Epoch 3, Step 26576: Loss = 0.33723095059394836\n",
            "Epoch 3, Step 26577: Loss = 0.4005255103111267\n",
            "Epoch 3, Step 26578: Loss = 0.4488934278488159\n",
            "Epoch 3, Step 26579: Loss = 0.3626938462257385\n",
            "Epoch 3, Step 26580: Loss = 0.39943307638168335\n",
            "Epoch 3, Step 26581: Loss = 0.14285752177238464\n",
            "Epoch 3, Step 26582: Loss = 0.3508501350879669\n",
            "Epoch 3, Step 26583: Loss = 0.3594358265399933\n",
            "Epoch 3, Step 26584: Loss = 0.5080024600028992\n",
            "Epoch 3, Step 26585: Loss = 0.2104799896478653\n",
            "Epoch 3, Step 26586: Loss = 0.27645638585090637\n",
            "Epoch 3, Step 26587: Loss = 0.38931867480278015\n",
            "Epoch 3, Step 26588: Loss = 0.40069594979286194\n",
            "Epoch 3, Step 26589: Loss = 0.24493975937366486\n",
            "Epoch 3, Step 26590: Loss = 0.35544371604919434\n",
            "Epoch 3, Step 26591: Loss = 0.2962416708469391\n",
            "Epoch 3, Step 26592: Loss = 0.5872460603713989\n",
            "Epoch 3, Step 26593: Loss = 0.4939103424549103\n",
            "Epoch 3, Step 26594: Loss = 0.18643255531787872\n",
            "Epoch 3, Step 26595: Loss = 0.28592416644096375\n",
            "Epoch 3, Step 26596: Loss = 0.34643107652664185\n",
            "Epoch 3, Step 26597: Loss = 0.2654815912246704\n",
            "Epoch 3, Step 26598: Loss = 0.45616447925567627\n",
            "Epoch 3, Step 26599: Loss = 0.38654473423957825\n",
            "Epoch 3, Step 26600: Loss = 0.2556424140930176\n",
            "Epoch 3, Step 26601: Loss = 0.30890193581581116\n",
            "Epoch 3, Step 26602: Loss = 0.1908489167690277\n",
            "Epoch 3, Step 26603: Loss = 0.24288064241409302\n",
            "Epoch 3, Step 26604: Loss = 0.5898998379707336\n",
            "Epoch 3, Step 26605: Loss = 0.32056525349617004\n",
            "Epoch 3, Step 26606: Loss = 0.35004255175590515\n",
            "Epoch 3, Step 26607: Loss = 0.26059606671333313\n",
            "Epoch 3, Step 26608: Loss = 0.31440025568008423\n",
            "Epoch 3, Step 26609: Loss = 0.32078346610069275\n",
            "Epoch 3, Step 26610: Loss = 0.3016032874584198\n",
            "Epoch 3, Step 26611: Loss = 0.30588415265083313\n",
            "Epoch 3, Step 26612: Loss = 0.39659684896469116\n",
            "Epoch 3, Step 26613: Loss = 0.2891249656677246\n",
            "Epoch 3, Step 26614: Loss = 0.20566599071025848\n",
            "Epoch 3, Step 26615: Loss = 0.2170846164226532\n",
            "Epoch 3, Step 26616: Loss = 0.18785566091537476\n",
            "Epoch 3, Step 26617: Loss = 0.5808778405189514\n",
            "Epoch 3, Step 26618: Loss = 0.29500964283943176\n",
            "Epoch 3, Step 26619: Loss = 0.21122537553310394\n",
            "Epoch 3, Step 26620: Loss = 0.41238638758659363\n",
            "Epoch 3, Step 26621: Loss = 0.22640345990657806\n",
            "Epoch 3, Step 26622: Loss = 0.2838621437549591\n",
            "Epoch 3, Step 26623: Loss = 0.29338639974594116\n",
            "Epoch 3, Step 26624: Loss = 0.3017396628856659\n",
            "Epoch 3, Step 26625: Loss = 0.6777048707008362\n",
            "Epoch 3, Step 26626: Loss = 0.3224009871482849\n",
            "Epoch 3, Step 26627: Loss = 0.4439713954925537\n",
            "Epoch 3, Step 26628: Loss = 0.19841577112674713\n",
            "Epoch 3, Step 26629: Loss = 0.3317440152168274\n",
            "Epoch 3, Step 26630: Loss = 0.3895433843135834\n",
            "Epoch 3, Step 26631: Loss = 0.2633405327796936\n",
            "Epoch 3, Step 26632: Loss = 0.2943904995918274\n",
            "Epoch 3, Step 26633: Loss = 0.2772718071937561\n",
            "Epoch 3, Step 26634: Loss = 0.2775258719921112\n",
            "Epoch 3, Step 26635: Loss = 0.23896925151348114\n",
            "Epoch 3, Step 26636: Loss = 0.6301664113998413\n",
            "Epoch 3, Step 26637: Loss = 0.6184027194976807\n",
            "Epoch 3, Step 26638: Loss = 0.6121987104415894\n",
            "Epoch 3, Step 26639: Loss = 0.37207362055778503\n",
            "Epoch 3, Step 26640: Loss = 0.23461318016052246\n",
            "Epoch 3, Step 26641: Loss = 0.2995624840259552\n",
            "Epoch 3, Step 26642: Loss = 0.21528077125549316\n",
            "Epoch 3, Step 26643: Loss = 0.33994248509407043\n",
            "Epoch 3, Step 26644: Loss = 0.31058818101882935\n",
            "Epoch 3, Step 26645: Loss = 0.3067987561225891\n",
            "Epoch 3, Step 26646: Loss = 0.7102229595184326\n",
            "Epoch 3, Step 26647: Loss = 0.29717397689819336\n",
            "Epoch 3, Step 26648: Loss = 0.31314781308174133\n",
            "Epoch 3, Step 26649: Loss = 0.2337249219417572\n",
            "Epoch 3, Step 26650: Loss = 0.4671472907066345\n",
            "Epoch 3, Step 26651: Loss = 0.2654472291469574\n",
            "Epoch 3, Step 26652: Loss = 0.27578118443489075\n",
            "Epoch 3, Step 26653: Loss = 0.41045767068862915\n",
            "Epoch 3, Step 26654: Loss = 0.4234168231487274\n",
            "Epoch 3, Step 26655: Loss = 0.36950868368148804\n",
            "Epoch 3, Step 26656: Loss = 0.33045855164527893\n",
            "Epoch 3, Step 26657: Loss = 0.1756516695022583\n",
            "Epoch 3, Step 26658: Loss = 0.5960499048233032\n",
            "Epoch 3, Step 26659: Loss = 0.3228929936885834\n",
            "Epoch 3, Step 26660: Loss = 0.46163609623908997\n",
            "Epoch 3, Step 26661: Loss = 0.23851941525936127\n",
            "Epoch 3, Step 26662: Loss = 0.32809436321258545\n",
            "Epoch 3, Step 26663: Loss = 0.43333443999290466\n",
            "Epoch 3, Step 26664: Loss = 0.5548773407936096\n",
            "Epoch 3, Step 26665: Loss = 0.5882399678230286\n",
            "Epoch 3, Step 26666: Loss = 0.35390904545783997\n",
            "Epoch 3, Step 26667: Loss = 0.2767501175403595\n",
            "Epoch 3, Step 26668: Loss = 0.22020728886127472\n",
            "Epoch 3, Step 26669: Loss = 0.5363634824752808\n",
            "Epoch 3, Step 26670: Loss = 0.47836193442344666\n",
            "Epoch 3, Step 26671: Loss = 0.6822800636291504\n",
            "Epoch 3, Step 26672: Loss = 0.16557295620441437\n",
            "Epoch 3, Step 26673: Loss = 0.4257515072822571\n",
            "Epoch 3, Step 26674: Loss = 0.16596849262714386\n",
            "Epoch 3, Step 26675: Loss = 0.3046395182609558\n",
            "Epoch 3, Step 26676: Loss = 0.18264609575271606\n",
            "Epoch 3, Step 26677: Loss = 0.3077818751335144\n",
            "Epoch 3, Step 26678: Loss = 0.24802972376346588\n",
            "Epoch 3, Step 26679: Loss = 0.2242579162120819\n",
            "Epoch 3, Step 26680: Loss = 0.6137679219245911\n",
            "Epoch 3, Step 26681: Loss = 0.24236635863780975\n",
            "Epoch 3, Step 26682: Loss = 0.186264306306839\n",
            "Epoch 3, Step 26683: Loss = 0.0940806046128273\n",
            "Epoch 3, Step 26684: Loss = 0.2345026582479477\n",
            "Epoch 3, Step 26685: Loss = 0.22652430832386017\n",
            "Epoch 3, Step 26686: Loss = 0.20114269852638245\n",
            "Epoch 3, Step 26687: Loss = 0.46616125106811523\n",
            "Epoch 3, Step 26688: Loss = 0.4359387457370758\n",
            "Epoch 3, Step 26689: Loss = 0.23714138567447662\n",
            "Epoch 3, Step 26690: Loss = 0.30798760056495667\n",
            "Epoch 3, Step 26691: Loss = 0.30329710245132446\n",
            "Epoch 3, Step 26692: Loss = 0.2193531095981598\n",
            "Epoch 3, Step 26693: Loss = 0.42591872811317444\n",
            "Epoch 3, Step 26694: Loss = 0.22103039920330048\n",
            "Epoch 3, Step 26695: Loss = 0.21348115801811218\n",
            "Epoch 3, Step 26696: Loss = 0.3326253294944763\n",
            "Epoch 3, Step 26697: Loss = 0.2346203774213791\n",
            "Epoch 3, Step 26698: Loss = 0.24268320202827454\n",
            "Epoch 3, Step 26699: Loss = 0.3144817054271698\n",
            "Epoch 3, Step 26700: Loss = 0.19077932834625244\n",
            "Epoch 3, Step 26701: Loss = 0.5287948250770569\n",
            "Epoch 3, Step 26702: Loss = 0.6044344305992126\n",
            "Epoch 3, Step 26703: Loss = 0.30049777030944824\n",
            "Epoch 3, Step 26704: Loss = 0.15903088450431824\n",
            "Epoch 3, Step 26705: Loss = 0.2649940848350525\n",
            "Epoch 3, Step 26706: Loss = 0.4523317813873291\n",
            "Epoch 3, Step 26707: Loss = 0.5777931213378906\n",
            "Epoch 3, Step 26708: Loss = 0.3699941039085388\n",
            "Epoch 3, Step 26709: Loss = 0.6166974902153015\n",
            "Epoch 3, Step 26710: Loss = 0.41457369923591614\n",
            "Epoch 3, Step 26711: Loss = 0.30315250158309937\n",
            "Epoch 3, Step 26712: Loss = 0.3874497711658478\n",
            "Epoch 3, Step 26713: Loss = 0.4172886610031128\n",
            "Epoch 3, Step 26714: Loss = 0.2549482583999634\n",
            "Epoch 3, Step 26715: Loss = 0.45924776792526245\n",
            "Epoch 3, Step 26716: Loss = 0.4254799485206604\n",
            "Epoch 3, Step 26717: Loss = 0.2721848785877228\n",
            "Epoch 3, Step 26718: Loss = 0.45772597193717957\n",
            "Epoch 3, Step 26719: Loss = 0.5223073363304138\n",
            "Epoch 3, Step 26720: Loss = 0.18046626448631287\n",
            "Epoch 3, Step 26721: Loss = 0.32417601346969604\n",
            "Epoch 3, Step 26722: Loss = 0.24239741265773773\n",
            "Epoch 3, Step 26723: Loss = 0.20864900946617126\n",
            "Epoch 3, Step 26724: Loss = 0.2571318745613098\n",
            "Epoch 3, Step 26725: Loss = 0.3119889795780182\n",
            "Epoch 3, Step 26726: Loss = 0.3072810769081116\n",
            "Epoch 3, Step 26727: Loss = 0.3000965118408203\n",
            "Epoch 3, Step 26728: Loss = 0.35037875175476074\n",
            "Epoch 3, Step 26729: Loss = 0.22688941657543182\n",
            "Epoch 3, Step 26730: Loss = 0.4113236665725708\n",
            "Epoch 3, Step 26731: Loss = 0.3958812952041626\n",
            "Epoch 3, Step 26732: Loss = 0.34447571635246277\n",
            "Epoch 3, Step 26733: Loss = 0.281767338514328\n",
            "Epoch 3, Step 26734: Loss = 0.2840486466884613\n",
            "Epoch 3, Step 26735: Loss = 0.23320309817790985\n",
            "Epoch 3, Step 26736: Loss = 0.38897189497947693\n",
            "Epoch 3, Step 26737: Loss = 0.3425472378730774\n",
            "Epoch 3, Step 26738: Loss = 0.272727906703949\n",
            "Epoch 3, Step 26739: Loss = 0.2245834320783615\n",
            "Epoch 3, Step 26740: Loss = 0.31325557827949524\n",
            "Epoch 3, Step 26741: Loss = 0.41047972440719604\n",
            "Epoch 3, Step 26742: Loss = 0.26095646619796753\n",
            "Epoch 3, Step 26743: Loss = 0.5392953157424927\n",
            "Epoch 3, Step 26744: Loss = 0.4461490511894226\n",
            "Epoch 3, Step 26745: Loss = 0.4022602438926697\n",
            "Epoch 3, Step 26746: Loss = 0.5002546310424805\n",
            "Epoch 3, Step 26747: Loss = 0.6904555559158325\n",
            "Epoch 3, Step 26748: Loss = 0.19413705170154572\n",
            "Epoch 3, Step 26749: Loss = 0.38451942801475525\n",
            "Epoch 3, Step 26750: Loss = 0.25947219133377075\n",
            "Epoch 3, Step 26751: Loss = 0.21759244799613953\n",
            "Epoch 3, Step 26752: Loss = 0.5522453188896179\n",
            "Epoch 3, Step 26753: Loss = 0.3358955979347229\n",
            "Epoch 3, Step 26754: Loss = 0.2768956124782562\n",
            "Epoch 3, Step 26755: Loss = 0.5120225548744202\n",
            "Epoch 3, Step 26756: Loss = 0.2818133533000946\n",
            "Epoch 3, Step 26757: Loss = 0.3345012664794922\n",
            "Epoch 3, Step 26758: Loss = 0.3921402394771576\n",
            "Epoch 3, Step 26759: Loss = 0.37073883414268494\n",
            "Epoch 3, Step 26760: Loss = 0.37176620960235596\n",
            "Epoch 3, Step 26761: Loss = 0.34736397862434387\n",
            "Epoch 3, Step 26762: Loss = 0.5700123310089111\n",
            "Epoch 3, Step 26763: Loss = 0.2632036507129669\n",
            "Epoch 3, Step 26764: Loss = 0.24365928769111633\n",
            "Epoch 3, Step 26765: Loss = 0.24291902780532837\n",
            "Epoch 3, Step 26766: Loss = 0.32432591915130615\n",
            "Epoch 3, Step 26767: Loss = 0.45357704162597656\n",
            "Epoch 3, Step 26768: Loss = 0.36788198351860046\n",
            "Epoch 3, Step 26769: Loss = 0.2221420407295227\n",
            "Epoch 3, Step 26770: Loss = 0.2538831830024719\n",
            "Epoch 3, Step 26771: Loss = 0.3244560956954956\n",
            "Epoch 3, Step 26772: Loss = 0.16977345943450928\n",
            "Epoch 3, Step 26773: Loss = 0.3738595247268677\n",
            "Epoch 3, Step 26774: Loss = 0.20329587161540985\n",
            "Epoch 3, Step 26775: Loss = 0.2872723639011383\n",
            "Epoch 3, Step 26776: Loss = 0.33265718817710876\n",
            "Epoch 3, Step 26777: Loss = 0.18155008554458618\n",
            "Epoch 3, Step 26778: Loss = 0.361419141292572\n",
            "Epoch 3, Step 26779: Loss = 0.5312682390213013\n",
            "Epoch 3, Step 26780: Loss = 0.5510055422782898\n",
            "Epoch 3, Step 26781: Loss = 0.21078166365623474\n",
            "Epoch 3, Step 26782: Loss = 0.237357035279274\n",
            "Epoch 3, Step 26783: Loss = 0.4533054530620575\n",
            "Epoch 3, Step 26784: Loss = 0.28634974360466003\n",
            "Epoch 3, Step 26785: Loss = 0.5438439249992371\n",
            "Epoch 3, Step 26786: Loss = 0.46931368112564087\n",
            "Epoch 3, Step 26787: Loss = 0.2598330080509186\n",
            "Epoch 3, Step 26788: Loss = 0.49884724617004395\n",
            "Epoch 3, Step 26789: Loss = 0.2632686197757721\n",
            "Epoch 3, Step 26790: Loss = 0.19050556421279907\n",
            "Epoch 3, Step 26791: Loss = 0.259967565536499\n",
            "Epoch 3, Step 26792: Loss = 0.14956845343112946\n",
            "Epoch 3, Step 26793: Loss = 0.29692620038986206\n",
            "Epoch 3, Step 26794: Loss = 0.6262266635894775\n",
            "Epoch 3, Step 26795: Loss = 0.365785151720047\n",
            "Epoch 3, Step 26796: Loss = 0.42567864060401917\n",
            "Epoch 3, Step 26797: Loss = 0.22313813865184784\n",
            "Epoch 3, Step 26798: Loss = 0.2599617838859558\n",
            "Epoch 3, Step 26799: Loss = 0.20778873562812805\n",
            "Epoch 3, Step 26800: Loss = 0.17797647416591644\n",
            "Epoch 3, Step 26801: Loss = 0.4563450217247009\n",
            "Epoch 3, Step 26802: Loss = 0.3350672423839569\n",
            "Epoch 3, Step 26803: Loss = 0.3396494388580322\n",
            "Epoch 3, Step 26804: Loss = 0.16737642884254456\n",
            "Epoch 3, Step 26805: Loss = 0.3240587115287781\n",
            "Epoch 3, Step 26806: Loss = 0.26984742283821106\n",
            "Epoch 3, Step 26807: Loss = 0.30276358127593994\n",
            "Epoch 3, Step 26808: Loss = 0.503479540348053\n",
            "Epoch 3, Step 26809: Loss = 0.5782235264778137\n",
            "Epoch 3, Step 26810: Loss = 0.5305598974227905\n",
            "Epoch 3, Step 26811: Loss = 0.3422420024871826\n",
            "Epoch 3, Step 26812: Loss = 0.292076975107193\n",
            "Epoch 3, Step 26813: Loss = 0.4643831253051758\n",
            "Epoch 3, Step 26814: Loss = 0.5172381401062012\n",
            "Epoch 3, Step 26815: Loss = 0.49071091413497925\n",
            "Epoch 3, Step 26816: Loss = 0.4303952157497406\n",
            "Epoch 3, Step 26817: Loss = 0.20781095325946808\n",
            "Epoch 3, Step 26818: Loss = 0.5393804311752319\n",
            "Epoch 3, Step 26819: Loss = 0.6038743853569031\n",
            "Epoch 3, Step 26820: Loss = 0.3004871904850006\n",
            "Epoch 3, Step 26821: Loss = 0.34644490480422974\n",
            "Epoch 3, Step 26822: Loss = 0.3608267605304718\n",
            "Epoch 3, Step 26823: Loss = 0.6228142380714417\n",
            "Epoch 3, Step 26824: Loss = 0.4725728929042816\n",
            "Epoch 3, Step 26825: Loss = 0.45227742195129395\n",
            "Epoch 3, Step 26826: Loss = 0.4244820177555084\n",
            "Epoch 3, Step 26827: Loss = 0.30256301164627075\n",
            "Epoch 3, Step 26828: Loss = 0.26872512698173523\n",
            "Epoch 3, Step 26829: Loss = 0.3358587324619293\n",
            "Epoch 3, Step 26830: Loss = 0.5080668330192566\n",
            "Epoch 3, Step 26831: Loss = 0.46883687376976013\n",
            "Epoch 3, Step 26832: Loss = 0.33366066217422485\n",
            "Epoch 3, Step 26833: Loss = 0.39941561222076416\n",
            "Epoch 3, Step 26834: Loss = 0.28522011637687683\n",
            "Epoch 3, Step 26835: Loss = 0.42502596974372864\n",
            "Epoch 3, Step 26836: Loss = 0.2652819752693176\n",
            "Epoch 3, Step 26837: Loss = 0.2647918164730072\n",
            "Epoch 3, Step 26838: Loss = 0.2571392059326172\n",
            "Epoch 3, Step 26839: Loss = 0.23960064351558685\n",
            "Epoch 3, Step 26840: Loss = 0.3051748275756836\n",
            "Epoch 3, Step 26841: Loss = 0.2295561283826828\n",
            "Epoch 3, Step 26842: Loss = 0.4478507339954376\n",
            "Epoch 3, Step 26843: Loss = 0.20913216471672058\n",
            "Epoch 3, Step 26844: Loss = 0.3171231150627136\n",
            "Epoch 3, Step 26845: Loss = 0.3416999578475952\n",
            "Epoch 3, Step 26846: Loss = 0.28283655643463135\n",
            "Epoch 3, Step 26847: Loss = 0.498138964176178\n",
            "Epoch 3, Step 26848: Loss = 0.20840483903884888\n",
            "Epoch 3, Step 26849: Loss = 0.4372621774673462\n",
            "Epoch 3, Step 26850: Loss = 0.2764470875263214\n",
            "Epoch 3, Step 26851: Loss = 0.3645194172859192\n",
            "Epoch 3, Step 26852: Loss = 0.2404259592294693\n",
            "Epoch 3, Step 26853: Loss = 0.18173432350158691\n",
            "Epoch 3, Step 26854: Loss = 0.29946842789649963\n",
            "Epoch 3, Step 26855: Loss = 0.44763755798339844\n",
            "Epoch 3, Step 26856: Loss = 0.23434750735759735\n",
            "Epoch 3, Step 26857: Loss = 0.34872084856033325\n",
            "Epoch 3, Step 26858: Loss = 0.24862121045589447\n",
            "Epoch 3, Step 26859: Loss = 0.2667430341243744\n",
            "Epoch 3, Step 26860: Loss = 0.17460696399211884\n",
            "Epoch 3, Step 26861: Loss = 0.2802892029285431\n",
            "Epoch 3, Step 26862: Loss = 0.23399777710437775\n",
            "Epoch 3, Step 26863: Loss = 0.5879568457603455\n",
            "Epoch 3, Step 26864: Loss = 0.28230759501457214\n",
            "Epoch 3, Step 26865: Loss = 0.18272805213928223\n",
            "Epoch 3, Step 26866: Loss = 0.23429372906684875\n",
            "Epoch 3, Step 26867: Loss = 0.30855947732925415\n",
            "Epoch 3, Step 26868: Loss = 0.3734096884727478\n",
            "Epoch 3, Step 26869: Loss = 0.40188586711883545\n",
            "Epoch 3, Step 26870: Loss = 0.19280360639095306\n",
            "Epoch 3, Step 26871: Loss = 0.22840110957622528\n",
            "Epoch 3, Step 26872: Loss = 0.6231169104576111\n",
            "Epoch 3, Step 26873: Loss = 0.41931337118148804\n",
            "Epoch 3, Step 26874: Loss = 0.49158382415771484\n",
            "Epoch 3, Step 26875: Loss = 0.3923706114292145\n",
            "Epoch 3, Step 26876: Loss = 0.2611575424671173\n",
            "Epoch 3, Step 26877: Loss = 0.22407755255699158\n",
            "Epoch 3, Step 26878: Loss = 0.3197176158428192\n",
            "Epoch 3, Step 26879: Loss = 0.23678049445152283\n",
            "Epoch 3, Step 26880: Loss = 0.1791718304157257\n",
            "Epoch 3, Step 26881: Loss = 0.2507910132408142\n",
            "Epoch 3, Step 26882: Loss = 0.325952410697937\n",
            "Epoch 3, Step 26883: Loss = 0.22929967939853668\n",
            "Epoch 3, Step 26884: Loss = 0.30404555797576904\n",
            "Epoch 3, Step 26885: Loss = 0.29904916882514954\n",
            "Epoch 3, Step 26886: Loss = 0.2959425151348114\n",
            "Epoch 3, Step 26887: Loss = 0.3879817724227905\n",
            "Epoch 3, Step 26888: Loss = 0.30502966046333313\n",
            "Epoch 3, Step 26889: Loss = 0.19157135486602783\n",
            "Epoch 3, Step 26890: Loss = 0.3590594530105591\n",
            "Epoch 3, Step 26891: Loss = 0.28102219104766846\n",
            "Epoch 3, Step 26892: Loss = 0.4070667624473572\n",
            "Epoch 3, Step 26893: Loss = 0.20818345248699188\n",
            "Epoch 3, Step 26894: Loss = 0.3298661708831787\n",
            "Epoch 3, Step 26895: Loss = 0.32525256276130676\n",
            "Epoch 3, Step 26896: Loss = 0.39029282331466675\n",
            "Epoch 3, Step 26897: Loss = 0.7503461241722107\n",
            "Epoch 3, Step 26898: Loss = 0.6186708807945251\n",
            "Epoch 3, Step 26899: Loss = 0.26060017943382263\n",
            "Epoch 3, Step 26900: Loss = 0.18519382178783417\n",
            "Epoch 3, Step 26901: Loss = 0.205572247505188\n",
            "Epoch 3, Step 26902: Loss = 0.4632907211780548\n",
            "Epoch 3, Step 26903: Loss = 0.22021253407001495\n",
            "Epoch 3, Step 26904: Loss = 0.561101496219635\n",
            "Epoch 3, Step 26905: Loss = 0.2907067537307739\n",
            "Epoch 3, Step 26906: Loss = 0.231861874461174\n",
            "Epoch 3, Step 26907: Loss = 0.17275963723659515\n",
            "Epoch 3, Step 26908: Loss = 0.5584784150123596\n",
            "Epoch 3, Step 26909: Loss = 0.36703217029571533\n",
            "Epoch 3, Step 26910: Loss = 0.23642569780349731\n",
            "Epoch 3, Step 26911: Loss = 0.4628463089466095\n",
            "Epoch 3, Step 26912: Loss = 0.18511241674423218\n",
            "Epoch 3, Step 26913: Loss = 0.4243501126766205\n",
            "Epoch 3, Step 26914: Loss = 0.4222671389579773\n",
            "Epoch 3, Step 26915: Loss = 0.42399370670318604\n",
            "Epoch 3, Step 26916: Loss = 0.3192768394947052\n",
            "Epoch 3, Step 26917: Loss = 0.33678555488586426\n",
            "Epoch 3, Step 26918: Loss = 0.21749675273895264\n",
            "Epoch 3, Step 26919: Loss = 0.23281952738761902\n",
            "Epoch 3, Step 26920: Loss = 0.3882984519004822\n",
            "Epoch 3, Step 26921: Loss = 0.42229437828063965\n",
            "Epoch 3, Step 26922: Loss = 0.19721700251102448\n",
            "Epoch 3, Step 26923: Loss = 0.3843439817428589\n",
            "Epoch 3, Step 26924: Loss = 0.3830763101577759\n",
            "Epoch 3, Step 26925: Loss = 0.34892538189888\n",
            "Epoch 3, Step 26926: Loss = 0.41360148787498474\n",
            "Epoch 3, Step 26927: Loss = 0.2793799042701721\n",
            "Epoch 3, Step 26928: Loss = 0.29179030656814575\n",
            "Epoch 3, Step 26929: Loss = 0.2451334297657013\n",
            "Epoch 3, Step 26930: Loss = 0.3297306001186371\n",
            "Epoch 3, Step 26931: Loss = 0.31879717111587524\n",
            "Epoch 3, Step 26932: Loss = 0.22386997938156128\n",
            "Epoch 3, Step 26933: Loss = 0.38237133622169495\n",
            "Epoch 3, Step 26934: Loss = 0.2657281160354614\n",
            "Epoch 3, Step 26935: Loss = 0.36792418360710144\n",
            "Epoch 3, Step 26936: Loss = 0.41784000396728516\n",
            "Epoch 3, Step 26937: Loss = 0.2622341513633728\n",
            "Epoch 3, Step 26938: Loss = 0.4024946093559265\n",
            "Epoch 3, Step 26939: Loss = 0.22651635110378265\n",
            "Epoch 3, Step 26940: Loss = 0.3456745743751526\n",
            "Epoch 3, Step 26941: Loss = 0.3041124641895294\n",
            "Epoch 3, Step 26942: Loss = 0.33898085355758667\n",
            "Epoch 3, Step 26943: Loss = 0.4126175343990326\n",
            "Epoch 3, Step 26944: Loss = 0.3916180431842804\n",
            "Epoch 3, Step 26945: Loss = 0.1878003627061844\n",
            "Epoch 3, Step 26946: Loss = 0.25641632080078125\n",
            "Epoch 3, Step 26947: Loss = 0.29510629177093506\n",
            "Epoch 3, Step 26948: Loss = 0.25457295775413513\n",
            "Epoch 3, Step 26949: Loss = 0.26381710171699524\n",
            "Epoch 3, Step 26950: Loss = 0.19228047132492065\n",
            "Epoch 3, Step 26951: Loss = 0.3741394281387329\n",
            "Epoch 3, Step 26952: Loss = 0.23191623389720917\n",
            "Epoch 3, Step 26953: Loss = 0.328991562128067\n",
            "Epoch 3, Step 26954: Loss = 0.22378256916999817\n",
            "Epoch 3, Step 26955: Loss = 0.4860990345478058\n",
            "Epoch 3, Step 26956: Loss = 0.18232861161231995\n",
            "Epoch 3, Step 26957: Loss = 0.25163277983665466\n",
            "Epoch 3, Step 26958: Loss = 0.36596062779426575\n",
            "Epoch 3, Step 26959: Loss = 0.26261579990386963\n",
            "Epoch 3, Step 26960: Loss = 0.3555932939052582\n",
            "Epoch 3, Step 26961: Loss = 0.48663660883903503\n",
            "Epoch 3, Step 26962: Loss = 0.672826886177063\n",
            "Epoch 3, Step 26963: Loss = 0.3290584981441498\n",
            "Epoch 3, Step 26964: Loss = 0.37047746777534485\n",
            "Epoch 3, Step 26965: Loss = 0.2867332696914673\n",
            "Epoch 3, Step 26966: Loss = 0.2369953840970993\n",
            "Epoch 3, Step 26967: Loss = 0.3875919282436371\n",
            "Epoch 3, Step 26968: Loss = 0.32308444380760193\n",
            "Epoch 3, Step 26969: Loss = 0.21468432247638702\n",
            "Epoch 3, Step 26970: Loss = 0.2139558643102646\n",
            "Epoch 3, Step 26971: Loss = 0.2551756203174591\n",
            "Epoch 3, Step 26972: Loss = 0.4348866939544678\n",
            "Epoch 3, Step 26973: Loss = 0.48942074179649353\n",
            "Epoch 3, Step 26974: Loss = 0.3043079674243927\n",
            "Epoch 3, Step 26975: Loss = 0.49709469079971313\n",
            "Epoch 3, Step 26976: Loss = 0.2665616571903229\n",
            "Epoch 3, Step 26977: Loss = 0.21859903633594513\n",
            "Epoch 3, Step 26978: Loss = 0.23846907913684845\n",
            "Epoch 3, Step 26979: Loss = 0.13830767571926117\n",
            "Epoch 3, Step 26980: Loss = 0.36580029129981995\n",
            "Epoch 3, Step 26981: Loss = 0.3147158920764923\n",
            "Epoch 3, Step 26982: Loss = 0.2688826322555542\n",
            "Epoch 3, Step 26983: Loss = 0.5181418061256409\n",
            "Epoch 3, Step 26984: Loss = 0.25722038745880127\n",
            "Epoch 3, Step 26985: Loss = 0.31260523200035095\n",
            "Epoch 3, Step 26986: Loss = 0.2876843214035034\n",
            "Epoch 3, Step 26987: Loss = 0.42259567975997925\n",
            "Epoch 3, Step 26988: Loss = 0.42422229051589966\n",
            "Epoch 3, Step 26989: Loss = 0.15838010609149933\n",
            "Epoch 3, Step 26990: Loss = 0.3125256597995758\n",
            "Epoch 3, Step 26991: Loss = 0.38769522309303284\n",
            "Epoch 3, Step 26992: Loss = 0.3003464341163635\n",
            "Epoch 3, Step 26993: Loss = 0.24371355772018433\n",
            "Epoch 3, Step 26994: Loss = 0.35885491967201233\n",
            "Epoch 3, Step 26995: Loss = 0.30311623215675354\n",
            "Epoch 3, Step 26996: Loss = 0.27133750915527344\n",
            "Epoch 3, Step 26997: Loss = 0.2915979325771332\n",
            "Epoch 3, Step 26998: Loss = 0.4135490357875824\n",
            "Epoch 3, Step 26999: Loss = 0.5120459794998169\n",
            "Epoch 3, Step 27000: Loss = 0.5090774893760681\n",
            "Epoch 3, Step 27001: Loss = 0.3238646686077118\n",
            "Epoch 3, Step 27002: Loss = 0.5065355896949768\n",
            "Epoch 3, Step 27003: Loss = 0.7023596167564392\n",
            "Epoch 3, Step 27004: Loss = 0.20683413743972778\n",
            "Epoch 3, Step 27005: Loss = 0.412337988615036\n",
            "Epoch 3, Step 27006: Loss = 0.24695107340812683\n",
            "Epoch 3, Step 27007: Loss = 0.24937303364276886\n",
            "Epoch 3, Step 27008: Loss = 0.24977177381515503\n",
            "Epoch 3, Step 27009: Loss = 0.4623216390609741\n",
            "Epoch 3, Step 27010: Loss = 0.3684086799621582\n",
            "Epoch 3, Step 27011: Loss = 0.23287509381771088\n",
            "Epoch 3, Step 27012: Loss = 0.23148079216480255\n",
            "Epoch 3, Step 27013: Loss = 0.29394394159317017\n",
            "Epoch 3, Step 27014: Loss = 0.20799170434474945\n",
            "Epoch 3, Step 27015: Loss = 0.28915584087371826\n",
            "Epoch 3, Step 27016: Loss = 0.21587461233139038\n",
            "Epoch 3, Step 27017: Loss = 0.4943597614765167\n",
            "Epoch 3, Step 27018: Loss = 0.17285314202308655\n",
            "Epoch 3, Step 27019: Loss = 0.28174397349357605\n",
            "Epoch 3, Step 27020: Loss = 0.22741390764713287\n",
            "Epoch 3, Step 27021: Loss = 0.5364266633987427\n",
            "Epoch 3, Step 27022: Loss = 0.3671322762966156\n",
            "Epoch 3, Step 27023: Loss = 0.41807547211647034\n",
            "Epoch 3, Step 27024: Loss = 0.264481782913208\n",
            "Epoch 3, Step 27025: Loss = 0.44997429847717285\n",
            "Epoch 3, Step 27026: Loss = 0.32670438289642334\n",
            "Epoch 3, Step 27027: Loss = 0.26538166403770447\n",
            "Epoch 3, Step 27028: Loss = 0.42462193965911865\n",
            "Epoch 3, Step 27029: Loss = 0.3843558728694916\n",
            "Epoch 3, Step 27030: Loss = 0.21940526366233826\n",
            "Epoch 3, Step 27031: Loss = 0.3553634583950043\n",
            "Epoch 3, Step 27032: Loss = 0.43212831020355225\n",
            "Epoch 3, Step 27033: Loss = 0.3709624111652374\n",
            "Epoch 3, Step 27034: Loss = 0.32373255491256714\n",
            "Epoch 3, Step 27035: Loss = 0.48954206705093384\n",
            "Epoch 3, Step 27036: Loss = 0.4837982654571533\n",
            "Epoch 3, Step 27037: Loss = 0.3211299180984497\n",
            "Epoch 3, Step 27038: Loss = 0.3734382390975952\n",
            "Epoch 3, Step 27039: Loss = 0.260846883058548\n",
            "Epoch 3, Step 27040: Loss = 0.35152819752693176\n",
            "Epoch 3, Step 27041: Loss = 0.28517118096351624\n",
            "Epoch 3, Step 27042: Loss = 0.17297479510307312\n",
            "Epoch 3, Step 27043: Loss = 0.30165016651153564\n",
            "Epoch 3, Step 27044: Loss = 0.5201207995414734\n",
            "Epoch 3, Step 27045: Loss = 0.3255370855331421\n",
            "Epoch 3, Step 27046: Loss = 0.38331061601638794\n",
            "Epoch 3, Step 27047: Loss = 0.3685133755207062\n",
            "Epoch 3, Step 27048: Loss = 0.31082338094711304\n",
            "Epoch 3, Step 27049: Loss = 0.22350551187992096\n",
            "Epoch 3, Step 27050: Loss = 0.2921862006187439\n",
            "Epoch 3, Step 27051: Loss = 0.35298994183540344\n",
            "Epoch 3, Step 27052: Loss = 0.21936210989952087\n",
            "Epoch 3, Step 27053: Loss = 0.2759060263633728\n",
            "Epoch 3, Step 27054: Loss = 0.2641508877277374\n",
            "Epoch 3, Step 27055: Loss = 0.3697822093963623\n",
            "Epoch 3, Step 27056: Loss = 0.24140994250774384\n",
            "Epoch 3, Step 27057: Loss = 0.4204327166080475\n",
            "Epoch 3, Step 27058: Loss = 0.307735413312912\n",
            "Epoch 3, Step 27059: Loss = 0.32115113735198975\n",
            "Epoch 3, Step 27060: Loss = 0.26315194368362427\n",
            "Epoch 3, Step 27061: Loss = 0.5034863948822021\n",
            "Epoch 3, Step 27062: Loss = 0.6030430793762207\n",
            "Epoch 3, Step 27063: Loss = 0.2861965596675873\n",
            "Epoch 3, Step 27064: Loss = 0.25080201029777527\n",
            "Epoch 3, Step 27065: Loss = 0.36431002616882324\n",
            "Epoch 3, Step 27066: Loss = 0.30169177055358887\n",
            "Epoch 3, Step 27067: Loss = 0.35314467549324036\n",
            "Epoch 3, Step 27068: Loss = 0.49709343910217285\n",
            "Epoch 3, Step 27069: Loss = 0.1960666924715042\n",
            "Epoch 3, Step 27070: Loss = 0.20122545957565308\n",
            "Epoch 3, Step 27071: Loss = 0.32913124561309814\n",
            "Epoch 3, Step 27072: Loss = 0.36884573101997375\n",
            "Epoch 3, Step 27073: Loss = 0.47693145275115967\n",
            "Epoch 3, Step 27074: Loss = 0.44754263758659363\n",
            "Epoch 3, Step 27075: Loss = 0.3293217122554779\n",
            "Epoch 3, Step 27076: Loss = 0.2294929474592209\n",
            "Epoch 3, Step 27077: Loss = 0.15234000980854034\n",
            "Epoch 3, Step 27078: Loss = 0.17079904675483704\n",
            "Epoch 3, Step 27079: Loss = 0.09855126589536667\n",
            "Epoch 3, Step 27080: Loss = 0.3584950864315033\n",
            "Epoch 3, Step 27081: Loss = 0.4035382568836212\n",
            "Epoch 3, Step 27082: Loss = 0.39805838465690613\n",
            "Epoch 3, Step 27083: Loss = 0.2519195079803467\n",
            "Epoch 3, Step 27084: Loss = 0.29227495193481445\n",
            "Epoch 3, Step 27085: Loss = 0.28836923837661743\n",
            "Epoch 3, Step 27086: Loss = 0.5162103176116943\n",
            "Epoch 3, Step 27087: Loss = 0.41227927803993225\n",
            "Epoch 3, Step 27088: Loss = 0.2838146686553955\n",
            "Epoch 3, Step 27089: Loss = 0.43244579434394836\n",
            "Epoch 3, Step 27090: Loss = 0.6487558484077454\n",
            "Epoch 3, Step 27091: Loss = 0.19101376831531525\n",
            "Epoch 3, Step 27092: Loss = 0.31139302253723145\n",
            "Epoch 3, Step 27093: Loss = 0.5677149295806885\n",
            "Epoch 3, Step 27094: Loss = 0.2991819679737091\n",
            "Epoch 3, Step 27095: Loss = 0.6907486319541931\n",
            "Epoch 3, Step 27096: Loss = 0.11512484401464462\n",
            "Epoch 3, Step 27097: Loss = 0.24853837490081787\n",
            "Epoch 3, Step 27098: Loss = 0.24521972239017487\n",
            "Epoch 3, Step 27099: Loss = 0.4113864600658417\n",
            "Epoch 3, Step 27100: Loss = 0.4396537244319916\n",
            "Epoch 3, Step 27101: Loss = 0.20032261312007904\n",
            "Epoch 3, Step 27102: Loss = 0.25901657342910767\n",
            "Epoch 3, Step 27103: Loss = 0.32810482382774353\n",
            "Epoch 3, Step 27104: Loss = 0.1786588579416275\n",
            "Epoch 3, Step 27105: Loss = 0.4007730484008789\n",
            "Epoch 3, Step 27106: Loss = 0.3044307827949524\n",
            "Epoch 3, Step 27107: Loss = 0.24974048137664795\n",
            "Epoch 3, Step 27108: Loss = 0.34082797169685364\n",
            "Epoch 3, Step 27109: Loss = 0.2210848033428192\n",
            "Epoch 3, Step 27110: Loss = 0.3503398299217224\n",
            "Epoch 3, Step 27111: Loss = 0.47366583347320557\n",
            "Epoch 3, Step 27112: Loss = 0.3814903199672699\n",
            "Epoch 3, Step 27113: Loss = 0.1200682669878006\n",
            "Epoch 3, Step 27114: Loss = 0.3800920248031616\n",
            "Epoch 3, Step 27115: Loss = 0.2519747018814087\n",
            "Epoch 3, Step 27116: Loss = 0.37813282012939453\n",
            "Epoch 3, Step 27117: Loss = 0.22035939991474152\n",
            "Epoch 3, Step 27118: Loss = 0.34004300832748413\n",
            "Epoch 3, Step 27119: Loss = 0.1527901440858841\n",
            "Epoch 3, Step 27120: Loss = 0.23746761679649353\n",
            "Epoch 3, Step 27121: Loss = 0.4213813841342926\n",
            "Epoch 3, Step 27122: Loss = 0.3634762465953827\n",
            "Epoch 3, Step 27123: Loss = 0.25146424770355225\n",
            "Epoch 3, Step 27124: Loss = 0.4869880974292755\n",
            "Epoch 3, Step 27125: Loss = 0.3999476730823517\n",
            "Epoch 3, Step 27126: Loss = 0.4353988468647003\n",
            "Epoch 3, Step 27127: Loss = 0.3622262477874756\n",
            "Epoch 3, Step 27128: Loss = 0.39629998803138733\n",
            "Epoch 3, Step 27129: Loss = 0.5540615320205688\n",
            "Epoch 3, Step 27130: Loss = 0.16632042825222015\n",
            "Epoch 3, Step 27131: Loss = 0.22634288668632507\n",
            "Epoch 3, Step 27132: Loss = 0.3063940405845642\n",
            "Epoch 3, Step 27133: Loss = 0.293926864862442\n",
            "Epoch 3, Step 27134: Loss = 0.19727903604507446\n",
            "Epoch 3, Step 27135: Loss = 0.35678958892822266\n",
            "Epoch 3, Step 27136: Loss = 0.1995455026626587\n",
            "Epoch 3, Step 27137: Loss = 0.36229532957077026\n",
            "Epoch 3, Step 27138: Loss = 0.3007412254810333\n",
            "Epoch 3, Step 27139: Loss = 0.21581362187862396\n",
            "Epoch 3, Step 27140: Loss = 0.5088449120521545\n",
            "Epoch 3, Step 27141: Loss = 0.35614392161369324\n",
            "Epoch 3, Step 27142: Loss = 0.321732759475708\n",
            "Epoch 3, Step 27143: Loss = 0.38305601477622986\n",
            "Epoch 3, Step 27144: Loss = 0.5008133053779602\n",
            "Epoch 3, Step 27145: Loss = 0.4413999021053314\n",
            "Epoch 3, Step 27146: Loss = 0.31327736377716064\n",
            "Epoch 3, Step 27147: Loss = 0.305158793926239\n",
            "Epoch 3, Step 27148: Loss = 0.30803805589675903\n",
            "Epoch 3, Step 27149: Loss = 0.3810270130634308\n",
            "Epoch 3, Step 27150: Loss = 0.1539490967988968\n",
            "Epoch 3, Step 27151: Loss = 0.3323274850845337\n",
            "Epoch 3, Step 27152: Loss = 0.29494836926460266\n",
            "Epoch 3, Step 27153: Loss = 0.3204135000705719\n",
            "Epoch 3, Step 27154: Loss = 0.7439850568771362\n",
            "Epoch 3, Step 27155: Loss = 0.4222041666507721\n",
            "Epoch 3, Step 27156: Loss = 0.47407156229019165\n",
            "Epoch 3, Step 27157: Loss = 0.28134310245513916\n",
            "Epoch 3, Step 27158: Loss = 0.40593960881233215\n",
            "Epoch 3, Step 27159: Loss = 0.2552163302898407\n",
            "Epoch 3, Step 27160: Loss = 0.1634058803319931\n",
            "Epoch 3, Step 27161: Loss = 0.44012123346328735\n",
            "Epoch 3, Step 27162: Loss = 0.3258815407752991\n",
            "Epoch 3, Step 27163: Loss = 0.2792496085166931\n",
            "Epoch 3, Step 27164: Loss = 0.28475069999694824\n",
            "Epoch 3, Step 27165: Loss = 0.2046755999326706\n",
            "Epoch 3, Step 27166: Loss = 0.2586809992790222\n",
            "Epoch 3, Step 27167: Loss = 0.375507652759552\n",
            "Epoch 3, Step 27168: Loss = 0.25725409388542175\n",
            "Epoch 3, Step 27169: Loss = 0.28828564286231995\n",
            "Epoch 3, Step 27170: Loss = 0.4067991375923157\n",
            "Epoch 3, Step 27171: Loss = 0.3820253014564514\n",
            "Epoch 3, Step 27172: Loss = 0.34053102135658264\n",
            "Epoch 3, Step 27173: Loss = 0.4051501750946045\n",
            "Epoch 3, Step 27174: Loss = 0.21095465123653412\n",
            "Epoch 3, Step 27175: Loss = 0.23796230554580688\n",
            "Epoch 3, Step 27176: Loss = 0.2952672243118286\n",
            "Epoch 3, Step 27177: Loss = 0.5872225761413574\n",
            "Epoch 3, Step 27178: Loss = 0.30952906608581543\n",
            "Epoch 3, Step 27179: Loss = 0.5214278101921082\n",
            "Epoch 3, Step 27180: Loss = 0.5737519264221191\n",
            "Epoch 3, Step 27181: Loss = 0.204740971326828\n",
            "Epoch 3, Step 27182: Loss = 0.5694748163223267\n",
            "Epoch 3, Step 27183: Loss = 0.3331061601638794\n",
            "Epoch 3, Step 27184: Loss = 0.3006535470485687\n",
            "Epoch 3, Step 27185: Loss = 0.4297982156276703\n",
            "Epoch 3, Step 27186: Loss = 0.4111904501914978\n",
            "Epoch 3, Step 27187: Loss = 0.2489037811756134\n",
            "Epoch 3, Step 27188: Loss = 0.14893582463264465\n",
            "Epoch 3, Step 27189: Loss = 0.4050997197628021\n",
            "Epoch 3, Step 27190: Loss = 0.3943367302417755\n",
            "Epoch 3, Step 27191: Loss = 0.3514624536037445\n",
            "Epoch 3, Step 27192: Loss = 0.3386959433555603\n",
            "Epoch 3, Step 27193: Loss = 0.6703124642372131\n",
            "Epoch 3, Step 27194: Loss = 0.16859255731105804\n",
            "Epoch 3, Step 27195: Loss = 0.6623937487602234\n",
            "Epoch 3, Step 27196: Loss = 0.43605300784111023\n",
            "Epoch 3, Step 27197: Loss = 0.5116347074508667\n",
            "Epoch 3, Step 27198: Loss = 0.26616770029067993\n",
            "Epoch 3, Step 27199: Loss = 0.36597904562950134\n",
            "Epoch 3, Step 27200: Loss = 0.422312468290329\n",
            "Epoch 3, Step 27201: Loss = 0.6102954149246216\n",
            "Epoch 3, Step 27202: Loss = 0.37262439727783203\n",
            "Epoch 3, Step 27203: Loss = 0.3433138132095337\n",
            "Epoch 3, Step 27204: Loss = 0.24421291053295135\n",
            "Epoch 3, Step 27205: Loss = 0.2757585346698761\n",
            "Epoch 3, Step 27206: Loss = 0.549899697303772\n",
            "Epoch 3, Step 27207: Loss = 0.3621634244918823\n",
            "Epoch 3, Step 27208: Loss = 0.35547223687171936\n",
            "Epoch 3, Step 27209: Loss = 0.1999768763780594\n",
            "Epoch 3, Step 27210: Loss = 0.27404704689979553\n",
            "Epoch 3, Step 27211: Loss = 0.16096755862236023\n",
            "Epoch 3, Step 27212: Loss = 0.48708102107048035\n",
            "Epoch 3, Step 27213: Loss = 0.26558396220207214\n",
            "Epoch 3, Step 27214: Loss = 0.2849746346473694\n",
            "Epoch 3, Step 27215: Loss = 0.27350372076034546\n",
            "Epoch 3, Step 27216: Loss = 0.2787725627422333\n",
            "Epoch 3, Step 27217: Loss = 0.49420344829559326\n",
            "Epoch 3, Step 27218: Loss = 0.5137163996696472\n",
            "Epoch 3, Step 27219: Loss = 0.16759748756885529\n",
            "Epoch 3, Step 27220: Loss = 0.1656171977519989\n",
            "Epoch 3, Step 27221: Loss = 0.4471273422241211\n",
            "Epoch 3, Step 27222: Loss = 0.4698440432548523\n",
            "Epoch 3, Step 27223: Loss = 0.27187103033065796\n",
            "Epoch 3, Step 27224: Loss = 0.264200896024704\n",
            "Epoch 3, Step 27225: Loss = 0.2535277009010315\n",
            "Epoch 3, Step 27226: Loss = 0.4409570097923279\n",
            "Epoch 3, Step 27227: Loss = 0.39743372797966003\n",
            "Epoch 3, Step 27228: Loss = 0.3294556140899658\n",
            "Epoch 3, Step 27229: Loss = 0.2721126079559326\n",
            "Epoch 3, Step 27230: Loss = 0.27436381578445435\n",
            "Epoch 3, Step 27231: Loss = 0.21637916564941406\n",
            "Epoch 3, Step 27232: Loss = 0.4907534718513489\n",
            "Epoch 3, Step 27233: Loss = 0.19581817090511322\n",
            "Epoch 3, Step 27234: Loss = 0.16496145725250244\n",
            "Epoch 3, Step 27235: Loss = 0.38348209857940674\n",
            "Epoch 3, Step 27236: Loss = 0.32328465580940247\n",
            "Epoch 3, Step 27237: Loss = 0.5457108020782471\n",
            "Epoch 3, Step 27238: Loss = 0.41920122504234314\n",
            "Epoch 3, Step 27239: Loss = 0.6953865885734558\n",
            "Epoch 3, Step 27240: Loss = 0.5420169830322266\n",
            "Epoch 3, Step 27241: Loss = 0.33662593364715576\n",
            "Epoch 3, Step 27242: Loss = 0.439123272895813\n",
            "Epoch 3, Step 27243: Loss = 0.40970006585121155\n",
            "Epoch 3, Step 27244: Loss = 0.13278190791606903\n",
            "Epoch 3, Step 27245: Loss = 0.2860143184661865\n",
            "Epoch 3, Step 27246: Loss = 0.27100667357444763\n",
            "Epoch 3, Step 27247: Loss = 0.23375800251960754\n",
            "Epoch 3, Step 27248: Loss = 0.44864484667778015\n",
            "Epoch 3, Step 27249: Loss = 0.20823584496974945\n",
            "Epoch 3, Step 27250: Loss = 0.5162003040313721\n",
            "Epoch 3, Step 27251: Loss = 0.4227405786514282\n",
            "Epoch 3, Step 27252: Loss = 0.6397141814231873\n",
            "Epoch 3, Step 27253: Loss = 0.4538339376449585\n",
            "Epoch 3, Step 27254: Loss = 0.38572290539741516\n",
            "Epoch 3, Step 27255: Loss = 0.13729849457740784\n",
            "Epoch 3, Step 27256: Loss = 0.3023233711719513\n",
            "Epoch 3, Step 27257: Loss = 0.3350989520549774\n",
            "Epoch 3, Step 27258: Loss = 0.3654823899269104\n",
            "Epoch 3, Step 27259: Loss = 0.519672155380249\n",
            "Epoch 3, Step 27260: Loss = 0.15321676433086395\n",
            "Epoch 3, Step 27261: Loss = 0.20165537297725677\n",
            "Epoch 3, Step 27262: Loss = 0.2522470951080322\n",
            "Epoch 3, Step 27263: Loss = 0.35331279039382935\n",
            "Epoch 3, Step 27264: Loss = 0.20770877599716187\n",
            "Epoch 3, Step 27265: Loss = 0.15586082637310028\n",
            "Epoch 3, Step 27266: Loss = 0.430067241191864\n",
            "Epoch 3, Step 27267: Loss = 0.23790591955184937\n",
            "Epoch 3, Step 27268: Loss = 0.17106126248836517\n",
            "Epoch 3, Step 27269: Loss = 0.15320853888988495\n",
            "Epoch 3, Step 27270: Loss = 0.28829607367515564\n",
            "Epoch 3, Step 27271: Loss = 0.251469224691391\n",
            "Epoch 3, Step 27272: Loss = 0.3099079132080078\n",
            "Epoch 3, Step 27273: Loss = 0.2674407958984375\n",
            "Epoch 3, Step 27274: Loss = 0.26321128010749817\n",
            "Epoch 3, Step 27275: Loss = 0.2782663404941559\n",
            "Epoch 3, Step 27276: Loss = 0.21664966642856598\n",
            "Epoch 3, Step 27277: Loss = 0.3107163608074188\n",
            "Epoch 3, Step 27278: Loss = 0.1886196732521057\n",
            "Epoch 3, Step 27279: Loss = 0.26913556456565857\n",
            "Epoch 3, Step 27280: Loss = 0.2686566114425659\n",
            "Epoch 3, Step 27281: Loss = 0.35207149386405945\n",
            "Epoch 3, Step 27282: Loss = 0.16624686121940613\n",
            "Epoch 3, Step 27283: Loss = 0.061635538935661316\n",
            "Epoch 3, Step 27284: Loss = 0.35596829652786255\n",
            "Epoch 3, Step 27285: Loss = 0.5401018261909485\n",
            "Epoch 3, Step 27286: Loss = 0.31395578384399414\n",
            "Epoch 3, Step 27287: Loss = 0.5084282159805298\n",
            "Epoch 3, Step 27288: Loss = 0.5215939283370972\n",
            "Epoch 3, Step 27289: Loss = 0.19088630378246307\n",
            "Epoch 3, Step 27290: Loss = 0.30220529437065125\n",
            "Epoch 3, Step 27291: Loss = 0.20307961106300354\n",
            "Epoch 3, Step 27292: Loss = 0.35172098875045776\n",
            "Epoch 3, Step 27293: Loss = 0.3575849235057831\n",
            "Epoch 3, Step 27294: Loss = 0.25044211745262146\n",
            "Epoch 3, Step 27295: Loss = 0.43567588925361633\n",
            "Epoch 3, Step 27296: Loss = 0.1245691329240799\n",
            "Epoch 3, Step 27297: Loss = 0.31747788190841675\n",
            "Epoch 3, Step 27298: Loss = 0.16889642179012299\n",
            "Epoch 3, Step 27299: Loss = 0.2542836368083954\n",
            "Epoch 3, Step 27300: Loss = 0.2025727480649948\n",
            "Epoch 3, Step 27301: Loss = 0.22935569286346436\n",
            "Epoch 3, Step 27302: Loss = 0.20194905996322632\n",
            "Epoch 3, Step 27303: Loss = 0.35585129261016846\n",
            "Epoch 3, Step 27304: Loss = 0.27379292249679565\n",
            "Epoch 3, Step 27305: Loss = 0.22453846037387848\n",
            "Epoch 3, Step 27306: Loss = 0.4332587718963623\n",
            "Epoch 3, Step 27307: Loss = 0.6146736145019531\n",
            "Epoch 3, Step 27308: Loss = 0.25927674770355225\n",
            "Epoch 3, Step 27309: Loss = 0.29937517642974854\n",
            "Epoch 3, Step 27310: Loss = 0.16565366089344025\n",
            "Epoch 3, Step 27311: Loss = 0.4648265838623047\n",
            "Epoch 3, Step 27312: Loss = 0.31924504041671753\n",
            "Epoch 3, Step 27313: Loss = 0.34920772910118103\n",
            "Epoch 3, Step 27314: Loss = 0.43394654989242554\n",
            "Epoch 3, Step 27315: Loss = 0.2814452052116394\n",
            "Epoch 3, Step 27316: Loss = 0.46282511949539185\n",
            "Epoch 3, Step 27317: Loss = 0.40055203437805176\n",
            "Epoch 3, Step 27318: Loss = 0.47900640964508057\n",
            "Epoch 3, Step 27319: Loss = 0.30780649185180664\n",
            "Epoch 3, Step 27320: Loss = 0.29129067063331604\n",
            "Epoch 3, Step 27321: Loss = 0.5002216696739197\n",
            "Epoch 3, Step 27322: Loss = 0.2339535653591156\n",
            "Epoch 3, Step 27323: Loss = 0.3935701549053192\n",
            "Epoch 3, Step 27324: Loss = 0.295167475938797\n",
            "Epoch 3, Step 27325: Loss = 0.2899279296398163\n",
            "Epoch 3, Step 27326: Loss = 0.277856707572937\n",
            "Epoch 3, Step 27327: Loss = 0.30376356840133667\n",
            "Epoch 3, Step 27328: Loss = 0.3937702476978302\n",
            "Epoch 3, Step 27329: Loss = 0.1820944994688034\n",
            "Epoch 3, Step 27330: Loss = 0.2630988657474518\n",
            "Epoch 3, Step 27331: Loss = 0.3752481937408447\n",
            "Epoch 3, Step 27332: Loss = 0.2521135210990906\n",
            "Epoch 3, Step 27333: Loss = 0.20204399526119232\n",
            "Epoch 3, Step 27334: Loss = 0.2330082356929779\n",
            "Epoch 3, Step 27335: Loss = 0.20193538069725037\n",
            "Epoch 3, Step 27336: Loss = 0.1678871363401413\n",
            "Epoch 3, Step 27337: Loss = 0.20245613157749176\n",
            "Epoch 3, Step 27338: Loss = 0.5991156101226807\n",
            "Epoch 3, Step 27339: Loss = 0.31706538796424866\n",
            "Epoch 3, Step 27340: Loss = 0.48152247071266174\n",
            "Epoch 3, Step 27341: Loss = 0.1978418380022049\n",
            "Epoch 3, Step 27342: Loss = 0.26314839720726013\n",
            "Epoch 3, Step 27343: Loss = 0.3737349510192871\n",
            "Epoch 3, Step 27344: Loss = 0.3646186292171478\n",
            "Epoch 3, Step 27345: Loss = 0.21752004325389862\n",
            "Epoch 3, Step 27346: Loss = 0.23428203165531158\n",
            "Epoch 3, Step 27347: Loss = 0.348482221364975\n",
            "Epoch 3, Step 27348: Loss = 0.32887786626815796\n",
            "Epoch 3, Step 27349: Loss = 0.14168736338615417\n",
            "Epoch 3, Step 27350: Loss = 0.13042940199375153\n",
            "Epoch 3, Step 27351: Loss = 0.2204534411430359\n",
            "Epoch 3, Step 27352: Loss = 0.2424720972776413\n",
            "Epoch 3, Step 27353: Loss = 0.28662800788879395\n",
            "Epoch 3, Step 27354: Loss = 0.21713703870773315\n",
            "Epoch 3, Step 27355: Loss = 0.46127450466156006\n",
            "Epoch 3, Step 27356: Loss = 0.3082771897315979\n",
            "Epoch 3, Step 27357: Loss = 0.47476276755332947\n",
            "Epoch 3, Step 27358: Loss = 0.24444079399108887\n",
            "Epoch 3, Step 27359: Loss = 0.33738499879837036\n",
            "Epoch 3, Step 27360: Loss = 0.43130213022232056\n",
            "Epoch 3, Step 27361: Loss = 0.5165755748748779\n",
            "Epoch 3, Step 27362: Loss = 0.19236883521080017\n",
            "Epoch 3, Step 27363: Loss = 0.35357487201690674\n",
            "Epoch 3, Step 27364: Loss = 0.3622961938381195\n",
            "Epoch 3, Step 27365: Loss = 0.2569202780723572\n",
            "Epoch 3, Step 27366: Loss = 0.5305567979812622\n",
            "Epoch 3, Step 27367: Loss = 0.35367467999458313\n",
            "Epoch 3, Step 27368: Loss = 0.20680251717567444\n",
            "Epoch 3, Step 27369: Loss = 0.593267560005188\n",
            "Epoch 3, Step 27370: Loss = 0.22847053408622742\n",
            "Epoch 3, Step 27371: Loss = 0.31247031688690186\n",
            "Epoch 3, Step 27372: Loss = 0.5101507902145386\n",
            "Epoch 3, Step 27373: Loss = 0.39903947710990906\n",
            "Epoch 3, Step 27374: Loss = 0.3105902075767517\n",
            "Epoch 3, Step 27375: Loss = 0.3543618619441986\n",
            "Epoch 3, Step 27376: Loss = 0.473101943731308\n",
            "Epoch 3, Step 27377: Loss = 0.2280004322528839\n",
            "Epoch 3, Step 27378: Loss = 0.48550865054130554\n",
            "Epoch 3, Step 27379: Loss = 0.35989028215408325\n",
            "Epoch 3, Step 27380: Loss = 0.5069962739944458\n",
            "Epoch 3, Step 27381: Loss = 0.3468095362186432\n",
            "Epoch 3, Step 27382: Loss = 0.41020864248275757\n",
            "Epoch 3, Step 27383: Loss = 0.2976320683956146\n",
            "Epoch 3, Step 27384: Loss = 0.31116265058517456\n",
            "Epoch 3, Step 27385: Loss = 0.3050912916660309\n",
            "Epoch 3, Step 27386: Loss = 0.24629664421081543\n",
            "Epoch 3, Step 27387: Loss = 0.1987183541059494\n",
            "Epoch 3, Step 27388: Loss = 0.38565775752067566\n",
            "Epoch 3, Step 27389: Loss = 0.247003436088562\n",
            "Epoch 3, Step 27390: Loss = 0.3565521836280823\n",
            "Epoch 3, Step 27391: Loss = 0.5490777492523193\n",
            "Epoch 3, Step 27392: Loss = 0.3644125461578369\n",
            "Epoch 3, Step 27393: Loss = 0.4846498370170593\n",
            "Epoch 3, Step 27394: Loss = 0.32654303312301636\n",
            "Epoch 3, Step 27395: Loss = 0.290645956993103\n",
            "Epoch 3, Step 27396: Loss = 0.30554792284965515\n",
            "Epoch 3, Step 27397: Loss = 0.2664751708507538\n",
            "Epoch 3, Step 27398: Loss = 0.31617844104766846\n",
            "Epoch 3, Step 27399: Loss = 0.2383490800857544\n",
            "Epoch 3, Step 27400: Loss = 0.16985836625099182\n",
            "Epoch 3, Step 27401: Loss = 0.34681445360183716\n",
            "Epoch 3, Step 27402: Loss = 0.18102163076400757\n",
            "Epoch 3, Step 27403: Loss = 0.1398804485797882\n",
            "Epoch 3, Step 27404: Loss = 0.45631879568099976\n",
            "Epoch 3, Step 27405: Loss = 0.29463618993759155\n",
            "Epoch 3, Step 27406: Loss = 0.2342454195022583\n",
            "Epoch 3, Step 27407: Loss = 0.24947653710842133\n",
            "Epoch 3, Step 27408: Loss = 0.48244768381118774\n",
            "Epoch 3, Step 27409: Loss = 0.39076152443885803\n",
            "Epoch 3, Step 27410: Loss = 0.3971273601055145\n",
            "Epoch 3, Step 27411: Loss = 0.18163220584392548\n",
            "Epoch 3, Step 27412: Loss = 0.2444063276052475\n",
            "Epoch 3, Step 27413: Loss = 0.3568897247314453\n",
            "Epoch 3, Step 27414: Loss = 0.43783244490623474\n",
            "Epoch 3, Step 27415: Loss = 0.20317642390727997\n",
            "Epoch 3, Step 27416: Loss = 0.2532316744327545\n",
            "Epoch 3, Step 27417: Loss = 0.332429438829422\n",
            "Epoch 3, Step 27418: Loss = 0.08951030671596527\n",
            "Epoch 3, Step 27419: Loss = 0.3063597083091736\n",
            "Epoch 3, Step 27420: Loss = 0.2842874228954315\n",
            "Epoch 3, Step 27421: Loss = 0.17537707090377808\n",
            "Epoch 3, Step 27422: Loss = 0.293464332818985\n",
            "Epoch 3, Step 27423: Loss = 0.33340656757354736\n",
            "Epoch 3, Step 27424: Loss = 0.3931157886981964\n",
            "Epoch 3, Step 27425: Loss = 0.2627871632575989\n",
            "Epoch 3, Step 27426: Loss = 0.2911089360713959\n",
            "Epoch 3, Step 27427: Loss = 0.4829227924346924\n",
            "Epoch 3, Step 27428: Loss = 0.25959888100624084\n",
            "Epoch 3, Step 27429: Loss = 0.2633211314678192\n",
            "Epoch 3, Step 27430: Loss = 0.35506245493888855\n",
            "Epoch 3, Step 27431: Loss = 0.8522525429725647\n",
            "Epoch 3, Step 27432: Loss = 0.5648784041404724\n",
            "Epoch 3, Step 27433: Loss = 0.29906636476516724\n",
            "Epoch 3, Step 27434: Loss = 0.22561995685100555\n",
            "Epoch 3, Step 27435: Loss = 0.24598096311092377\n",
            "Epoch 3, Step 27436: Loss = 0.3295740783214569\n",
            "Epoch 3, Step 27437: Loss = 0.28472718596458435\n",
            "Epoch 3, Step 27438: Loss = 0.41960588097572327\n",
            "Epoch 3, Step 27439: Loss = 0.2390289157629013\n",
            "Epoch 3, Step 27440: Loss = 0.25566306710243225\n",
            "Epoch 3, Step 27441: Loss = 0.17009609937667847\n",
            "Epoch 3, Step 27442: Loss = 0.4781651198863983\n",
            "Epoch 3, Step 27443: Loss = 0.22406131029129028\n",
            "Epoch 3, Step 27444: Loss = 0.23637929558753967\n",
            "Epoch 3, Step 27445: Loss = 0.5695244669914246\n",
            "Epoch 3, Step 27446: Loss = 0.3364749550819397\n",
            "Epoch 3, Step 27447: Loss = 0.2998485863208771\n",
            "Epoch 3, Step 27448: Loss = 0.13088716566562653\n",
            "Epoch 3, Step 27449: Loss = 0.449677973985672\n",
            "Epoch 3, Step 27450: Loss = 0.5505693554878235\n",
            "Epoch 3, Step 27451: Loss = 0.22913295030593872\n",
            "Epoch 3, Step 27452: Loss = 0.23927715420722961\n",
            "Epoch 3, Step 27453: Loss = 0.34510067105293274\n",
            "Epoch 3, Step 27454: Loss = 0.26171961426734924\n",
            "Epoch 3, Step 27455: Loss = 0.36700865626335144\n",
            "Epoch 3, Step 27456: Loss = 0.191055029630661\n",
            "Epoch 3, Step 27457: Loss = 0.12668964266777039\n",
            "Epoch 3, Step 27458: Loss = 0.22162555158138275\n",
            "Epoch 3, Step 27459: Loss = 0.45830264687538147\n",
            "Epoch 3, Step 27460: Loss = 0.3124978840351105\n",
            "Epoch 3, Step 27461: Loss = 0.29163044691085815\n",
            "Epoch 3, Step 27462: Loss = 0.3434862792491913\n",
            "Epoch 3, Step 27463: Loss = 0.20565545558929443\n",
            "Epoch 3, Step 27464: Loss = 0.5293571352958679\n",
            "Epoch 3, Step 27465: Loss = 0.30542194843292236\n",
            "Epoch 3, Step 27466: Loss = 0.09889449179172516\n",
            "Epoch 3, Step 27467: Loss = 0.17345912754535675\n",
            "Epoch 3, Step 27468: Loss = 0.3586137890815735\n",
            "Epoch 3, Step 27469: Loss = 0.200373113155365\n",
            "Epoch 3, Step 27470: Loss = 0.6172493100166321\n",
            "Epoch 3, Step 27471: Loss = 0.28172561526298523\n",
            "Epoch 3, Step 27472: Loss = 0.3128705322742462\n",
            "Epoch 3, Step 27473: Loss = 0.3889910578727722\n",
            "Epoch 3, Step 27474: Loss = 0.3185886740684509\n",
            "Epoch 3, Step 27475: Loss = 0.22327463328838348\n",
            "Epoch 3, Step 27476: Loss = 0.3341537415981293\n",
            "Epoch 3, Step 27477: Loss = 0.3760243058204651\n",
            "Epoch 3, Step 27478: Loss = 0.520719587802887\n",
            "Epoch 3, Step 27479: Loss = 0.4213802218437195\n",
            "Epoch 3, Step 27480: Loss = 0.49126192927360535\n",
            "Epoch 3, Step 27481: Loss = 0.3544408977031708\n",
            "Epoch 3, Step 27482: Loss = 0.16694113612174988\n",
            "Epoch 3, Step 27483: Loss = 0.1533053070306778\n",
            "Epoch 3, Step 27484: Loss = 0.4746301770210266\n",
            "Epoch 3, Step 27485: Loss = 0.3485793173313141\n",
            "Epoch 3, Step 27486: Loss = 0.4433923661708832\n",
            "Epoch 3, Step 27487: Loss = 0.3628281354904175\n",
            "Epoch 3, Step 27488: Loss = 0.3449445366859436\n",
            "Epoch 3, Step 27489: Loss = 0.27414754033088684\n",
            "Epoch 3, Step 27490: Loss = 0.3912277817726135\n",
            "Epoch 3, Step 27491: Loss = 0.3455779552459717\n",
            "Epoch 3, Step 27492: Loss = 0.3704603910446167\n",
            "Epoch 3, Step 27493: Loss = 0.19617268443107605\n",
            "Epoch 3, Step 27494: Loss = 0.20668521523475647\n",
            "Epoch 3, Step 27495: Loss = 0.5281585454940796\n",
            "Epoch 3, Step 27496: Loss = 0.1951252818107605\n",
            "Epoch 3, Step 27497: Loss = 0.5959300398826599\n",
            "Epoch 3, Step 27498: Loss = 0.32997429370880127\n",
            "Epoch 3, Step 27499: Loss = 0.6360135674476624\n",
            "Epoch 3, Step 27500: Loss = 0.3650858402252197\n",
            "Epoch 3, Step 27501: Loss = 0.3412395417690277\n",
            "Epoch 3, Step 27502: Loss = 0.38089635968208313\n",
            "Epoch 3, Step 27503: Loss = 0.34647998213768005\n",
            "Epoch 3, Step 27504: Loss = 0.33016568422317505\n",
            "Epoch 3, Step 27505: Loss = 0.27076244354248047\n",
            "Epoch 3, Step 27506: Loss = 0.37296319007873535\n",
            "Epoch 3, Step 27507: Loss = 0.6659708023071289\n",
            "Epoch 3, Step 27508: Loss = 0.46455901861190796\n",
            "Epoch 3, Step 27509: Loss = 0.25414568185806274\n",
            "Epoch 3, Step 27510: Loss = 0.32797619700431824\n",
            "Epoch 3, Step 27511: Loss = 0.2130870223045349\n",
            "Epoch 3, Step 27512: Loss = 0.20222975313663483\n",
            "Epoch 3, Step 27513: Loss = 0.4160727262496948\n",
            "Epoch 3, Step 27514: Loss = 0.3121570944786072\n",
            "Epoch 3, Step 27515: Loss = 0.2528591752052307\n",
            "Epoch 3, Step 27516: Loss = 0.3396279811859131\n",
            "Epoch 3, Step 27517: Loss = 0.3436143696308136\n",
            "Epoch 3, Step 27518: Loss = 0.6593722701072693\n",
            "Epoch 3, Step 27519: Loss = 0.2454645037651062\n",
            "Epoch 3, Step 27520: Loss = 0.6303613185882568\n",
            "Epoch 3, Step 27521: Loss = 0.27554428577423096\n",
            "Epoch 3, Step 27522: Loss = 0.30158787965774536\n",
            "Epoch 3, Step 27523: Loss = 0.34832412004470825\n",
            "Epoch 3, Step 27524: Loss = 0.43848904967308044\n",
            "Epoch 3, Step 27525: Loss = 0.5625147223472595\n",
            "Epoch 3, Step 27526: Loss = 0.34633204340934753\n",
            "Epoch 3, Step 27527: Loss = 0.3199699819087982\n",
            "Epoch 3, Step 27528: Loss = 0.43311455845832825\n",
            "Epoch 3, Step 27529: Loss = 0.30571886897087097\n",
            "Epoch 3, Step 27530: Loss = 0.23282122611999512\n",
            "Epoch 3, Step 27531: Loss = 0.25624072551727295\n",
            "Epoch 3, Step 27532: Loss = 0.33199343085289\n",
            "Epoch 3, Step 27533: Loss = 0.3543716073036194\n",
            "Epoch 3, Step 27534: Loss = 0.2692398726940155\n",
            "Epoch 3, Step 27535: Loss = 0.49671313166618347\n",
            "Epoch 3, Step 27536: Loss = 0.5380361676216125\n",
            "Epoch 3, Step 27537: Loss = 0.2453441470861435\n",
            "Epoch 3, Step 27538: Loss = 0.12844736874103546\n",
            "Epoch 3, Step 27539: Loss = 0.35117068886756897\n",
            "Epoch 3, Step 27540: Loss = 0.43190667033195496\n",
            "Epoch 3, Step 27541: Loss = 0.5553239583969116\n",
            "Epoch 3, Step 27542: Loss = 0.3474561870098114\n",
            "Epoch 3, Step 27543: Loss = 0.22038498520851135\n",
            "Epoch 3, Step 27544: Loss = 0.3075440526008606\n",
            "Epoch 3, Step 27545: Loss = 0.1978253573179245\n",
            "Epoch 3, Step 27546: Loss = 0.36408576369285583\n",
            "Epoch 3, Step 27547: Loss = 0.22312717139720917\n",
            "Epoch 3, Step 27548: Loss = 0.3544594645500183\n",
            "Epoch 3, Step 27549: Loss = 0.45112574100494385\n",
            "Epoch 3, Step 27550: Loss = 0.21465006470680237\n",
            "Epoch 3, Step 27551: Loss = 0.3867904543876648\n",
            "Epoch 3, Step 27552: Loss = 0.2681555449962616\n",
            "Epoch 3, Step 27553: Loss = 0.2505035102367401\n",
            "Epoch 3, Step 27554: Loss = 0.26167431473731995\n",
            "Epoch 3, Step 27555: Loss = 0.27585387229919434\n",
            "Epoch 3, Step 27556: Loss = 0.4143599569797516\n",
            "Epoch 3, Step 27557: Loss = 0.3914237916469574\n",
            "Epoch 3, Step 27558: Loss = 0.40026554465293884\n",
            "Epoch 3, Step 27559: Loss = 0.48231062293052673\n",
            "Epoch 3, Step 27560: Loss = 0.33015403151512146\n",
            "Epoch 3, Step 27561: Loss = 0.20649820566177368\n",
            "Epoch 3, Step 27562: Loss = 0.40220001339912415\n",
            "Epoch 3, Step 27563: Loss = 0.35891273617744446\n",
            "Epoch 3, Step 27564: Loss = 0.23643215000629425\n",
            "Epoch 3, Step 27565: Loss = 0.45324137806892395\n",
            "Epoch 3, Step 27566: Loss = 0.44373568892478943\n",
            "Epoch 3, Step 27567: Loss = 0.45279794931411743\n",
            "Epoch 3, Step 27568: Loss = 0.1792958527803421\n",
            "Epoch 3, Step 27569: Loss = 0.32840925455093384\n",
            "Epoch 3, Step 27570: Loss = 0.37389248609542847\n",
            "Epoch 3, Step 27571: Loss = 0.4616122245788574\n",
            "Epoch 3, Step 27572: Loss = 0.5211316347122192\n",
            "Epoch 3, Step 27573: Loss = 0.2412686049938202\n",
            "Epoch 3, Step 27574: Loss = 0.6392843127250671\n",
            "Epoch 3, Step 27575: Loss = 0.5601838827133179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modeli kaydet\n",
        "model_dir = \"/content/drive/My Drive/bart_model\"\n",
        "\n",
        "model.save_pretrained(model_dir)\n",
        "tokenizer.save_pretrained(model_dir)\n",
        "\n",
        "print(\"Model ve tokenizer başarıyla kaydedildi!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSXo9WSzJLj2",
        "outputId": "89dcd455-998f-45ad-cf6c-8089304e4d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ve tokenizer başarıyla kaydedildi!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "import torch\n",
        "\n",
        "# Model ve tokenizer'ı yükle\n",
        "model_dir = \"/content/drive/My Drive/bart_model\"\n",
        "model = BartForConditionalGeneration.from_pretrained(model_dir)\n",
        "tokenizer = BartTokenizer.from_pretrained(model_dir)\n",
        "\n",
        "# Cihaz seçimi\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Test için fonksiyon\n",
        "def test_model(sentence):\n",
        "    # Girdi cümlesini tokenleştir\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", max_length=128, truncation=True).to(device)\n",
        "\n",
        "    # Model çıktısı\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(inputs[\"input_ids\"], max_length=128, num_beams=4, early_stopping=True)\n",
        "\n",
        "    # Düzeltilmiş cümleyi çöz\n",
        "    corrected_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return corrected_sentence\n",
        "\n",
        "# Test için örnek cümleler\n",
        "test_sentences = [\n",
        "    \"I has a apple.\",\n",
        "    \"She dont like running in the rain.\",\n",
        "    \"He go to the park every day and play football.\"\n",
        "]\n",
        "\n",
        "# Test sonuçları\n",
        "for sentence in test_sentences:\n",
        "    print(f\"Orijinal Cümle: {sentence}\")\n",
        "    print(f\"Düzeltilmiş Cümle: {test_model(sentence)}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shyj4M2Eqt_5",
        "outputId": "57bfb7be-b297-4f43-ea5b-9918056b0d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orijinal Cümle: I has a apple.\n",
            "Düzeltilmiş Cümle: I have an apple .\n",
            "--------------------------------------------------\n",
            "Orijinal Cümle: She dont like running in the rain.\n",
            "Düzeltilmiş Cümle: She does n't like running in the rain .\n",
            "--------------------------------------------------\n",
            "Orijinal Cümle: He go to the park every day and play football.\n",
            "Düzeltilmiş Cümle: He goes to the park every day and plays football .\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers evaluate nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxlcmc2vrTmg",
        "outputId": "12074a52-78cc-4bcb-c7a5-1cdfff16e056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m745.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt\")\n",
        "!pip install rouge_score\n",
        "!pip install meteor\n",
        "!pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Nei0texiN-V",
        "outputId": "53d4588f-45d6-44b9-95de-60bc33c1454c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Requirement already satisfied: meteor in /usr/local/lib/python3.10/dist-packages (2.0.17)\n",
            "Requirement already satisfied: bgzip<0.6.0,>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from meteor) (0.5.0)\n",
            "Requirement already satisfied: biom-format<3.0.0,>=2.1.15 in /usr/local/lib/python3.10/dist-packages (from meteor) (2.1.16)\n",
            "Requirement already satisfied: cogent3<2025.0.0,>=2024.2.5a1 in /usr/local/lib/python3.10/dist-packages (from meteor) (2024.12.19a1)\n",
            "Requirement already satisfied: ete3<4.0.0,>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from meteor) (3.1.3)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from meteor) (23.2)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from meteor) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<16.0.0,>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from meteor) (15.0.2)\n",
            "Requirement already satisfied: pysam<0.23.0,>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from meteor) (0.22.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from biom-format<3.0.0,>=2.1.15->meteor) (8.1.7)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from biom-format<3.0.0,>=2.1.15->meteor) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from biom-format<3.0.0,>=2.1.15->meteor) (1.13.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from biom-format<3.0.0,>=2.1.15->meteor) (3.12.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from cogent3<2025.0.0,>=2024.2.5a1->meteor) (5.2.0)\n",
            "Requirement already satisfied: loky in /usr/local/lib/python3.10/dist-packages (from cogent3<2025.0.0,>=2024.2.5a1->meteor) (3.4.1)\n",
            "Requirement already satisfied: numba>0.54 in /usr/local/lib/python3.10/dist-packages (from cogent3<2025.0.0,>=2024.2.5a1->meteor) (0.60.0)\n",
            "Requirement already satisfied: scitrack in /usr/local/lib/python3.10/dist-packages (from cogent3<2025.0.0,>=2024.2.5a1->meteor) (2024.10.8)\n",
            "Requirement already satisfied: stevedore in /usr/local/lib/python3.10/dist-packages (from cogent3<2025.0.0,>=2024.2.5a1->meteor) (5.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from cogent3<2025.0.0,>=2024.2.5a1->meteor) (4.67.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from cogent3<2025.0.0,>=2024.2.5a1->meteor) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.1.2->meteor) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.1.2->meteor) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.1.2->meteor) (2024.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>0.54->cogent3<2025.0.0,>=2024.2.5a1->meteor) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.2->meteor) (1.17.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from loky->cogent3<2025.0.0,>=2024.2.5a1->meteor) (3.1.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore->cogent3<2025.0.0,>=2024.2.5a1->meteor) (6.1.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (3.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from evaluate import load\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "import torch\n",
        "\n",
        "# Cihaz seçimi\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Drive bağlantısı\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Modellerin yüklenmesi\n",
        "bart_model_path = \"/content/drive/My Drive/bart_model\"  # BART modelinizin yolu\n",
        "bart_tokenizer = BartTokenizer.from_pretrained(bart_model_path)\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(bart_model_path).to(device)\n",
        "\n",
        "# JFLEG veri setini yükle\n",
        "dataset = load_dataset(\"jfleg\", split=\"test\")\n",
        "\n",
        "# Test verilerini ayıkla\n",
        "inputs = [entry[\"sentence\"] for entry in dataset]  # Hatalı cümleler\n",
        "references = [[ref for ref in entry[\"corrections\"]] for entry in dataset]  # Tüm referansları kullan\n",
        "\n",
        "# Metrikleri yükle\n",
        "rouge = load(\"rouge\")\n",
        "ter = load(\"ter\")\n",
        "meteor = load(\"meteor\")\n",
        "\n",
        "# BLEU ve diğer metrikler için fonksiyonlar\n",
        "def calculate_bleu_scores(model, tokenizer, inputs, references):\n",
        "    hypotheses = []\n",
        "    for sentence in inputs:\n",
        "        # Model çıktısını üret\n",
        "        inputs_enc = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
        "        outputs = model.generate(inputs_enc[\"input_ids\"], max_length=128, num_beams=4, early_stopping=True)\n",
        "        hypothesis = tokenizer.decode(outputs[0], skip_special_tokens=True).split()\n",
        "        hypotheses.append(hypothesis)\n",
        "\n",
        "    # BLEU skorunu hesapla (corpus_bleu tüm referansları ve hipotezleri kullanır)\n",
        "    bleu_score = corpus_bleu(references, hypotheses)\n",
        "    return bleu_score\n",
        "\n",
        "def calculate_metrics(model, tokenizer, inputs, references):\n",
        "    hypotheses = []\n",
        "    for sentence in inputs:\n",
        "        # Model çıktısını üret\n",
        "        inputs_enc = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
        "        outputs = model.generate(inputs_enc[\"input_ids\"], max_length=128, num_beams=4, early_stopping=True)\n",
        "        hypothesis = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        hypotheses.append(hypothesis)\n",
        "\n",
        "    # ROUGE\n",
        "    rouge_score = rouge.compute(predictions=hypotheses, references=references)\n",
        "\n",
        "    # TER (ilk referansı kullanır)\n",
        "    ter_score = ter.compute(predictions=hypotheses, references=[refs[0] for refs in references])\n",
        "\n",
        "    # METEOR\n",
        "    meteor_score = meteor.compute(predictions=hypotheses, references=[refs[0] for refs in references])\n",
        "\n",
        "    return rouge_score, ter_score, meteor_score\n",
        "\n",
        "# BLEU Skoru Hesapla\n",
        "print(\"BART Modeli BLEU Skorları:\")\n",
        "bart_bleu = calculate_bleu_scores(bart_model, bart_tokenizer, inputs, references)\n",
        "print(f\"BART Modeli BLEU Skoru (Tüm Test Verileri): {bart_bleu:.4f}\")\n",
        "\n",
        "# Diğer Metrikleri Hesapla\n",
        "rouge_score, ter_score, meteor_score = calculate_metrics(bart_model, bart_tokenizer, inputs, references)\n",
        "\n",
        "# Sonuçları Yazdır\n",
        "print(\"\\nBART Modeli ROUGE Skorları:\")\n",
        "print(rouge_score)\n",
        "\n",
        "print(\"\\nBART Modeli TER Skoru:\")\n",
        "print(f\"TER: {ter_score['score']:.4f}\")\n",
        "\n",
        "print(\"\\nBART Modeli METEOR Skoru:\")\n",
        "print(f\"METEOR: {meteor_score['meteor']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578,
          "referenced_widgets": [
            "e208dc3760854afd9d9ade6fc14c4dfd",
            "fb22d0c1b33647d2af64c3a30e7b3938",
            "bf83cb25b80e415a86d750552c2e7cd8",
            "65b171820bb149efa950c8d13cf91a7e",
            "65ed960fd5564fa1a7edfad5958f14f9",
            "4daf51c881f94a83b7f26f59f955b683",
            "0bdb7da716a0496bbe3286d6e2235c55",
            "fe292e5182f24c9d9a0d47822982dff2",
            "d03fecbf09764c15a12f03cf4b2ee597",
            "eb8ca82b90e845e1b7d809a2fdc90976",
            "5770370c0ded4a9c8401dc217c7468ef"
          ]
        },
        "id": "0A5bdv3viQoF",
        "outputId": "cb002cce-81b3-436f-944b-531e92689504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e208dc3760854afd9d9ade6fc14c4dfd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BART Modeli BLEU Skorları:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BART Modeli BLEU Skoru (Tüm Test Verileri): 0.0000\n",
            "\n",
            "BART Modeli ROUGE Skorları:\n",
            "{'rouge1': 0.9132424527407997, 'rouge2': 0.8296658342375558, 'rougeL': 0.9104384401235732, 'rougeLsum': 0.9104402595241979}\n",
            "\n",
            "BART Modeli TER Skoru:\n",
            "TER: 17.9179\n",
            "\n",
            "BART Modeli METEOR Skoru:\n",
            "METEOR: 0.8750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We55M3Ndlgks",
        "outputId": "7f8b331d-d95f-4a56-ddbd-6d7e9e6a60ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (3.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "import sacrebleu\n",
        "import torch\n",
        "\n",
        "# Cihaz seçimi\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Modellerin yüklenmesi\n",
        "bart_model_path = \"/content/drive/My Drive/bart_model\"  # BART modelinizin yolu\n",
        "bart_tokenizer = BartTokenizer.from_pretrained(bart_model_path)\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(bart_model_path).to(device)\n",
        "\n",
        "# JFLEG veri setini yükle\n",
        "dataset = load_dataset(\"jfleg\", split=\"test\")\n",
        "\n",
        "# Test verilerini ayıkla\n",
        "inputs = [entry[\"sentence\"] for entry in dataset]  # Hatalı cümleler\n",
        "references = [[ref for ref in entry[\"corrections\"]] for entry in dataset]  # Tüm referansları kullan\n",
        "\n",
        "# BLEU hesaplama fonksiyonu\n",
        "def calculate_bleu_with_sacrebleu(model, tokenizer, inputs, references):\n",
        "    hypotheses = []\n",
        "    flattened_references = []\n",
        "\n",
        "    for sentence in inputs:\n",
        "        # Model çıktısını üret\n",
        "        inputs_enc = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
        "        outputs = model.generate(inputs_enc[\"input_ids\"], max_length=128, num_beams=4, early_stopping=True)\n",
        "        hypothesis = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        hypotheses.append(hypothesis)\n",
        "\n",
        "    # Referansları sacreBLEU formatına uygun hale getirme\n",
        "    for ref_list in references:\n",
        "        flattened_references.append([ref for ref in ref_list])  # Çoklu referans formatı\n",
        "\n",
        "    # sacreBLEU hesaplama\n",
        "    bleu = sacrebleu.corpus_bleu(hypotheses, list(zip(*flattened_references)))\n",
        "    return bleu\n",
        "\n",
        "# SacreBLEU Hesapla\n",
        "bart_bleu = calculate_bleu_with_sacrebleu(bart_model, bart_tokenizer, inputs, references)\n",
        "\n",
        "# Sonuçları Yazdır\n",
        "print(f\"BART Modeli SacreBLEU Skoru (Tüm Test Verileri): {bart_bleu.score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkRDRmJMli5g",
        "outputId": "cd41a139-006a-413a-9c35-48bea6a5e39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BART Modeli SacreBLEU Skoru (Tüm Test Verileri): 82.4333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HcMbm44flodr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}